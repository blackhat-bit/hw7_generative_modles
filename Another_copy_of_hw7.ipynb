{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blackhat-bit/hw7_generative_modles/blob/main/Another_copy_of_hw7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MWoe14Ai3I-"
      },
      "source": [
        "# Exercise 7: Denoising Diffusion Probabilistic Models\n",
        "## Submission date: 31\\07\\2025, 23:59.\n",
        "\n",
        "Submitted by:\n",
        "\n",
        " **Student 1 Name+ID\n",
        "\n",
        " **Student 2 Name+ID\n",
        "\n",
        "\n",
        "<font color='red'>Before submission, please make sure that all the plots and results are present as a colab notebook file</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJqF9yRcHWIZ"
      },
      "source": [
        "# Assignment 1: Proof of Posterior Distribution in DDPM\n",
        "\n",
        "### Problem Statement\n",
        "\n",
        "We need to prove that $q(x_{t-1}|x_t, x_0) = \\mathcal{N}(x_{t-1}; \\tilde{\\mu}_t(x_t, x_0), \\tilde{\\beta}_t\\mathbf)$ using Bayes' theorem and find $\\tilde{\\mu}_t$ and $\\tilde{\\beta}_t$.\n",
        "\n",
        "### Solution\n",
        "We start by applying Bayes' theorem:\n",
        "$$\n",
        "q(x_{t-1}|x_t, x_0) = \\frac{q(x_t | x_{t-1}, x_0) \\cdot q(x_{t-1} | x_0)}{q(x_t | x_0)} \\tag{1}\n",
        "$$\n",
        "\n",
        "Since the forward process is Markovian, $x_t$ only depends on $x_{t-1}$ and not on $x_0$ given $x_{t-1}$:\n",
        "$$\n",
        "q(x_t | x_{t-1}, x_0) = q(x_t | x_{t-1}) \\tag{2}\n",
        "$$\n",
        "\n",
        "From the DDPM forward process definitions, we know:\n",
        "$$\n",
        "q(x_t | x_{t-1}) = \\mathcal{N}(x_t; \\sqrt{\\alpha_t}x_{t-1}, \\beta_t\\mathbf{I}) \\tag{3}\n",
        "$$\n",
        "$$\n",
        "q(x_{t-1} | x_0) = \\mathcal{N}(x_{t-1}; \\sqrt{\\bar{\\alpha}_{t-1}}x_0, (1 - \\bar{\\alpha}_{t-1})\\mathbf{I}) \\tag{4}\n",
        "$$\n",
        "$$\n",
        "q(x_t | x_0) = \\mathcal{N}(x_t; \\sqrt{\\bar{\\alpha}_t}x_0, (1 - \\bar{\\alpha}_t)\\mathbf{I}) \\tag{5}\n",
        "$$\n",
        "where $\\bar{\\alpha}_t = \\prod_{i=1}^{t} \\alpha_i$ and $\\alpha_t = 1 - \\beta_t$.\n",
        "\n",
        "Now we'll use the result from HW1 Question 11, which showed that the product of Gaussians results in a Gaussian distribution. Specifically, we work with the log-probabilities:\n",
        "$$\n",
        "\\log q(x_{t-1}|x_t, x_0) = \\log q(x_t|x_{t-1}) + \\log q(x_{t-1}|x_0) - \\log q(x_t|x_0) + \\text{const} \\tag{6}\n",
        "$$\n",
        "\n",
        "Expanding each term:\n",
        "$$\n",
        "\\log q(x_t|x_{t-1}) = -\\frac{1}{2\\beta_t}\\|x_t - \\sqrt{\\alpha_t}x_{t-1}\\|^2 + \\text{const} \\tag{7}\n",
        "$$\n",
        "$$\n",
        "\\log q(x_{t-1}|x_0) = -\\frac{1}{2(1-\\bar{\\alpha}_{t-1})}\\|x_{t-1} - \\sqrt{\\bar{\\alpha}_{t-1}}x_0\\|^2 + \\text{const} \\tag{8}\n",
        "$$\n",
        "$$\n",
        "\\log q(x_t|x_0) = -\\frac{1}{2(1-\\bar{\\alpha}_t)}\\|x_t - \\sqrt{\\bar{\\alpha}_t}x_0\\|^2 + \\text{const} \\tag{9}\n",
        "$$\n",
        "\n",
        "Following the technique from HW1 Question 12 (completing the square), we'll collect all terms involving $x_{t-1}$ from the log-probabilities. Note that the term $-\\log q(x_t|x_0)$ from Equation (6) can be dropped, as it does not depend on $x_{t-1}$ and will be absorbed by the normalization constant of the resulting posterior distribution. We are therefore interested in the expression:\n",
        "$$\n",
        "-\\frac{1}{2\\beta_t}\\|x_t - \\sqrt{\\alpha_t}x_{t-1}\\|^2 - \\frac{1}{2(1-\\bar{\\alpha}_{t-1})}\\|x_{t-1} - \\sqrt{\\bar{\\alpha}_{t-1}}x_0\\|^2 \\tag{10}\n",
        "$$\n",
        "$$\n",
        "= -\\frac{1}{2\\beta_t}(x_t^T x_t - 2\\sqrt{\\alpha_t}x_t^T x_{t-1} + \\alpha_t x_{t-1}^T x_{t-1}) - \\frac{1}{2(1-\\bar{\\alpha}_{t-1})}(x_{t-1}^T x_{t-1} - 2\\sqrt{\\bar{\\alpha}_{t-1}}x_0^T x_{t-1} + \\bar{\\alpha}_{t-1}x_0^T x_0) \\tag{11/12}\n",
        "$$\n",
        "\n",
        "Collecting coefficients of $x_{t-1}^T x_{t-1}$ and $x_{t-1}$:\n",
        "$$\n",
        "\\text{Coefficient of } x_{t-1}^T x_{t-1}: -\\frac{1}{2}\\left(\\frac{\\alpha_t}{\\beta_t} + \\frac{1}{1-\\bar{\\alpha}_{t-1}}\\right) \\tag{13}\n",
        "$$\n",
        "$$\n",
        "\\text{Linear term in } x_{t-1}: \\left(\\frac{\\sqrt{\\alpha_t}}{\\beta_t}x_t^T + \\frac{\\sqrt{\\bar{\\alpha}_{t-1}}}{1-\\bar{\\alpha}_{t-1}}x_0^T\\right) \\tag{14}\n",
        "$$\n",
        "\n",
        "Using the fact that $\\bar{\\alpha}_t = \\alpha_t \\bar{\\alpha}_{t-1}$ and $1 - \\bar{\\alpha}_t = \\beta_t + \\alpha_t(1-\\bar{\\alpha}_{t-1})$:\n",
        "$$\n",
        "\\frac{\\alpha_t}{\\beta_t} + \\frac{1}{1-\\bar{\\alpha}_{t-1}} = \\frac{\\alpha_t(1-\\bar{\\alpha}_{t-1}) + \\beta_t}{\\beta_t(1-\\bar{\\alpha}_{t-1})} = \\frac{1-\\bar{\\alpha}_t}{\\beta_t(1-\\bar{\\alpha}_{t-1})} \\tag{15}\n",
        "$$\n",
        "\n",
        "Therefore, the precision (inverse variance) is:\n",
        "$$\n",
        "\\tilde{\\beta}_t^{-1} = \\frac{1-\\bar{\\alpha}_t}{\\beta_t(1-\\bar{\\alpha}_{t-1})} \\tag{16}\n",
        "$$\n",
        "Which gives us the variance:\n",
        "$$\n",
        "\\boxed{\\tilde{\\beta}_t = \\frac{\\beta_t(1-\\bar{\\alpha}_{t-1})}{1-\\bar{\\alpha}_t}} \\tag{17}\n",
        "$$\n",
        "\n",
        "For the mean, we explicitly derive it from the coefficients of the linear terms in $x_{t-1}$ found in the exponent. The coefficient corresponds to $\\tilde{\\mu}_t/\\tilde{\\beta}_t$. Therefore, we have:\n",
        "$$\n",
        "\\tilde{\\mu}_t = \\tilde{\\beta}_t \\cdot (\\text{coefficient of } x_{t-1}) = \\tilde{\\beta}_t \\left( \\frac{\\sqrt{\\alpha_t}}{\\beta_t}x_t + \\frac{\\sqrt{\\bar{\\alpha}_{t-1}}}{1-\\bar{\\alpha}_{t-1}}x_0 \\right) \\tag{18}\n",
        "$$\n",
        "\n",
        "Substituting our derived expression for $\\tilde{\\beta}_t$ from Equation (17):\n",
        "$$\n",
        "\\tilde{\\mu}_t = \\left( \\frac{\\beta_t(1-\\bar{\\alpha}_{t-1})}{1-\\bar{\\alpha}_t} \\right) \\left( \\frac{\\sqrt{\\alpha_t}}{\\beta_t}x_t + \\frac{\\sqrt{\\bar{\\alpha}_{t-1}}}{1-\\bar{\\alpha}_{t-1}}x_0 \\right) \\tag{19}\n",
        "$$\n",
        "\n",
        "Distributing the terms cancels out the denominators and yields the final expression for the mean:\n",
        "\n",
        "$$\n",
        "\\boxed{\\tilde{\\mu}_t = \\frac{\\sqrt{\\alpha_t}(1-\\bar{\\alpha}_{t-1})x_t + \\sqrt{\\bar{\\alpha}_{t-1}}\\beta_t x_0}{1-\\bar{\\alpha}_t}} \\tag{20}\n",
        "$$\n",
        "\n",
        "This completes the proof that $q(x_{t-1}|x_t, x_0) = \\mathcal{N}(x_{t-1}; \\tilde{\\mu}_t(x_t, x_0), \\tilde{\\beta}_t\\mathbf)$ with the derived expressions for $\\tilde{\\mu}_t$ and $\\tilde{\\beta}_t$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HA5GrP2zY9bI"
      },
      "source": [
        "## Configurations and initializations\n",
        "\n",
        "This section loads libraries and configurations for various tasks for this course"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzI4F5xRY9bK"
      },
      "outputs": [],
      "source": [
        "## Standard libraries\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "## Imports for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "plt.set_cmap('cividis')\n",
        "import seaborn as sns\n",
        "\n",
        "## Progress bar\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "## PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "# Torchvision\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "\n",
        "# Path to the folder where the datasets are/should be downloaded (e.g. MNIST)\n",
        "DATASET_PATH = \"../data\"\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Fetching the device that will be used throughout this notebook\n",
        "device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda\")\n",
        "print(\"Using device\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBLtcuK8CbmC"
      },
      "outputs": [],
      "source": [
        "def scale(sample):\n",
        "    return 2 * sample - 1\n",
        "\n",
        "# Transformations applied on each image => only make them a tensor\n",
        "transform = transforms.Compose([transforms.ToTensor(), scale])\n",
        "\n",
        "# Loading the training dataset. We need to split it into a training and validation part\n",
        "train_dataset = MNIST(root=DATASET_PATH, train=True, transform=transform, download=True)\n",
        "\n",
        "train_set, val_set = torch.utils.data.random_split(train_dataset, [50000, 10000])\n",
        "\n",
        "# Loading the test set\n",
        "test_set = MNIST(root=DATASET_PATH, train=False, transform=transform, download=True)\n",
        "\n",
        "# We define a set of data loaders that we can use for various purposes later.\n",
        "train_loader = data.DataLoader(train_set, batch_size=128, shuffle=True,  drop_last=True)\n",
        "val_loader   = data.DataLoader(val_set,   batch_size=128, shuffle=False, drop_last=True)\n",
        "test_loader  = data.DataLoader(test_set,  batch_size=128, shuffle=False, drop_last=True)\n",
        "\n",
        "print('Train size:', len(train_loader.dataset))\n",
        "print('Validation size:', len(val_loader.dataset))\n",
        "print('Test size:', len(test_loader.dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEjj8YMDY9bL"
      },
      "outputs": [],
      "source": [
        "def show_tensor_image(img):\n",
        "    reverse_transforms = transforms.Compose([\n",
        "        transforms.Lambda(lambda t: (t + 1) / 2),\n",
        "        transforms.Lambda(lambda t: torch.minimum(torch.tensor([1]), t)),\n",
        "        transforms.Lambda(lambda t: torch.maximum(torch.tensor([0]), t)),\n",
        "        transforms.ToPILImage(),\n",
        "    ])\n",
        "    plt.imshow(reverse_transforms(img))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ia5Wo24C96s"
      },
      "outputs": [],
      "source": [
        "def show_imgs(imgs, nrows=1):\n",
        "    ncols = len(imgs) // nrows\n",
        "\n",
        "    imgs = torch.stack(imgs) if isinstance(imgs, list) else imgs        # T, img, ch, size, size or img, ch, size, size\n",
        "\n",
        "    imgs = imgs.unsqueeze(0) if imgs.ndim == 4 else imgs                # T, img, ch, size, size\n",
        "    imgs = imgs.transpose(1, 0)                                         # img, T, ch, size, size\n",
        "    imgs = imgs.reshape((-1,) + imgs.shape[2:])                         # img * T, ch, size, size\n",
        "\n",
        "    plt.figure(figsize=(ncols * 1.2, nrows * 1.2))\n",
        "    grid = torchvision.utils.make_grid(imgs.cpu(), nrow=ncols, pad_value=128)\n",
        "    show_tensor_image(grid.detach().cpu())\n",
        "\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "show_imgs([train_dataset[i][0] for i in range(8)], nrows=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXyytS2zD8YD"
      },
      "source": [
        "## Components & Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKrRnXWfrfOu"
      },
      "outputs": [],
      "source": [
        "class EmbedBlock(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim):\n",
        "        super(EmbedBlock, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        layers = [\n",
        "            nn.Linear(input_dim, emb_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(emb_dim, emb_dim),\n",
        "            nn.Unflatten(1, (emb_dim, 1, 1)),\n",
        "        ]\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, self.input_dim)\n",
        "        #x = x[:, None]\n",
        "        return self.model(x)\n",
        "\n",
        "class SinusoidalPositionEmbedBlock(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, time):\n",
        "        device = time.device\n",
        "        half_dim = self.dim // 2\n",
        "        embeddings = math.log(10000) / (half_dim - 1)\n",
        "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
        "        embeddings = time[:, None] * embeddings[None, :]\n",
        "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
        "        return embeddings\n",
        "\n",
        "class DownBlock(nn.Module):\n",
        "    def __init__(self, in_chs, out_chs):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(in_chs, out_chs, 3, 1, 1),\n",
        "            nn.BatchNorm2d(out_chs),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_chs, out_chs, 3, 1, 1),\n",
        "            nn.BatchNorm2d(out_chs),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "class UpBlock(nn.Module):\n",
        "    def __init__(self, in_chs, out_chs):\n",
        "        super().__init__()\n",
        "        # Note: We'll handle concatenation input size dynamically\n",
        "        self.upsample = nn.ConvTranspose2d(in_chs, in_chs, 2, 2)\n",
        "        self.conv1 = nn.Conv2d(in_chs + in_chs, out_chs, 3, 1, 1)  # Assumes same skip size\n",
        "        self.bn1 = nn.BatchNorm2d(out_chs)\n",
        "        self.conv2 = nn.Conv2d(out_chs, out_chs, 3, 1, 1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_chs)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x, skip):\n",
        "        x = self.upsample(x)\n",
        "        x = torch.cat((x, skip), 1)\n",
        "\n",
        "        # Handle mismatched concatenation sizes\n",
        "        if hasattr(self, '_adaptive_conv1'):\n",
        "            conv1 = self._adaptive_conv1\n",
        "        else:\n",
        "            if x.shape[1] != self.conv1.in_channels:\n",
        "                self._adaptive_conv1 = nn.Conv2d(x.shape[1], self.conv1.out_channels, 3, 1, 1).to(x.device)\n",
        "                conv1 = self._adaptive_conv1\n",
        "            else:\n",
        "                conv1 = self.conv1\n",
        "\n",
        "        x = self.relu(self.bn1(conv1(x)))\n",
        "        x = self.relu(self.bn2(self.conv2(x)))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5ErXXVQqSye"
      },
      "source": [
        "<img align=\"center\" width=\"70%\" src=\"https://sharon.srworkspace.com/dgm/time.png\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wv8_SKFBsaST"
      },
      "outputs": [],
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, T, img_shape):\n",
        "        super(UNet, self).__init__()\n",
        "        self.T = T\n",
        "\n",
        "        img_chs = img_shape[0]\n",
        "        down_chs = (64, 128, 128)\n",
        "        up_chs = down_chs[::-1]               # Reverse of the down channels\n",
        "        latent_image_size = img_shape[1] // 4 # 2 ** (len(down_chs) - 1)\n",
        "\n",
        "        # Time embedding dimension\n",
        "        t_embed_dim = 8\n",
        "\n",
        "        # Initial convolution\n",
        "        self.down0 = nn.Sequential(\n",
        "            nn.Conv2d(img_chs, down_chs[0], 3, padding=1),\n",
        "            nn.BatchNorm2d(down_chs[0]),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Downsample\n",
        "        self.down1 = DownBlock(down_chs[0], down_chs[1])\n",
        "        self.down2 = DownBlock(down_chs[1], down_chs[2])\n",
        "        self.to_vec = nn.Sequential(nn.Flatten(), nn.ReLU())\n",
        "\n",
        "        # Embeddings\n",
        "        self.dense_emb = nn.Sequential(\n",
        "            nn.Linear(down_chs[2]*latent_image_size**2, down_chs[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(down_chs[1], down_chs[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(down_chs[1], down_chs[2]*latent_image_size**2),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.sinusoidaltime = SinusoidalPositionEmbedBlock(t_embed_dim)\n",
        "\n",
        "        # Fix: Match time embedding dimensions to feature map dimensions\n",
        "        self.temb_1 = EmbedBlock(t_embed_dim, down_chs[1])  # 128 channels for h2\n",
        "        self.temb_2 = EmbedBlock(t_embed_dim, down_chs[0])  # 64 channels for h1\n",
        "\n",
        "        # Upsample\n",
        "        self.up0 = nn.Sequential(\n",
        "            nn.Unflatten(1, (up_chs[0], latent_image_size, latent_image_size)),\n",
        "            nn.Conv2d(up_chs[0], up_chs[0], 3, padding=1),\n",
        "            nn.BatchNorm2d(up_chs[0]),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.up1 = UpBlock(up_chs[0], up_chs[1])\n",
        "        self.up2 = UpBlock(up_chs[1], up_chs[2])\n",
        "\n",
        "        # Match output channels\n",
        "        self.out = nn.Sequential(\n",
        "            nn.Conv2d(2 * up_chs[2], up_chs[2], 3, 1, 1),\n",
        "            nn.BatchNorm2d(up_chs[-1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(up_chs[-1], img_chs, 3, 1, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        # Ensure input tensors are on the same device as the model\n",
        "        device = next(self.parameters()).device\n",
        "        x = x.to(device)\n",
        "        t = t.to(device)\n",
        "\n",
        "        # Convert integer timesteps to float in range [0,1]\n",
        "        t = t.float() / self.T\n",
        "\n",
        "        # Create sinusoidal time embeddings\n",
        "        t_emb = self.sinusoidaltime(t)\n",
        "        temb_1 = self.temb_1(t_emb)\n",
        "        temb_2 = self.temb_2(t_emb)\n",
        "\n",
        "        # Encoder path (downsampling)\n",
        "        h1 = self.down0(x)  # (B, 64, 28, 28)\n",
        "        h2 = self.down1(h1)  # (B, 128, 14, 14)\n",
        "        h3 = self.down2(h2)  # (B, 128, 7, 7)\n",
        "\n",
        "        # Bottleneck\n",
        "        hv = self.to_vec(h3)\n",
        "        hv = self.dense_emb(hv)\n",
        "        h = self.up0(hv)  # (B, 128, 7, 7)\n",
        "\n",
        "        # Add time embedding to corresponding skip connections\n",
        "        h2_with_temb = h2 + temb_1\n",
        "        h1_with_temb = h1 + temb_2\n",
        "\n",
        "        # Decoder path (upsampling with skip connections)\n",
        "        h = self.up1(h, h2_with_temb)\n",
        "        h = self.up2(h, h1_with_temb)\n",
        "\n",
        "        # Final output\n",
        "        out = self.out(torch.cat([h, h1_with_temb], dim=1))\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVdI8FjrZgRx"
      },
      "source": [
        "## Define DDPM model\n",
        "\n",
        "A fundemantal idea of diffusion models is to add a little noise to the image each time step and learn how to remove it, depending on time. Here, we will use different variance schedules of  $\\beta_t$.\n",
        "\n",
        "<img width=\"70%\" src=\"https://sharon.srworkspace.com/dgm/dog.png\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caQug2W_ZgRz"
      },
      "outputs": [],
      "source": [
        "class DDPM(nn.Module):\n",
        "    def __init__(self, T, img_shape, method='cosine'):\n",
        "        super(DDPM, self).__init__()\n",
        "        self.T = T\n",
        "\n",
        "        epsilon=0.008\n",
        "        if method == 'cosine':\n",
        "            steps=torch.linspace(0,T,steps=T+1).to(device)\n",
        "            f_t=torch.cos(((steps/T+epsilon)/(1.0+epsilon))*math.pi*0.5)**2\n",
        "            self.Beta = torch.clip(1.0-f_t[1:]/f_t[:T], 0.0, 0.999)\n",
        "\n",
        "        elif method == 'linear':\n",
        "            self.Beta = torch.linspace(1e-4, 2e-2, T).to(device)\n",
        "\n",
        "        # Forward diffusion variables\n",
        "        self.a = 1.0 - self.Beta\n",
        "        self.a_bar = torch.cumprod(self.a, dim=0)\n",
        "\n",
        "        self.img_chs = img_shape[0]\n",
        "        self.img_size = img_shape[1]\n",
        "\n",
        "        self.net = UNet(T, img_shape)\n",
        "\n",
        "        # Logging\n",
        "        self.logs = defaultdict(list)\n",
        "\n",
        "    def log(self, key, value):\n",
        "        self.logs[key].append(value)\n",
        "\n",
        "    def q(self, x_0, t):\n",
        "        \"\"\"\n",
        "        Forward diffusion process: q(x_t | x_0)\n",
        "        \"\"\"\n",
        "        device = x_0.device  # Get device from input\n",
        "\n",
        "        # Generate random noise with same shape as x_0\n",
        "        noise = torch.randn_like(x_0).to(device)\n",
        "\n",
        "        # Get alpha_bar values for the batch\n",
        "        a_bar_t = self.a_bar[t].reshape(-1, 1, 1, 1).to(device)\n",
        "\n",
        "        # Apply forward diffusion: x_t = sqrt(a_bar_t) * x_0 + sqrt(1 - a_bar_t) * noise\n",
        "        x_t = torch.sqrt(a_bar_t) * x_0 + torch.sqrt(1 - a_bar_t) * noise\n",
        "\n",
        "        return x_t, noise\n",
        "\n",
        "    def get_x0_pred(self, x_t, t, e_t):\n",
        "        # Fix: Properly index and reshape alpha_bar\n",
        "        device = x_t.device\n",
        "        a_bar_t = self.a_bar[t].reshape(-1, 1, 1, 1).to(device)\n",
        "\n",
        "        x_0_pred = (x_t - torch.sqrt(1 - a_bar_t) * e_t) / torch.sqrt(a_bar_t)\n",
        "        x_0_pred = x_0_pred.clamp(-1, 1)\n",
        "        return x_0_pred\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def reverse_q(self, x_t, t, e_t):\n",
        "        \"\"\"\n",
        "        Sample from q(x_{t-1} | x_t, x_0) using predicted noise\n",
        "        \"\"\"\n",
        "        device = x_t.device\n",
        "\n",
        "        # Special case: at t=0, just return the denoised image\n",
        "        if t[0] == 0:\n",
        "            return self.get_x0_pred(x_t, t, e_t)\n",
        "\n",
        "        # Get predicted x_0\n",
        "        x_0_pred = self.get_x0_pred(x_t, t, e_t)\n",
        "\n",
        "        # Extract parameters and move to correct device\n",
        "        a_t = self.a[t].reshape(-1, 1, 1, 1).to(device)\n",
        "        a_bar_t = self.a_bar[t].reshape(-1, 1, 1, 1).to(device)\n",
        "        a_bar_t_1 = self.a_bar[t-1].reshape(-1, 1, 1, 1).to(device)\n",
        "        beta_t = self.Beta[t].reshape(-1, 1, 1, 1).to(device)\n",
        "\n",
        "        # Calculate posterior mean (from Assignment 1)\n",
        "        mu_tilde = (torch.sqrt(a_t) * (1 - a_bar_t_1) * x_t +\n",
        "                    torch.sqrt(a_bar_t_1) * beta_t * x_0_pred) / (1 - a_bar_t)\n",
        "\n",
        "        # Calculate posterior variance (from Assignment 1)\n",
        "        beta_tilde = beta_t * (1 - a_bar_t_1) / (1 - a_bar_t)\n",
        "\n",
        "        # Sample from posterior (no noise at t=0)\n",
        "        noise = torch.randn_like(x_t).to(device) if t[0] > 0 else 0\n",
        "        x_t_1 = mu_tilde + torch.sqrt(beta_tilde) * noise\n",
        "\n",
        "        return x_t_1\n",
        "\n",
        "    def get_loss(self, x_0, t):\n",
        "        \"\"\"\n",
        "        Calculate the training loss\n",
        "        \"\"\"\n",
        "        device = x_0.device\n",
        "\n",
        "        # Add noise to image\n",
        "        x_t, noise = self.q(x_0, t)\n",
        "\n",
        "        # Predict noise with UNet\n",
        "        predicted_noise = self.net(x_t, t)\n",
        "\n",
        "        # MSE loss between true and predicted noise\n",
        "        loss = F.mse_loss(predicted_noise, noise)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def sample(self, num_imgs=1, skip=1):\n",
        "        \"\"\"\n",
        "        Generate samples by reversing the diffusion process\n",
        "        \"\"\"\n",
        "        self.eval()\n",
        "        device = next(self.parameters()).device\n",
        "\n",
        "        # Start from pure noise\n",
        "        x_t = torch.randn(num_imgs, self.img_chs, self.img_size, self.img_size).to(device)\n",
        "\n",
        "        # Reverse diffusion: go from T-1 to 0\n",
        "        for t in reversed(range(self.T)):\n",
        "            # Create batch of timesteps\n",
        "            t_batch = torch.full((num_imgs,), t, dtype=torch.long).to(device)\n",
        "\n",
        "            # Predict noise\n",
        "            e_t = self.net(x_t, t_batch)\n",
        "\n",
        "            # Take reverse step\n",
        "            x_t = self.reverse_q(x_t, t_batch, e_t)\n",
        "\n",
        "        return x_t  # Return final result, not intermediate steps\n",
        "\n",
        "    def log(self, key, value):\n",
        "        self.logs[key].append(value)\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        # Generate random timesteps for the batch\n",
        "        t = torch.randint(0, self.T, (len(batch),), device=batch.device)\n",
        "        loss = self.get_loss(batch, t)\n",
        "\n",
        "        # Log losses\n",
        "        self.log('train_loss', loss.item())\n",
        "        return loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def validation_step(self, loader):\n",
        "        loss = 0\n",
        "        for imgs, _ in tqdm(loader, leave=False):\n",
        "          imgs = imgs.to(device)\n",
        "          t = torch.randint(0, self.T, (len(imgs),), device=device)\n",
        "          loss += self.get_loss(imgs, t)\n",
        "\n",
        "        loss = loss.item()\n",
        "        loss = loss / len(loader)\n",
        "        # Log losses\n",
        "        self.log('val_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def test_step(self, loader):\n",
        "        loss = 0\n",
        "        for imgs, _ in tqdm(loader, leave=False):\n",
        "          imgs = imgs.to(device)\n",
        "          t = torch.randint(0, self.T, (len(imgs),), device=device)\n",
        "          loss += self.get_loss(imgs, t)\n",
        "\n",
        "        loss = loss.item()\n",
        "        loss = loss / len(loader)\n",
        "        # Log losses\n",
        "        self.log('test_loss', loss)\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UC3z8ECxZgR0"
      },
      "outputs": [],
      "source": [
        "#@title you may run this to make sure your implementation for q is good\n",
        "\n",
        "# Get first image from training set\n",
        "x_0 = train_set[1][0].to(device)  # Initial image\n",
        "plt.figure(figsize=(14, 8))\n",
        "\n",
        "# Initialize DDPM model\n",
        "ddpm = DDPM(T=1000, img_shape=x_0.shape)\n",
        "\n",
        "# Test forward process at different timesteps\n",
        "for t in range(0, ddpm.T, 100):  # Show every 100 timesteps\n",
        "    t_tensor = torch.Tensor([t]).type(torch.int64).to(device)\n",
        "    x_t, noise = ddpm.q(x_0.unsqueeze(0), t_tensor)  # Add batch dimension\n",
        "    img = torch.squeeze(x_t).cpu()\n",
        "\n",
        "    ax = plt.subplot(1, 10, t // 100 + 1)\n",
        "    ax.axis('off')\n",
        "    ax.set_title(f't={t}')\n",
        "    show_tensor_image(img)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOh7AyR5Zd8Z"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsWbEjaR2m6r"
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "img_shape = train_set[0][0].shape\n",
        "model = DDPM(T=1000, img_shape=img_shape)\n",
        "print(\"Num params: {:,}\".format(sum(p.numel() for p in model.parameters())))\n",
        "model = torch.compile(model.to(device))\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "epochs = 40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQU8IOMAZFhf"
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    losses = []\n",
        "\n",
        "    for imgs, _ in tqdm(train_loader):\n",
        "        imgs = imgs.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        loss = model.training_step(imgs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    val_loss = model.validation_step(val_loader)\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        print(f\"Epoch {epoch} | Loss: {val_loss} \")\n",
        "        sampled_data = model.sample(skip=100)\n",
        "        show_imgs(sampled_data)\n",
        "\n",
        "# Test loop\n",
        "model.eval()\n",
        "\n",
        "final_loss = model.test_step(test_loader)\n",
        "print(f\"Final test loss: {final_loss}\")\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'mnist.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eumx9gP8qa6U"
      },
      "source": [
        "# Visualize samples after training (assignment 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_Wz0y0zqacq"
      },
      "outputs": [],
      "source": [
        "print(\"Generating 8 samples after training...\")\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    samples = model.sample(num_imgs=8, skip=50)\n",
        "\n",
        "    # Handle different sample formats\n",
        "    if len(samples.shape) == 5:  # (time_steps, batch, channels, height, width)\n",
        "        final_samples = samples[-1]  # Take final timestep\n",
        "        print(f\"Generated {len(samples)} diffusion steps, showing final result\")\n",
        "    else:\n",
        "        final_samples = samples\n",
        "        print(\"Generated final samples\")\n",
        "\n",
        "    print(\"Final generated samples:\")\n",
        "    show_imgs(final_samples, nrows=2)\n",
        "\n",
        "    print(\"Are they recognizable? (Examine the digits above)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrD-gm46npzf"
      },
      "source": [
        " # Loss Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9fRvNscnpWW"
      },
      "outputs": [],
      "source": [
        "# Plot training and validation loss curves\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_losses = model.logs['train_loss']\n",
        "val_losses = model.logs['val_loss']\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label='Training Loss', color='blue')\n",
        "plt.plot(val_losses, label='Validation Loss', color='red')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss Curves')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Final Training Loss: {train_losses[-1]:.4f}\")\n",
        "print(f\"Final Validation Loss: {val_losses[-1]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDylSsQYn7Vw"
      },
      "source": [
        "# Forward diffusion visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0QYDAian_4m"
      },
      "outputs": [],
      "source": [
        "# Show forward diffusion process\n",
        "\"\"\"\n",
        "print(\"Forward diffusion process visualization:\")\n",
        "x_0 = train_set[1][0].to(device)\n",
        "plt.figure(figsize=(14, 8))\n",
        "\n",
        "for i, t in enumerate(range(0, model.T, 100)):\n",
        "    t_tensor = torch.Tensor([t]).type(torch.int64).to(device)\n",
        "    x_t, noise = model.q(x_0.unsqueeze(0), t_tensor)\n",
        "    img = torch.squeeze(x_t).cpu()\n",
        "\n",
        "    ax = plt.subplot(1, 10, i + 1)\n",
        "    ax.axis('off')\n",
        "    ax.set_title(f't={t}')\n",
        "    show_tensor_image(img)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URB1vjLsbCW0"
      },
      "source": [
        "## Autocomplete two images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1YhKj8MbCW1"
      },
      "outputs": [],
      "source": [
        "def complete_image(y=None, ymask=None, scale=1.):\n",
        "    # Implement here\n",
        "    # Hint: Use ddpm.get_x0_pred(x_t, t, e_t)\n",
        "    \"\"\"\n",
        "    Complete missing parts of an image using gradient guidance\n",
        "    y: observed image with masked regions set to 0\n",
        "    ymask: binary mask (1 for observed pixels, 0 for missing)\n",
        "    scale: guidance strength\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    num_imgs = y.shape[0]\n",
        "\n",
        "    # Start from noise\n",
        "    x_t = torch.randn_like(y).to(device)\n",
        "\n",
        "    for t in reversed(range(model.T)):\n",
        "        t_batch = torch.full((num_imgs,), t, dtype=torch.long).to(device)\n",
        "\n",
        "        # Enable gradients for guidance\n",
        "        x_t.requires_grad_(True)\n",
        "\n",
        "        # Predict noise\n",
        "        e_t = model.net(x_t, t_batch)\n",
        "\n",
        "        # Get predicted x_0\n",
        "        x_0_pred = model.get_x0_pred(x_t, t_batch, e_t)\n",
        "\n",
        "        # Compute guidance loss on observed pixels\n",
        "        loss = F.mse_loss(ymask * x_0_pred, ymask * y, reduction='sum')\n",
        "\n",
        "        # Compute gradient\n",
        "        grad = torch.autograd.grad(loss, x_t)[0]\n",
        "\n",
        "        # Disable gradients for reverse step\n",
        "        x_t = x_t.detach()\n",
        "\n",
        "        # Take guided reverse step\n",
        "        x_t = model.reverse_q(x_t, t_batch, e_t) - scale * grad\n",
        "\n",
        "    return x_t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zc9NJv1Eq6zW"
      },
      "source": [
        " # image completion experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUjgfR61q-Cq"
      },
      "outputs": [],
      "source": [
        "# Select 6 test images\n",
        "test_imgs, _ = next(iter(test_loader))\n",
        "test_imgs = test_imgs[:6].to(device)\n",
        "\n",
        "# Create masks\n",
        "bottom_mask = torch.ones_like(test_imgs)\n",
        "bottom_mask[:, :, 14:, :] = 0  # Hide bottom half\n",
        "\n",
        "top_mask = torch.ones_like(test_imgs)\n",
        "top_mask[:, :, :14, :] = 0  # Hide top half\n",
        "\n",
        "# Prepare images\n",
        "imgs_bottom_hidden = test_imgs[:3] * bottom_mask[:3]\n",
        "imgs_top_hidden = test_imgs[3:] * top_mask[3:]\n",
        "\n",
        "# Generate completions\n",
        "results = []\n",
        "for i in range(3):\n",
        "    # Complete bottom half\n",
        "    y = imgs_bottom_hidden[i:i+1]\n",
        "    mask = bottom_mask[i:i+1]\n",
        "    for _ in range(5):\n",
        "        completed = complete_image(y, mask, scale=0.1)\n",
        "        results.append(completed)\n",
        "\n",
        "    # Complete top half\n",
        "    y = imgs_top_hidden[i:i+1]\n",
        "    mask = top_mask[i:i+1]\n",
        "    for _ in range(5):\n",
        "        completed = complete_image(y, mask, scale=0.1)\n",
        "        results.append(completed)\n",
        "\n",
        "# Visualize results\n",
        "print(\"Original images:\")\n",
        "show_imgs(test_imgs[:6])\n",
        "print(\"Masked images:\")\n",
        "show_imgs(torch.cat([imgs_bottom_hidden, imgs_top_hidden]))\n",
        "print(\"Completed samples:\")\n",
        "show_imgs(torch.cat(results), nrows=6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IL2uzCGEY-x0"
      },
      "source": [
        "# Bonus - Adding context\n",
        "<font color='red'>We completed the bonus</font><br/>\n",
        "\n",
        "MNIST is boring! Moreover, what is the point of generating samples without controling them? <br/>\n",
        "We will use a pretrained CLIP (Contrastive Language-Image Pre-Training).\n",
        "\n",
        "CLIP creates embeddings of both text and images such that images are aligned to the text that describes them. We will use this to encode text and decode into a new image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FaaUMZPat0pd"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet git+https://github.com/openai/CLIP.git\n",
        "\n",
        "import glob\n",
        "import csv\n",
        "from textwrap import wrap\n",
        "\n",
        "import clip\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDQzWRRMlLYT"
      },
      "source": [
        "## Load data\n",
        "Go to your <a href=\"https://www.kaggle.com/\">Kaggle</a> account and under the settings, generate new API token. <br/>\n",
        "This will export you a json file, which you will upload here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsQP__wzjHQp"
      },
      "outputs": [],
      "source": [
        "# The script expects you to upload JSON file to it!\n",
        "\n",
        "! pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets list\n",
        "! kaggle datasets download jessicali9530/celeba-dataset\n",
        "! unzip -q celeba-dataset.zip -d faces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRoYygVmk2iU"
      },
      "outputs": [],
      "source": [
        "FACES_PATH = \"/content/faces/img_align_celeba/img_align_celeba\"\n",
        "\n",
        "for i in range(1,9):\n",
        "  img = Image.open(f'{FACES_PATH}/00000{i}.jpg')\n",
        "  plt.subplot(2, 4, i)\n",
        "  plt.axis('off')\n",
        "  plt.imshow(img)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqU0DIjst5a7"
      },
      "source": [
        "## load pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5FzjTmiT42i"
      },
      "outputs": [],
      "source": [
        "clip.available_models()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8zRXdOAt9wH"
      },
      "outputs": [],
      "source": [
        "clip_model, clip_preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "clip_model.eval()\n",
        "CLIP_FEATURES = 512"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvgB41A-naVP"
      },
      "source": [
        "## Intro to CLIP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_0bO2pR3OEO"
      },
      "source": [
        "Load image using CLIP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTSyqKPpQSPq"
      },
      "outputs": [],
      "source": [
        "img = Image.open(f'{FACES_PATH}/000001.jpg')\n",
        "\n",
        "clip_imgs = torch.tensor(np.stack([clip_preprocess(img)])).to(device)\n",
        "print(\"After image clip preprocessing the size is \", clip_imgs.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqhqiEt530ml"
      },
      "source": [
        "Feature extractor of CLIP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jNKDvgm32oS"
      },
      "outputs": [],
      "source": [
        "clip_img_encoding = clip_model.encode_image(clip_imgs)\n",
        "print(clip_img_encoding.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igam8MX75YwZ"
      },
      "source": [
        "Now, we want to see how to tokenize text and encoder it using clip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KR_FILDZ5dFl"
      },
      "outputs": [],
      "source": [
        "text_list = [\n",
        "    \"An Angry man\",\n",
        "    \"Smiling bald person\",\n",
        "    \"Happy beautiful woman\"\n",
        "]\n",
        "text_tokens = clip.tokenize(text_list).to(device)\n",
        "print(\"Text tokens\")\n",
        "print(text_tokens[:,:10])\n",
        "print(\"----------------------------\")\n",
        "\n",
        "clip_text_encodings = clip_model.encode_text(text_tokens).float()\n",
        "print(\"For each text, encoding of 512 features \", clip_text_encodings.size())\n",
        "print(clip_text_encodings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xgr5aa1b6kEy"
      },
      "source": [
        "In order to see which one of our text descriptions best describes the faces, we can calculate the cosine similarity between the text encodings and the image encodings. <br/>\n",
        "We will load three flowers, give each its encoding and will compare to the texts above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykxsTFug7U2d"
      },
      "outputs": [],
      "source": [
        "def get_img_encodings(imgs):\n",
        "    processed_imgs = [clip_preprocess(img) for img in imgs]\n",
        "    clip_imgs = torch.tensor(np.stack(processed_imgs)).to(device)\n",
        "    clip_img_encodings = clip_model.encode_image(clip_imgs)\n",
        "    return clip_img_encodings\n",
        "\n",
        "imgs = [Image.open(f\"{FACES_PATH}/{i}.jpg\") for i in [\"000069\", \"000174\", \"000154\"]]\n",
        "for i, img in enumerate(imgs):\n",
        "    plt.subplot(1,3,i+1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1f3bp5rW7xQU"
      },
      "outputs": [],
      "source": [
        "clip_img_encodings = get_img_encodings(imgs)    # torch.Tensor([3, 512])\n",
        "\n",
        "text_list = [\n",
        "    \"A surprised man with black hair\",\n",
        "    \"A woman smiling with red hair\",\n",
        "    \"A person with black glasses and wears black hat\"\n",
        "]\n",
        "\n",
        "text_tokens = clip.tokenize(text_list).to(device)\n",
        "clip_text_encodings = clip_model.encode_text(text_tokens)   # torch.Tensor([3, 512])\n",
        "\n",
        "clip_img_encodings /= clip_img_encodings.norm(dim=-1, keepdim=True)\n",
        "clip_text_encodings /= clip_text_encodings.norm(dim=-1, keepdim=True)\n",
        "\n",
        "similarity = clip_img_encodings @ clip_text_encodings.T\n",
        "\n",
        "print(similarity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-dFXoeX9aCR"
      },
      "source": [
        "Well, is there a match?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDcUIzbW87MA"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10, 10))\n",
        "gs = fig.add_gridspec(2, 3, wspace=.1, hspace=0)\n",
        "\n",
        "ax = fig.add_subplot(gs[1, :])\n",
        "plt.imshow(similarity.detach().cpu().numpy().T, vmin=0.1, vmax=0.3)\n",
        "\n",
        "labels = [ '\\n'.join(wrap(text, 20)) for text in text_list ]\n",
        "plt.yticks(range(len(text_tokens)), labels, fontsize=10)\n",
        "plt.xticks([])\n",
        "\n",
        "for x in range(similarity.shape[1]):\n",
        "    for y in range(similarity.shape[0]):\n",
        "        plt.text(x, y, f\"{similarity[x, y]:.2f}\", ha=\"center\", va=\"center\", size=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfVr3jwTdBVG"
      },
      "source": [
        "Collabory: CLIP gives the most similar encoding of image to the most similar encoding of text.\n",
        "Hence, we will train using the image encoding, but create new images using an encoding of text, hopefully it will work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaVgCZGFwuss"
      },
      "source": [
        "## Proccess the data using clip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SMJJVCixBY-"
      },
      "outputs": [],
      "source": [
        "CLIP_FEATURES = 512\n",
        "\n",
        "def crop_face(sample):\n",
        "  return sample[:, 9:(9+32),4:(4+32)]\n",
        "\n",
        "pre_transforms = transforms.Compose([\n",
        "    transforms.Resize((50, 40)),\n",
        "    transforms.ToTensor(),  # Scales data into [0,1]\n",
        "    crop_face,\n",
        "    transforms.Lambda(lambda t: (t * 2) - 1)  # Scale between [-1, 1]\n",
        "])\n",
        "\n",
        "random_transforms = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X268JiRQxMft"
      },
      "source": [
        "With our current resources, we DO NOT want to encode ~50000 images. Download the csv file. It contains the file paths, along with its preprocessed CLIP data.\n",
        "\n",
        "Remark: the file contains 202k images. Training on all of them is an excellent idea - example will be attached at the end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNs4xTDJM-G0"
      },
      "outputs": [],
      "source": [
        "#!wget https://srworkspace.com/sharon/dgm/clip_data.zip\n",
        "#!unzip -q clip_data.zip\n",
        "#this is not working I've uploaded the csv file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1l_E-mIxKcq"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import csv\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, csv_path='clip_data.csv', max_samples=50_000):\n",
        "        self.imgs = []\n",
        "        self.labels = torch.empty(\n",
        "            max_samples, CLIP_FEATURES, dtype=torch.float, device=device\n",
        "        )\n",
        "\n",
        "        with open(csv_path, newline='') as csvfile:\n",
        "            reader = csv.reader(csvfile, delimiter=',')\n",
        "            for idx, row in tqdm(enumerate(reader), total=max_samples):\n",
        "                if idx >= max_samples:\n",
        "                    break\n",
        "                img = Image.open(row[0])\n",
        "                self.imgs.append(pre_transforms(img).to(device))\n",
        "                label = [float(x) for x in row[1:]]\n",
        "                self.labels[idx, :] = torch.FloatTensor(label).to(device)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return random_transforms(self.imgs[idx]), self.labels[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "data_paths = glob.glob(f'{FACES_PATH}/*.jpg', recursive=True)\n",
        "faces_data = MyDataset()\n",
        "faces_dataloader = data.DataLoader(faces_data, batch_size=128, shuffle=True, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sO4FUfVnxcbz"
      },
      "outputs": [],
      "source": [
        "#@title Components of UNet\n",
        "import math\n",
        "\n",
        "# --- USE THIS CORRECT VERSION ---\n",
        "class GELUConvBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, group_size):\n",
        "        super().__init__()\n",
        "        # Layers are defined ONCE and their weights will be learned\n",
        "        self.conv = nn.Conv2d(in_ch, out_ch, 3, 1, 1)\n",
        "        self.norm = nn.GroupNorm(group_size, out_ch)\n",
        "        self.activation = nn.GELU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # The same trained layers are used every time\n",
        "        x = self.conv(x)\n",
        "        x = self.norm(x)\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "class RearrangePoolBlock(nn.Module):\n",
        "    def __init__(self, in_chs, group_size):\n",
        "        super().__init__()\n",
        "        self.rearrange = nn.MaxPool2d(2)\n",
        "        self.conv = GELUConvBlock(in_chs, in_chs, group_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.rearrange(x)\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class DownBlock(nn.Module):\n",
        "    def __init__(self, in_chs, out_chs, group_size):\n",
        "        super(DownBlock, self).__init__()\n",
        "        layers = [\n",
        "            GELUConvBlock(in_chs, out_chs, group_size),\n",
        "            GELUConvBlock(out_chs, out_chs, group_size),\n",
        "            RearrangePoolBlock(out_chs, group_size),\n",
        "        ]\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "\n",
        "class UpBlock(nn.Module):\n",
        "    def __init__(self, in_ch, skip_ch, out_ch, group_size):\n",
        "        super().__init__()\n",
        "\n",
        "        # Upsampling layer takes in_ch from the layer below and produces out_ch\n",
        "        self.upsample = nn.ConvTranspose2d(in_ch, out_ch, kernel_size=4, stride=2, padding=1)\n",
        "\n",
        "        # The convolutional part must accept the COMBINED channels from the\n",
        "        # upsampled tensor (out_ch) and the skip connection (skip_ch).\n",
        "        self.convs = ResidualConvBlock(out_ch + skip_ch, out_ch, group_size)\n",
        "\n",
        "    def forward(self, x, skip, time_emb, context_emb):\n",
        "        # Upsample the tensor from the layer below.\n",
        "        x = self.upsample(x)\n",
        "\n",
        "        # Concatenate with the skip connection.\n",
        "        x = torch.cat([x, skip], dim=1)\n",
        "\n",
        "        # Pass the correctly sized tensor to the convolutional block.\n",
        "        return self.convs(x)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x, skip, time_emb, context_emb):\n",
        "\n",
        "        print(f\"--- Entering UpBlock ---\")\n",
        "        print(f\"Initial x shape: {x.shape}\")\n",
        "        print(f\"Initial skip shape: {skip.shape}\")\n",
        "\n",
        "        # Step 1: Upsample\n",
        "        x = self.upsample(x)\n",
        "        print(f\"After upsample, x shape: {x.shape}\")\n",
        "\n",
        "        # Step 2: Concatenate\n",
        "        x = torch.cat([x, skip], dim=1)\n",
        "        print(f\"After torch.cat, x shape: {x.shape}\")\n",
        "\n",
        "        # Step 3: Call convolutional layers (this is where the error happens)\n",
        "        print(f\"Passing tensor with shape {x.shape} to self.convs\")\n",
        "        print(f\"--- Exiting UpBlock ---\")\n",
        "\n",
        "        return self.convs(x)\n",
        "\n",
        "class SinusoidalPositionEmbedBlock(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, time):\n",
        "        device = time.device\n",
        "        half_dim = self.dim // 2\n",
        "        embeddings = math.log(10000) / (half_dim - 1)\n",
        "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
        "        embeddings = time[:, None] * embeddings[None, :]\n",
        "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class EmbedBlock(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim):\n",
        "        super(EmbedBlock, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        layers = [\n",
        "            nn.Linear(input_dim, emb_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(emb_dim, emb_dim),\n",
        "            nn.Unflatten(1, (emb_dim, 1, 1)),\n",
        "        ]\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, self.input_dim)\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "\n",
        "class ResidualConvBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, group_size):\n",
        "        super().__init__()\n",
        "\n",
        "        # Main convolutional path\n",
        "        self.convs = nn.Sequential(\n",
        "            # This first convolution MUST use in_ch. This is where the error was.\n",
        "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
        "            nn.GroupNorm(group_size, out_ch),\n",
        "            nn.GELU(),\n",
        "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
        "            nn.GroupNorm(group_size, out_ch)\n",
        "        )\n",
        "\n",
        "        # Residual connection path\n",
        "        if in_ch != out_ch:\n",
        "            self.residual = nn.Conv2d(in_ch, out_ch, kernel_size=1)\n",
        "        else:\n",
        "            self.residual = nn.Identity()\n",
        "\n",
        "        self.activation = nn.GELU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass input through main path and residual path, then add them\n",
        "        return self.activation(self.convs(x) + self.residual(x))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpKeY-b5R34x"
      },
      "source": [
        "## Recap to guidance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDpaecMaR8mD"
      },
      "source": [
        "So far, the models have generated image without control, but if we somehow embed what we want into the model, it will be taken into account during training!\n",
        "\n",
        "We use CLIP to encode text into embedding. Then, we will **not** feed it directly to the model, but rather apply a \"dropout\" on it first, as it will maintain divergence and prevent overfitting (see ```get_context_mask``` later).\n",
        "\n",
        "Then, at sampling, when removing noise, we will predict two types of noise:\n",
        "- \"keep context\" (uses context mask with $p=0$)\n",
        "- \"remove context\" (uses context mask with $p=1$)\n",
        "\n",
        "As always, there is tradeoff, weigted over both noises using\n",
        "$$\n",
        "_t=_(x_t,c=1) \\times (1+s)-_(x_t,c=0)\\times s\n",
        "$$\n",
        "\n",
        "Here is an example for impact of $s$, when we ignore the $\\text{keep}\\times 1$:\n",
        "\n",
        "<img width=\"50%\" src=\"https://srworkspace.com/sharon/dgm/guidance.png\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8qChe2NS_yQ"
      },
      "source": [
        "## Modify the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAst4_SrS-RT"
      },
      "source": [
        "<img width=\"70%\" src=\"https://sharon.srworkspace.com/dgm/context1.png\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTutNzEGxcb0"
      },
      "outputs": [],
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, T, img_shape):\n",
        "        super(UNet, self).__init__()\n",
        "        img_chs = img_shape[0]\n",
        "        self.T = T\n",
        "        down_chs = (32, 64, 128)\n",
        "        up_chs = down_chs[::-1]  # Reverse of the down channels\n",
        "        latent_image_size = img_shape[1] // 4 # 2 ** (len(down_chs) - 1)\n",
        "        t_embed_dim = 16\n",
        "        c_embed_dim=CLIP_FEATURES # New\n",
        "\n",
        "        small_group_size = 8 # New\n",
        "        big_group_size = 32 # New\n",
        "\n",
        "        # Inital convolution\n",
        "        self.down0 = ResidualConvBlock(img_chs, down_chs[0], small_group_size)\n",
        "\n",
        "        # Downsample\n",
        "        self.down1 = DownBlock(down_chs[0], down_chs[1], big_group_size)\n",
        "        self.down2 = DownBlock(down_chs[1], down_chs[2], big_group_size)\n",
        "        self.to_vec = nn.Sequential(nn.Flatten(), nn.GELU())\n",
        "\n",
        "        # Embeddings\n",
        "        self.dense_emb = nn.Sequential(\n",
        "            nn.Linear(down_chs[2] * latent_image_size**2, down_chs[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(down_chs[1], down_chs[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(down_chs[1], down_chs[2] * latent_image_size**2),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.sinusoidaltime = SinusoidalPositionEmbedBlock(t_embed_dim)\n",
        "        self.temb_1 = EmbedBlock(t_embed_dim, up_chs[0])\n",
        "        self.temb_2 = EmbedBlock(t_embed_dim, up_chs[1])\n",
        "        self.c_embed1 = EmbedBlock(c_embed_dim, up_chs[0])\n",
        "        self.c_embed2 = EmbedBlock(c_embed_dim, up_chs[1])\n",
        "\n",
        "        # Upsample\n",
        "        self.up0 = nn.Sequential(\n",
        "            nn.Unflatten(1, (up_chs[0], latent_image_size, latent_image_size)),\n",
        "            GELUConvBlock(up_chs[0], up_chs[0], big_group_size),\n",
        "        )\n",
        "\n",
        "        # up1 gets 128 channels from up0 and 64 channels from the down1 skip connection. It outputs 64 channels.\n",
        "        self.up1 = UpBlock(in_ch=up_chs[0], skip_ch=down_chs[1], out_ch=up_chs[1], group_size=big_group_size)\n",
        "\n",
        "        # up2 gets 64 channels from up1 and 32 channels from the down0 skip connection. It outputs 32 channels.\n",
        "        self.up2 = UpBlock(in_ch=up_chs[1], skip_ch=down_chs[0], out_ch=up_chs[2], group_size=big_group_size)\n",
        "\n",
        "        # Match output channels and one last concatenation\n",
        "        self.out = nn.Sequential(\n",
        "            nn.Conv2d(2 * up_chs[-1], up_chs[-1], 3, 1, 1),\n",
        "            nn.GroupNorm(small_group_size, up_chs[-1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(up_chs[-1], img_chs, 3, 1, 1),\n",
        "        )\n",
        "\n",
        "    # class UNet(nn.Module):\n",
        "    #    ... (your __init__ method) ...\n",
        "\n",
        "    def forward(self, x, t, c, c_mask):\n",
        "        \"\"\"\n",
        "        The full forward pass for the entire U-Net.\n",
        "        \"\"\"\n",
        "        # --- 1. SETUP: Calculate Embeddings ---\n",
        "        # Apply context dropout for classifier-free guidance\n",
        "        c = c * c_mask\n",
        "\n",
        "        # Get time and context embeddings, projected to the correct dimensions\n",
        "        t_emb = self.sinusoidaltime(t)\n",
        "        temb_1 = self.temb_1(t_emb) # For up2 block\n",
        "        temb_2 = self.temb_2(t_emb) # For up1 block\n",
        "\n",
        "        cemb_1 = self.c_embed1(c) # For up2 block\n",
        "        cemb_2 = self.c_embed2(c) # For up1 block\n",
        "\n",
        "        # --- 2. ENCODER (Downsampling Path) ---\n",
        "        skip1 = self.down0(x)\n",
        "        skip2 = self.down1(skip1)\n",
        "        h = self.down2(skip2)\n",
        "\n",
        "        # --- 3. BOTTLENECK ---\n",
        "        h = self.to_vec(h)\n",
        "        h = self.dense_emb(h)\n",
        "        h = self.up0(h) # Initial tensor for the decoder path\n",
        "\n",
        "        # --- 4. DECODER (Upsampling Path) ---\n",
        "        h = self.up1(h, skip2, temb_2, cemb_2)\n",
        "        h = self.up2(h, skip1, temb_1, cemb_1)\n",
        "\n",
        "        # --- 5. FINAL OUTPUT LAYER ---\n",
        "        out = self.out(h)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbnTlwrNyFcR"
      },
      "outputs": [],
      "source": [
        "class DDPM(nn.Module):\n",
        "    def __init__(self, T, img_shape, method='cosine'):\n",
        "        super(DDPM, self).__init__()\n",
        "        self.T = T\n",
        "\n",
        "        epsilon=0.008\n",
        "        if method == 'cosine':\n",
        "            steps=torch.linspace(0,T,steps=T+1).to(device)\n",
        "            f_t=torch.cos(((steps/T+epsilon)/(1.0+epsilon))*math.pi*0.5)**2\n",
        "            self.Beta = torch.clip(1.0-f_t[1:]/f_t[:T], 0.0, 0.999)\n",
        "\n",
        "        elif method == 'linear':\n",
        "            self.Beta = torch.linspace(1e-4, 2e-2, T).to(device)\n",
        "\n",
        "        # Forward diffusion variables\n",
        "        self.a = 1.0 - self.Beta\n",
        "        self.a_bar = torch.cumprod(self.a, dim=0)\n",
        "\n",
        "        self.img_chs = img_shape[0]\n",
        "        self.img_size = img_shape[1]\n",
        "\n",
        "        self.net = UNet(T,img_shape)\n",
        "\n",
        "        # Logging\n",
        "        self.logs = defaultdict(list)\n",
        "\n",
        "    def log(self, key, value):\n",
        "        self.logs[key].append(value)\n",
        "\n",
        "    def q(self, x_0, t):\n",
        "        \"\"\"\n",
        "        Samples a new image from q\n",
        "        Returns a tuple (img_after_noise, noise) at timestep t\n",
        "        x_0: the original image\n",
        "        t: timestep\n",
        "        \"\"\"\n",
        "        # Generate random noise with same shape as x_0\n",
        "        noise = torch.randn_like(x_0).to(device)\n",
        "\n",
        "        # Get alpha_bar values for the batch\n",
        "        a_bar_t = self.a_bar[t].reshape(-1, 1, 1, 1)\n",
        "\n",
        "        # Apply forward diffusion: x_t = sqrt(a_bar_t) * x_0 + sqrt(1 - a_bar_t) * noise\n",
        "        x_t = torch.sqrt(a_bar_t) * x_0 + torch.sqrt(1 - a_bar_t) * noise\n",
        "\n",
        "        return x_t, noise\n",
        "\n",
        "    def get_x0_pred(self, x_t, t, e_t):\n",
        "        # Fix: Properly index and reshape alpha_bar\n",
        "        device = x_t.device\n",
        "        a_bar_t = self.a_bar[t].reshape(-1, 1, 1, 1).to(device)\n",
        "\n",
        "        x_0_pred = (x_t - torch.sqrt(1 - a_bar_t) * e_t) / torch.sqrt(a_bar_t)\n",
        "        x_0_pred = x_0_pred.clamp(-1, 1)\n",
        "        return x_0_pred\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def reverse_q(self, x_t, t, e_t):\n",
        "        \"\"\"\n",
        "        Sample from q(x_{t-1} | x_t, x_0) using predicted noise\n",
        "        \"\"\"\n",
        "        # Special case: at t=0, just return the denoised image\n",
        "        if t[0] == 0:\n",
        "            return self.get_x0_pred(x_t, t, e_t)\n",
        "\n",
        "        # Get predicted x_0\n",
        "        x_0_pred = self.get_x0_pred(x_t, t, e_t)\n",
        "\n",
        "        # Extract parameters\n",
        "        a_t = self.a[t].reshape(-1, 1, 1, 1)\n",
        "        a_bar_t = self.a_bar[t].reshape(-1, 1, 1, 1)\n",
        "        a_bar_t_1 = self.a_bar[t-1].reshape(-1, 1, 1, 1)\n",
        "        beta_t = self.Beta[t].reshape(-1, 1, 1, 1)\n",
        "\n",
        "        # Calculate posterior mean (from Assignment 1)\n",
        "        mu_tilde = (torch.sqrt(a_t) * (1 - a_bar_t_1) * x_t +\n",
        "                    torch.sqrt(a_bar_t_1) * beta_t * x_0_pred) / (1 - a_bar_t)\n",
        "\n",
        "        # Calculate posterior variance (from Assignment 1)\n",
        "        beta_tilde = beta_t * (1 - a_bar_t_1) / (1 - a_bar_t)\n",
        "\n",
        "        # Sample from posterior (no noise at t=0)\n",
        "        noise = torch.randn_like(x_t) if t[0] > 0 else 0\n",
        "        x_t_1 = mu_tilde + torch.sqrt(beta_tilde) * noise\n",
        "\n",
        "        return x_t_1\n",
        "        def get_context_mask(self, c, drop_prob=0.1):\n",
        "            c_mask = torch.bernoulli(torch.ones_like(c).float() - drop_prob).to(device)\n",
        "            return c_mask\n",
        "\n",
        "    def get_loss(self, x_0, t, c):\n",
        "        \"\"\"\n",
        "        Returns the loss between the true noise and the predicted noise\n",
        "        x_0: the original image\n",
        "        t: timestep\n",
        "        c: clip embeddings\n",
        "        \"\"\"\n",
        "        # Implement here\n",
        "        \"\"\"\n",
        "        Loss with context conditioning\n",
        "        \"\"\"\n",
        "        # Add noise\n",
        "        x_t, noise = self.q(x_0, t)\n",
        "\n",
        "        # Random context dropout\n",
        "        c_mask = self.get_context_mask(c, drop_prob=0.1)\n",
        "\n",
        "        # Predict noise with context\n",
        "        predicted_noise = self.net(x_t, t, c, c_mask)\n",
        "\n",
        "        # MSE loss\n",
        "        loss = F.mse_loss(predicted_noise, noise)\n",
        "        return loss\n",
        "\n",
        "    def get_context_mask(self, c, drop_prob=0.1):\n",
        "        \"\"\"\n",
        "        Create context dropout mask for classifier-free guidance\n",
        "        \"\"\"\n",
        "        device = c.device\n",
        "        batch_size = c.shape[0]\n",
        "        # Create per-sample dropout mask\n",
        "        c_mask = torch.bernoulli(torch.ones(batch_size, 1).float() - drop_prob).to(device)\n",
        "        return c_mask\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def sample(self, text_list, s=1.0):\n",
        "        \"\"\"\n",
        "        Sample with CLIP text conditioning\n",
        "        s: guidance scale\n",
        "        \"\"\"\n",
        "        self.eval()\n",
        "\n",
        "        # Encode text with CLIP\n",
        "        text_tokens = clip.tokenize(text_list).to(device)\n",
        "        c = clip_model.encode_text(text_tokens).float()\n",
        "        c = c / c.norm(dim=-1, keepdim=True)\n",
        "\n",
        "        num_imgs = len(text_list)\n",
        "        x_t = torch.randn(num_imgs, self.img_chs, self.img_size, self.img_size).to(device)\n",
        "\n",
        "        for t in reversed(range(self.T)):\n",
        "            t_batch = torch.full((num_imgs,), t, dtype=torch.long).to(device)\n",
        "\n",
        "            # Unconditional prediction\n",
        "            c_mask_uncond = torch.zeros(num_imgs, 1).to(device)\n",
        "            e_uncond = self.net(x_t, t_batch, c, c_mask_uncond)\n",
        "\n",
        "            # Conditional prediction\n",
        "            c_mask_cond = torch.ones(num_imgs, 1).to(device)\n",
        "            e_cond = self.net(x_t, t_batch, c, c_mask_cond)\n",
        "\n",
        "            # Classifier-free guidance\n",
        "            e_t = e_uncond + s * (e_cond - e_uncond)\n",
        "\n",
        "            # Reverse step\n",
        "            x_t = self.reverse_q(x_t, t_batch, e_t)\n",
        "\n",
        "            return x_t      # (|text_list|, IMG_CH, IMG_SIZE, IMG_SIZE)\n",
        "\n",
        "    def log(self, key, value):\n",
        "        self.logs[key].append(value)\n",
        "\n",
        "    def training_step(self, imgs, clip_desc):\n",
        "        t = torch.randint(0, self.T, (len(imgs),), device=device)\n",
        "        loss = self.get_loss(imgs, t, clip_desc)\n",
        "\n",
        "        # Log losses\n",
        "        self.log('train_loss', loss.item())\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo04CKG6NoSe"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Idaf78ZGc_X0"
      },
      "source": [
        "This text list will be sampled at the end of each epoch, but does not affect the training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OC42EEI9yhLZ"
      },
      "outputs": [],
      "source": [
        "# Change me\n",
        "text_list = [\n",
        "    \"A man wearing a white hat\",\n",
        "    \"A woman in sun glasses\",\n",
        "    \"A man with green hair and a blue shirt\",\n",
        "    \"A sad woman with blue eyes\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29xs-z05P61u"
      },
      "outputs": [],
      "source": [
        "img_shape = faces_data[0][0].shape\n",
        "model = DDPM(T=300, img_shape=img_shape, method='linear')\n",
        "print(\"Num params: {:,}\".format(sum(p.numel() for p in model.parameters())))\n",
        "model = torch.compile(model.to(device))\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "epochs = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwNt_BAEPxFA"
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    losses = []\n",
        "\n",
        "    for imgs, clip_desc in tqdm(faces_dataloader):\n",
        "        imgs = imgs.to(device)\n",
        "        clip_desc = clip_desc.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        loss = model.training_step(imgs, clip_desc)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        epoch_loss = np.mean(model.logs['train_loss'][-390:])\n",
        "        print(f\"Epoch {epoch} | Loss: {epoch_loss} \")\n",
        "        sampled_data = model.sample(text_list, s=1.)\n",
        "        show_imgs(sampled_data)\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'clip_faces.pth')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if training loss is decreasing\n",
        "print(f\"Training losses: {model.logs['train_loss'][-10:]}\")  # Last 10 losses"
      ],
      "metadata": {
        "id": "OUVuzAsEeilZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MF6DDLvp_vgO"
      },
      "outputs": [],
      "source": [
        "# Test without text conditioning\n",
        "empty_prompts = [\"\"] * 4\n",
        "samples = model.sample(empty_prompts, s=0.0)\n",
        "show_imgs(samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkZDrwm0QEfb"
      },
      "source": [
        "## Final evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lR-7xU5RQENk"
      },
      "outputs": [],
      "source": [
        "text_list_new = [\n",
        "    \"A sad man with long hair\",\n",
        "    \"A smiling woman with green eyes\",\n",
        "]\n",
        "\n",
        "sampled_data = model.sample(text_list_new, s=0) # you may change 's'\n",
        "show_imgs(sampled_data)\n",
        "\n",
        "print(\"Final evaluation with different guidance scales:\")\n",
        "\n",
        "# Test different guidance scales\n",
        "for s in [0.0, 1.0, 2.0]:\n",
        "    print(f\"\\nGuidance scale s={s}:\")\n",
        "    samples = model.sample(text_list, s=s)\n",
        "    show_imgs(samples)\n",
        "\n",
        "# Generate unconditional samples\n",
        "print(\"\\nUnconditional samples (s=0):\")\n",
        "unconditional_prompts = [\"\"] * 8  # Empty strings for unconditional\n",
        "unconditional_samples = model.sample(unconditional_prompts, s=0.0)\n",
        "show_imgs(unconditional_samples, nrows=2)\n",
        "\n",
        "# Try some new creative prompts\n",
        "print(\"\\nCreative prompts:\")\n",
        "creative_prompts = [\n",
        "    \"A happy man with sunglasses\",\n",
        "    \"A woman with red lipstick\",\n",
        "    \"An old man with a beard\",\n",
        "    \"A young woman smiling\"\n",
        "]\n",
        "creative_samples = model.sample(creative_prompts, s=1.5)\n",
        "show_imgs(creative_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VklwAQXQd6-"
      },
      "source": [
        "As promised, here are samples from a larger model trained over all the images of CelebA\n",
        "\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAZwAAACXCAYAAAAh8e1OAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAOUwSURBVHhe7P1psyRZmt+H/Y778d1jj7hLrrV1dfesIEABNFKkZkhBJjPOmzGT6fPgywAyCkaANgMZDBBkECS8GAIQrdE903tVZlXud7+xh6968ZwT4RF5M/PerMzq6p58Ms+NCN/9bP/z7Kqu65oP9IE+0Af6QB/oPZOzu+EDfaAP9IE+0Ad6H/QBcD7QB/pAH+gDfSv0AXA+0Af6QB/oA30r9AFwPtAH+kAf6AN9K/QBcD7QB/pAH+gDfSv0AXA+0Af6QB/oA30r9AFwPtAH+kAf6AN9K/QBcD7QB/pAH+gDfSv0AXA+0Af6QB/oA30rpN420sDuaXVdr0tVVRRFQVEUVFVFbY835+ye+90ihVK72yzJDrtfKQfHUTiOAyhc18FxpCilUMru+wb0ymfZoVdV6VXnv+rYXbriXNXYaNs6yzLyPKcoivX2b0ZX3Jjtza84YouufIorN+5S86DmnXZPvs5TvE/afZ73QZs+r5TC9308z8PzPNTOQCmKgjzPybKMsizfQT94SzLP1Xw6Zcal4zg4ZlxqrWWsmjH68llvoJ1Db3DmbyW9qjVv8t5vBTi7p1RVRVmW67Jarbi8vGQ6m7Fardb7q99kJ7w2bQZYsyrt7w2QKFxXrweg67oEYUAURQSBj3alM3ueh3LkHHOF9TWvTW865U1V2jz/Tcfu0hX3tu9QVRWr1YqTkxPOzs6YTCbvsH2vuDF2s7L/zTbz7YpF0PaG7Z9X0+5B9i672y294jnfO73qed4HySLM8zz6/T6DwYBOp7NeWGHqejabcX5+ztHREcvlkqqqdi/07ZEyvdSMV8/z8H1fxqvvEwYBrVYLPwjQrkY5Cscce6NRunPgtc/7LaM39bbrvvdbA05tB3QNeZGzWq1YLpcsFgsuLi74xS9+waPHjzk5Plnvzwz4bJ7+xrd+D7Spqs2KzXI5zU/pkK52cRwXrV2iKKbTadNqtfEDn+FwwP7+Pr1+T4DH90niBO1rXMfduocdDLu0vcX8evmwbXplfe6eL+11Pdo9d0N2OBZFwdnZGf/pP/0nfvzjH/Pll182JpkrTtwi+yCvOu6K7cq0hzKAYycIe6h0ynX/xPTPrep5Y3e/an/zBrt0xXN+K3TVs7wvkgVWq9XiD//wD/m7f/fv8v3vf47v+1uA8+jRI/7mb/6Gv/qrv+L4+Jgsy3Yv9F5pi+Oy40wpXNel1W7T6/Zotdt0Oh0GwyEff/IJvV6XKIrRZky7jrsBK3upl75cve2Kn78z9Kbedt33fnvAqWsqM5hXqxWLxZzZdMp0OuXFixf8r//xP/Lzn/+cR48ekWUZi9mcxWJOVVY7K88b3/4d0qaaLLBgwEU+zaRmAcdx0J7GdV08z6PdbjMcDukPBkRRxJ07t/noo/sc3jokSVPiKKLTaROYVZS9zxawXdFU2zjUXMrv1pXZIbPrzr53Qc17N7fKxizLeP78Of/yX/5L/u2//bf85//8n0WE+o0f5aqbmrpylGgeLadpQchiSUO0WwO2k5pfbwE6u8/yun3fNr3pPd4FyTs6jsNg0OdP/uRP+If/8B/yD/7B3ycIgrXIuK5rfvazn/Hv//2/5y/+4i949OgRi8Vi51rvj7bBRv4opVCOg3Y1/cGA/YMDhsMBw+GI23fu8Md//Mfs7x/QarXwtMb3PLQ24/SlcSjUvI+5zRZdccrvBL2pp133vd8acKq6pq6hqmuWyyXT6ZTLywvGl5c8efqUf/fv/h0/+vGPefDgAdlqxWw6ZTGbU1XfZbGaMh3V2eJs7MRmRWSu6+L7Pp1Oh9H+HqPRiDiOuf/RfT777FPu3L1Du92mlSYMBgPiOMbzvPU17CBdA9sVzbXV2ZV6TZOra0yg34CuGHX2eVerFY8fP+af/tN/yl/+5V/yV3/1V99QjLL10o3v5rdS4MqnckzNGfEmdiFUbQCH2nLhDTbnjXX1pv1X0e6zvol273GT83fPfdW269Dr+pUleTbHcRiN9vizP/sf+fM//3P+9E//hDAMtwDnRz/6Ef/qX/0r/vE//sd8+eWXzOfznWt9S6QQ/arrrsfs/sEBd+/eY//ggIODA+7du8f/7u//fW7duk2n3RaRm+fjab3u8uqK7m/nhfXf3f3bP39n6Hq95M30zTTaZg6oqnINKpPJhOlkwnw+Z7lYkK1WZFkuSkQEpL7rVNeWCzMTlzw5VS26KFGOZiyWC8aXl5yenHB8dMTTJ094+OAhv/7Vr/ji17/m4cOveP78OcfHx5yfnzObzcjy3HABN6mL1x34un2/C6RAObBliGEXBdLNq6qSOt0Cm2ZB6mld4dKmbyZ1zXITuuq+V23bpVc981XbrkvXOXf3mN3f3z2yYjTf94njmCRJ6PV67O/vcefOHW7dusVoNCJNEgLfR2uRWjgvocvOz8bvm7b6BxJ6a8CRCq9RQFkULJcLLi8uOD874/z8nPHlpXA18wWr5ZIiL9aT93eb5Plk4qqAirquqOqKqiopipw8z1iulkwmY05Ojnny5DFff/0Vv/zlL/nxj3/Mf/qP/4n/7f/3v/HXf/3XfPnllzx69Ijnz59zfnmxVqauJ8YPdAXZ4Wy5GbEkUsYKUH6b1Y5ZFNSVWMzVVQWlfNZVtQ08L03ar6v/79KUsvvMV73L+yR7n93P7yAZkbX2NFEU0W636Xa7HOzv89FHH/GDH3yf733ve9y7e5dup0MchSJKc11j3GMus9v8H8DmndBbAw4N0ClLAZzxeMzFxQUXFxdMJ1Pmsw2XU5YWcH4baDOg61q4Gws6ZVlQFDnZKmM+m3F+dsbz5895+vQpDx884Oc//xk//vGP+clf/4Sf//znPHz4FU+ePOXFixdcXlyyXCzW1nyWk1rrF96WfldHgJKRb2XxNMBGuBzTSg2wqQ3YiO6mCTSvoqv2NQDvjeXbpKue9dui3+S9r0nrZlNovQ04o7097t69y6effsrHH3/ErVu3aLfahEG44XDWou6tq766mV+1/QO9kr4R4Fiqq5qyKMmybG2Nluc5ZVFsTaw3kCH9BmjTe8w8t7sZBII2AGT8jex7L5dL5rM5k8mEyVhEi9OpLYbbW2XkufgolaWIgWQsb0DuJWruuqpgHvhV5beSZEJXyLs1fjWoUVdr0dk3JGUMJXZvdSPabaDdxnod3fTGNz3+d5lML1EKxxGRWhiGhFFEFMdEcUwcx8RRLEDjieuCNYfeGvfNS+5So3/Yr9+4y7wX2u17b+qHu8e86fib01sDTo0VO9XkRc58Pufi4oLz83MuLy9ZLBbkhXA1Mqm+u4d+d2QNAhxcR4p2xTzSftqVjxSjO0Am8hoxmrB+RqvVivlcAOf8/Jznz1/w4MsH/PIXv+QXP/8lX37xJV9//Yhnz55xdHTM+PKS1WpFURaURswmdMO6uuHh32lS1hLNiNJ26x+xPBNOpgajuzEd0tTFFUN/d2YwWCyOu5ZjahpwXHENeMVAvGrbTWj3nrv3ftP2D6QUwvm64tAZJzH9wYDbt29z9+5dDg8OGPQHtFtt4jgmDMO1r9wabK645vr7zud3n27aD296/NvRWwMOdU1VScmynNl8ztn5OSenp5ydnTObz8nzXMQcN1KQfxsk3UsBjpLJzHUFXLR20VrjeVo+XQGfTRQBMxHuLIXquqYoChaLBbPpjPOzc54/e84vf/Er/uavf8pf/+SvN6Dz1SOePn3G+bnodGxEBqvbsde7Pv32DIM3kswcG52Na9tGFgQKoK7EidiCTXXVXG+mkDWXt+Fc1syfAZkm6Mgx5vMluqpNrtr2OrJTW7PY7bvHXfV797wPZNvMccQyzfN90jRlb2+P+x99xMcff8zt27cZDge0Wy2SJBHAMZEGGpfY1K6p3te10Ae6Ob0V4KwV3uZTJtol4/GYy8sxk8mE1XJJaTmc2s4I3zEyM49dQbvudtH2u+F+XMdBKacxY0kXtPVRFMUWl3NycsLjR4958OUDvvziS776+iuePnnKixdHnJycMJ5MWGUricJQVWJqvvuM8Iau/rp9v52k1hyOFMe1bWTqu2rqbZqWaK+g5ixiStPizVn780jZOm9NzRt8E27mKnpVG+5uX7/Izr7d4/72kbTlZvEYRRH9fo+DgwMODw/Z29uj2+mSJClREIp1mrFMW9ufrK/1oYbfF70V4GAm2aqSlWZh9DeLhUQaaK7av2u0WdE2gKQBLMLx2IlHupnobCyXtgHaXbJ1UpYleS66ndlsxmQyYTwec352zvHJMS+OXnB0dMzZ2Rnj8ZjpdMp8PifLsq3wP28Wsb1qGDQnxPrVh72R3vrEtyC5l530LRfZBACrBly3xUtz/gY05BoN0GoAS5OjcRyFK/YIOGYtIe1vJqH17Xenn926sduaZZeu2vYmeptz/naR9cfSWhMYvU0Ux6Rpi063S7fbJU1TAsvVGDHt1uJifa2XaWtb45yrjv1Ar6dvBDhlWVKUYiqcZRnL5ZLlYsFqtSLPv3uAYyci13FEP6NdPO3iuS6eK/obEdtsZPkCIqbUhgtplvXVt2c/qZ9qHcxwvphzfnHOs+cvePToEY8fP17rck5OTri8vGQ+n6+5nZdBp0mvmtDYnYHBHt0UJW0zaDv0ugnzTXTTc3bupTacjWNNoFHbVmiWm2lWd+N0pYws34KJWUyIaM5BuwrXUbiuQrsK7YDrym/XoQE+G7BaL4HXCLRbnCu2Nd6r+ZBX0stttk1XXe8DgVSJUuA6DoHvG6BJaaUtOp0OvW6XXq9HmqQEvkRGUMqwMNgxIHW70eTYGcAseHYGzIeWeHu6MeDYibYsS3JjobVcLpnPZ0zGY8bjMZPplCwzcdO+E2S7iExi2tP4nibwNL6vCXxN6HsEnot2xWoFZB6oGsBaFiVVaZ0MG34eWxOGBQqxYFuulszmcy4vxzx+8oRf/Pzn/OhHP+I//+cf89Of/oxf//rXfPnlA54+fcrFxQWrVUZZVlTGifG3j95iKErTGP9OhatlQeBoB5wm51hRlzVrCW1t2tU4hmL0Pq421/CkeJ6D7zt4voPnuXieg6dN8Rw8DzwNnlZordAatBYgEuBxUK7asEFrdugNhWbZTGa/vVPWd7Q/Og6u5xEnCd1ul+FwxN7eHgcHh9y6dZtbt24xGA5JkmQtRmuCDjut8dvYMr8tdGPAsWQnYut5b02DV6sVWZZ9h0RqmwEui5RtUZpuiNQ2qx9Z61jRjVii2XA+Fgh2l9lNssdVFGVJXuQsVyvG4wknp6c8f/6Co6MXnBwfc3p6xvnZOePxhPl8sUnpYH10rgSdN91/Q28cPK874HX7XqIbHXz18euFpOEumu3wUhSBl199fa5SOK4BL8u9GI7G1Wqjm3NBuwin44Jry5pDslZsm+tuYcUaWDZ9bOuAK17x3dJ7v8FvBSmjv/EDidYu0QVSWq2WlLRFHEVbKRU2MoydWnxDlb5h93eIXvekr9v3fumtAEcmgGaYl5zC6CyyLKPITSibKyfLb5MMk2zELFuyfKPHsWxyXa89bIwIx0xwjYnO6g9emumuJHu+6LnKLYMCMa44v7jg7OyM09NTLs4vmE6nLA1g53kuK/pXgk6TJOLDVeVatHvSjU6+Ke1cfH0/s60humANqa8GemWtqB1wDGBoDa7hUnwPfF8RmBL6ijBQRAFEgSIKmwXCQBH6EPrgewpPW1BqgJNjwMsRcLIAJSBpXgFeFsnQ+G7f+cb1vHuC/b27/W8BmTpUSuFqTRAExHFCK22RpglxHBNFEWEY4vk+rutuFg4vXefqKmzuumL3d5x2n/43/xZvDTiWq1kul5KWYLlgsRSDge+C0YBUbY2jZFLwXLuy3cj3Aaq6IisKllnGKsvJspy8KMiLQsRo62Cj1pfoTZN/kzbH1yZKgdTZiul0wtHREQ8fPuRXv/41Xz74ksePH3N8dMTZ2RmXl2NWq6UBnVfpcn4XSJlEdg7KhIavTR+rKgP4lQD3Wocjp6GcWgDGA88D34cgrAijijiqSdKadqum26npdWsGPdgbwP5QcTByONxzuLXvcHvf4da+y+HI5WDgsD9wGPUc+i1oJzVpWJGGNWkISQBxoIh9Rew7xL4i8hWhVvgueA5oJbog0QdtAEms7TaLHfu5FapndzK8kl51zKu2/w5Sg5t1XZfAD+h1u+zv73Pr9i1Goz067TZRGOKbeGmvMhT4QN8evT3gGEfHpcmBs1gsWC4EbFYrMfX9TU2SFscdwFFmReo4eObTseIaBWVVkRcFyyxnmeWs8pwsz8kLsb5bK/BvDDZNktV5aYN+LhZMJlOOXhjA+ZXocR4/fsLR8cZ6bbmUegQjRfoN1ed7pbVF2cZIwGJ7XRtDDWsyXtcS207VoGqUU+O4Ndqr8fwa368JwpowqoniiiSuBHDaNf0uDHow6iv2h1IO9hwO911uH7jc2hMA2h8q9vqKva6i14JOXNOKIA1rkqAmCdQW6ESeQ+QpQk/hO6AbxTXBrR0F7hXWcdaM13E3/VHqZKeOrqTmQa/6/rtLlnu0ZtBBENDt9tjf2+fw8BZ7e3u0Ox1CAzie1rjG5wbpdh/oN0BvDTgyeUpitd2S/YZSzK5BBjvQN+IPz1XGEq0hAlGWWxMz5jwvBGiskUAlgGPsob8hieLbih4X8wXn5xc8e/qcx48e8+TxE54/f87JyalEaxiP15xi/ZJI73V0s5F0s6NvfvzryVgCOeLftPZxEhZH3rnJ4RixJ9QoI0ZztXA42gM/gCCAKKqJYkgSaLVqOh3odhDQ6StGA8Vo4LA3cNgfuuyPXPZHmr2By17fZdRzGXQdei1FO1a0QgzoCNgkaw7HgI7vEHqKQCt8VwmX0wAdbbgc13I5zbLmcnZmQbtqei29CmjeeOJvN5m6WQOO1viBT6vVZjAYsLe3J5ZpaUoQBHietxVVYLt6fsfr6tr07dTDWwEOJiR8UUhMsKIoKAsxILAcwca0900T5DenbaBReI6D77gEroPvOgSuS6BNsZyOAheFu2VDJLoQoff43HVtDAo2oL1cLpnNZozHl1yOxXl2sVwaXc6uqfTuBXfJzlabt9qUXS3I7tGvL++HGroOWHOEV72oQjUMxdRaZ6O1iNWCQBGGijhSxLEiSV1aqUOr5dJuazptTbftmeLTbXt02j6dtken5dNueXRaHu2WRyvVtFKXJHFIYockUsThpkSh6INCK1Yzup/AVwSeI8V38D2FrxGxriNlY5iwzXFLPTQMEdSbWqC57VXH/I5RLf1AOQ6u46JdjdYeQRCID04USdJDrV/W2ay/vqauXlfdv9O029eaZXfm2J1Frkc3BhwLJnlRGHPoueS+WS7FaCDPG5ZWN3uYtyEHcAGtFL6jCF2H1Nd0Q49e5NOPAgZRwDAO6Yc+ncAj1S6x4xA5ikApPCXA46JeMmB9t7RppKqqyLNMMqXOZ5ydnfP06TN+/esv+NWvfs2DBw85Pj42ojWp22bE7XdVte/oMm9xJZlM7YSwnnCRl9s2OzdnKDFV1q41dbbgAmkC7bai33PYG7ns77scHnrcu+Nz/17Ax/dDPvko4tOPE773SYvvfdrme5+0+eyTDt/7uMtnH3fN9zafftTm049SPrkX89GdiI9uB9w7DLi9rzkcORwMFAd9xX7fYb/nst9z2Os6DDsug7bLoO0waDv0Ww791KGXOrRjx3BIFpwcAs8Vc22vEbdvnYLhVb3vqu27vfX99eDvCinHwdOaIAwIo5A0SSR19GDAcDik2+0RR9GWocAW8Hygd0jXH/s3BhwM6BR5znKxYDabif5mtWRlrKvyYpNk7H2SHVLagIavHCLXpe3rDdjEAUNTBnFAzwBO4hrAceRcbUDHckrvb8jK6r2qSvI8Z7GQCNPn5+c8ffKUX//61/zyl7/kwZcPODo6YjyesDDOtEXRMGD4TtJ1n61Rq0b0uQ4vQwNwJIYNUK/NWB1HfGV8XxEYK7MkEfFZp63o9x329jSHB5rbtzT37vp8dD/kk49DPv045nufpHz+aZvPP23x+WdtPv+ky/c+7fL5J10+/6TD9z7pCBB91OaTewkf34346E7I/ds+dw88bo2MccHQ4WDgcGBAZ6/nMuq6jLoOw47DsC1lYECnmzi0jEhuLYbzhQvytYOnTbw+13I8GwvKl6nZO68q9pjmsb9b5DiO4WpC4sgmWesyHA4ZjUb0ul2iKBZRWiNZ3wf6zdJbA45Vtud5vi7rmGCViIyuN/m8HW2Gk8IxojERpykC1yHSmthziT1N7HvEvibypASuiNU8pdBYsFGi2P1WhqgxIigFdDITiWA8GXN6esbJySln52fMpjOWKxGrvcnqr76W+fR3jBpzZHMFWiOgIzltGt3IgJLVh2hXnDSthVoYQhxDmipSI0brdFx6XU2vq+n3PQZ9n+EgYDgIGfbDzWc/ZNCTMuyFDHoB/Z5Pv6vpdly6bU275dJOHVqJopU4tCJFGpsSKcPBOFJCh9iWwCH0FYGn8LUUzziWij9QQ5ejBGyUBd8b0e4Zzd+7+367SRlDE1drtOfhBwFhGBHHCUmcEIWhSRfd4Gy2qsB2rJuWv6W0Ww1vWSU3BpzaOH0WRvdgY6dZQ4HSRvF9T5OfQlbErlJoJTqaNPDoRgHDJGSvHXPYb3N31OXuXo97ez3u7fe5vz/k/t6Au6M+dwY97vS73O63udVrcdhJOWgn7LdiRmlEPwrohT7twCPxNKHr4Bvdz7sEJQEJscLKM0nxcHl5yfn5OWdnEnn75PhkHfpmsVhQvCEKwau2f+eoWXnGGGCtt2n63NTGx8haexmdTeBLSSJFK3Votxy6bZd+12PY9xkNAob9gEE/ot8L6fViut2YTjeh3Ylpd2JanYS0nZC2U9JOSqvbotNr0+m36Q3aDIZthqM2+3tt9vZSRsOY4SAyIBXIfXoeo77H3tDjcC/g9kHInVshdw5D7h5G3D2MuHcYcnc/4PbI59bQY7+vGbZdusYgIQkUkQe+rtcGB44yvmN2wrxRZ3tfQPMur/XNyHGcrRTSSbLtd2NNod89Z/NbMr6+TbpBlbj/6B/9o3+0u/F1VFcVWZZxdnbG8ckxl5eXHB8f8/z5c548ecxsNqcwuob3Mfk5ZsLXSqzOIk/TjwP6ScggjdjvpNwZdbi712W/12Z/0GF/0GV/0GXQadFNEzpxSDeJ6KQRaeiT+Jo00LSjgNjTBNoh0mJ0oB1ZabrORuTTfKu3786bM5WqzeoWE7etwnUd2u02WmswIB8YT+otnccVA+qqba+j7aOvc64cU5Yl4/GYn/70p/zyl7/k8ePH12jzhiLccjbOJpxQbcRpAjyNs5Q4XvqBIggMNxMpOh2HXtehnboM+h57ez77+z6Dnk+vGzAaxHQ7Ee1WSJrEpGlMnMQEYUgQRYRhjBeGaD9A+wGeH+KHUrSnCQKPMPaJ44Ag0IS+QxJp4kiTRpokckljl3bLo9vx6XU9+j25f7/rM+z69Dse7USTxg6dxCWNHELPwXXAc8Ez1pICtNIfbF0I2Jg2eVPVbtEu6Nzo5JdIKUWSJHz++ef88Ic/5OOPP35pQn/+/DlffPEFP/nJTzg/PyfP861rvEsKwpA0Ten2exLOZjTke9/7nqQhGAzxfQ/f24DOLpezVTs7Xb75++rRcPXWv8103Tnn5oBT12RZxvHxMc+eP+Pi4pzj4yOOjl7w9OlT5vM5RVHIhPEeyDH6Fs9xjIGAx2E74aAdc6ubcmvQ4dNbAz69vcedUY87ewPu7A25tTdkv9dhr9uin0SM2gmDVkI38mmHPu3Ap2cAJ3RdYs8AjpIVuPhUbJwSa9MxbTivtydZyddGxJYZPVhVVURRRA0URYECkiSh1Wq9URF61bbX0fbR1zlXjvlGgGOeURkxGbZeG1yOnSMdJIS860IYiZFAHEOSKAY9l9HQpdtx2R953DoIuHMrYjQQ7mZvmNLrxrTbCe12QtpKSdKUKI4I45ggTgiiGD+MCcIYP04Ik4QojoiikCQNabVCWq2AOHSJA4dW4pmiaSUibut3ffaGIfujkP29kP1hwMEw5GAUsD8I6LU13dSh33JpRS6Rp1BVheeA59QmRpwUR1kTeNPJFBv7SVN3ZvO6XE3NPW9ql9fTtwI4tl80+serKI5jOt0ue3t79Pt99kZ7fO8zAZzBoI/neXjaMwkUG9ey1bjZ0riV7ZONfZuvDbp6699muu6cc2ORGmZiKMuSPBOxWtaInbaeMN4TKRM+3nOEwwk9TRp6dOKAXhLRb8X02ynDbotht8Wg22bQbTPsthn0Opvv3TbDTsuUlFEnZdhJGbYTBq2YQRrTSyI6UUg78El9n8T3CLWL77p4jonDZriea9b3K0nMzDcm0janzsXFBRcXF8ZMWmKtNc2k3zzB79I3fNB3QQ2wUcbtZk0WaJrFPLVSEt1ZuxJoM/AcwtAhiYXLSBNNK/Vop9qYNXvEiU8UB0RRQBBK8UMfL/DxggDPD9B+iA5CvDAiiKSEcUycxiSthNSI3lrtuFFCWu2AVsun3fZpd3y6vYBeP2DQD6UYXdFgEDDoBwx7AcOez6Dr0Wt7dFuaTurSjl3S2CEOFFGgCD0HX9sI1tag4opBrdiupM3G7y5ZrrbhtKmNHsbzPHzfXxfP83BtOoFGSgF7ru97RJEYDURRhB/IOVprWZTZ/EnN6qntn916W+/8QO+R3hpwinWYFokskJvsnu8TbDAWTZ7jEGgxCEgCj04S0W8lDDop/XZKt92i1UpJWy1Z0bYS4jQhSWWF2+q06HRadLpter0Ow36X0aDL3lBEbweDLoeDHrcGXQ57bfa7LfY7KaM0pheFtEOf1PeItIvvOGglhgtrK6u3oNqYSgvwSN1Op1MuLy+5uLhgPBkzn89ZrURfJsDzXQOd61/31UdaLnIz/GXBq4TLdMSfxdcSGy0OHdJY00o0aaJJY4849oljnyjyCQIzefk+2vNxtY/j+jjmU7kByrXbAlwd4uoI14/wghg/TAiiFmHcIkrbJO1GaaXErYS4FZO0IuJ2SNIOSdoBSTsk7USknZBWN6Ldjej0I7r9iP4gYjAMGQ4DRsOA0dBn0PPodz16BoSSyPjwaHFadl0BZ0EeW1ebXEdSa6+i1+379sgCheOa1CC+RxAGRHFEkiSkaSopBXo9ur0erXab2GTnFAdOH9eAieeJ342clxAnMb7xvbERHJoAvRki26Lal+tm9/cHepd0Y5FaVVUsl0uePHnCw68ecnR0xOnJKacnp5ycnLBava+0BMJmB67oW/pRQD+J2OskfH57j09ujbh/OGR/b8D+wYjBaEjabpO02sStNlHaMiKUiCiJiVsJabtFq53S7rTp97sM+z2GvQ57vQ6Hgx573Q7DdsogidhrpQzShNB1iVyX0HEIXReFZJ9cI7dSdj3+2mn1ZTLHGrm9oxSudte5hjxP02m3abXbRraPOL1pEa/RALuXVsJX0uaY7aOvf+7LIrUn11hvbMSAdrUqv8UUwwZPrc1dHGM96Drga0gTRSuFdurQabvcOgi4fStkMPDZG0Xs7cUMRzGtVkQcR0RJiyCM8fwY7Yc4OsLVIcr1UU4ITmg+A/MZoVzZptwQ14vRfoIOEjw/wY8SwrRNlCQEcUSQhEStmKiTkHRjok5E1DbbWhFROyZKI8JWQNzyafVCWp2QtOPT7ngM+iH9fkASa9J1ETFQXRkDAkdkt9UGXbYnRtPVpC43m9/l5KmUIknitxapKSU5jrQWLsYz6QQ67Tbdbpdur0u/3+fg8IC9/QOGwyHJOlKATxAaR04DWN1ej8Nbh9z/6CP29vfZ29vj7p27DIZD0jQ1Y2gniZ9qOHY3cHt3vDR/Xz0art76t5l26/BV9FaAs1gsePzkMQ8fPuTk5ESCTV5ccnZ2RpZlb7HifhOtRxSh1rQDj34U0I0Dhq2Ez26PuLff5/Zen163Q3fQp93vmUkhwY9j/CjCCwP8IMAPQ8I4JEoiojgiTWPaaUK7ldJOYnqJiOU6UUgaBiRa0woDEs+jLitUXePWUslFWZEX1RaTvg2312sIITlWMEtWgxLPrSSKIgbDIf1+H6UU2tX4voghHBP1+lUD6NV0FUf28paXSY7ZBpxfXVuHYydGpRQoEz/NPLNwbHbxbnQ3hrvxtYCNgI5Du+VycOBz6zAQZX0/pNcL6fUjUfKHIX6QoP0Q1wuFi3EDHCdAKQ9UIICjfDBFOYEBH3OsDnC9CNcTwwLPj/CjGC/w0YHG8zV+5BMkIWHqE8Q+QeLjRwFBHBLGAX7sE4SaMLYiPk2UaOJQ02oJZ6YdB99VBCZPT1HUZJlATF1DWUNhBAhqDSW7dd1sO7vPfl6nXV9NAjhvqcMxbe24rslF5aM9TZzEtNttOh1ZSHW6XUZ7e/QHfdqdDlp7a38kz/NAiaW8QtHtdTk4uMVHH91nOBzS7/XZPzig2+kSx7ExLZdj149oPpV9Jrv5RoDz8pYP9HIdvopuLFKrTaSBIt+E218tRY/z5snmm5LItH3tkgQeaejTjgN67UR0Mr0OvW6HdqdNnKaEaUqYpAR2NRonhGlK3GqRdtqknTadXpfeoM9w1Gc06rO/N+Bwf8jt/SG39wfcGfW5O+pzd9jj9qDLQTdlvxUzTEL6YUDLiNYiV8LmaOWYiAVXTeZvIplpbf3O53PGYzGTvri4WKejns1mLFZL8qKQoJa7l7kmyfM1n/LmT/x21Hzi7eevzZ/1NoNFjom+7LkmlEwg4rRWrGm3fDptn1YakCSirwmNvsbzA7QX4uoAx4jPcDxTNkAj4GMAyIlQbozjJbh+Cx208cIOQdwjbPWJ2rb0iNodok6HqN0mbLUIWylBmhK2EintlKidknRbtPot2oOU7ihlsJeyd5BwcJhweBhzuB9xuB8ZIwOffkfTNhZtUeDge84mHtsan9/Udrs946pj3g9ZzsKKt6wYLIoiklSMXzqdDr1+j8FwyGi0x/7+PoeHm6Rp+/v7Aib9Pr1en05HUkXHSbLOd9PpdOh0OrTaLcJAUkjbe79yBDY2X3eiFLrJsR/oKrox4AhtjAayleTAaYZdeR+kAEWNdhwCT5OEAWkcksTCpYSxWBj5UYTrhyjPR2kfpT2UthEebdAt+a08E9feE+9B5Xk4vo8b+Lihjx+HRGlE2k7otFP6nZS9Xptbwy63h11u9VscdGL20pBREtANPRLtmOgFYrr9lhUs6QyKgtwktpvP51xcXopvzukpk/FkLb7c1eNYLsEWqbuXy4Ze3vJt0HaCbmuhZjfIF8UGbLSWWGlx5JAmLmmsiWNNFHlEkU8Y+nh+sAEX5RtQ8QBv84mW70qD0tTr754BH/sZgoqACFQMTopyWjhOB0d3cL0ubtBH+31cr4frd1FeB6XbYIvbkqJbKK+F8ts4QRsdtgwwpcTtlPYgoT+KGO1FDPciRqOQ0cBnbyhm1WksAUJ9k5/HtYEIFPLFfr7Uyrtt+/7buQk2vu8TRzGtVotet8vB/j7379/n448/5pOPP+HTTz7l008/5ZNPPuajjz7i7t273Ll9mzu3b3Pv3j0++ugjPv5Y9t2/f9+Ue9y5c5v9AwnS2em0TaBOH9c1nI157SaerKto/f3lungZpK6qw999WucGM/+29n2Def6tRGqz2ZyHDx/yxa9/zdGLF1xeXjKdzphOp2I88A0e6CoStlgm73boM2rH3Bl0xLqs3+HenQP290b0+l38OMFLWugowfECAR7PhBOWvMGodXpHbaNAguugjGWL4zo4nhbFpnYJPJcoFCV06Lm0Ip9OHJKGHp5SeKom9bX4Uxg/GsfoWZpz6NtQVUmDB0Gwzlq4XC7xPI8kSUmSBNd1oTHQhTYD5Ipx9Q1JLviyDue6IjU7GTQnSiGb8A6jH9eueOV7noSx2RuIGfRo4NHv+9y6FXN4mNBphyStmDhNCOMU7YU4boTjxqAM+OCj8IHAgE9ITQjYfQEQyn58811ARxECEUrFKJUaXU+EoxMcr4Xrt3A84YqUTnDcFOWmKDcBNwY3QukI5cUoHeL6AW6g8SIfLwrwfJcodkkSTRhr0yVrUvO9KGtWmSwulIKqEt+sut5p7622bv541ffrkVKKJEnfKFL78ssv+clPfsLl5SV1XYtTZipxzvb29vjk00/4/PPv89FH9/n008/47Huf8dlnn3H//n0Bm7t3RY8zEjAZDAaMRiMODg4YDAcM+n1GoxH3799fg9BgMKTTEclGFEV42pM5Y+v5t6votWDT2PUyAP3u0y7ANKk5vpt1eFV9XkVvCTgzHjx4wK9+9StevHjBeDJhPpsxm88l0sAbJ52bkDS5YyzUOnHAfjfl7qjLqNti2Otw5/YBo9GQTq+HjmN0mOAEEY4nHI5k6DJpIE0eYQEdcelWTcCx8ay0KOQ9zyXyXWIDOJHn0ol8OgZ83LrCqUoS7VJXNXlRkhfleoVemuZ7mxqxabzruharnDDEdV2y1Yoojul1u8Y51NsaRPLZ7AyNi74TkgveHHDs88lX+WyAjq0oU1xHmsv3Fb4HUaTYH2n2R+LZ3+36HBwk7B8ktFohcRoTxqLYd7VV/kcoJQCyBhuEi6nXoGK3BwZY7G8DOKYoFaFUgnJilBs3ACfF8RIcL0S5Io5TboIyQIMrIKN0iPIiHC/ADTz8UOOHHn7oEQYOceySJC5B6OIg/jhx6FBXsFyVzOYlVWX6VVlTmeg/zSV9M975ps7ttt3v1ycBnOvpcP76r/+a8XgMQKvdom0MAw5v3eLzzz/n937vh9y/f59PPvmETz79lI8//pg7d+5w69YhB/uH7I32GAwG9Ho9+n0Jxrm3t0e316HT7dAf9Ll1+5Y55xa9XpdWKyWOE3zfx3Wsn5qtmo2Irbkos7UhpVEfW19vVk+/y3TV2N6ec95MbyXxqa0ex+aNsXG+rnigd01KSfwp39P4vsbzxIZfex6up3G1h+NqlOOilGuyKRoTSUGtNVdj92Ht+81vx3VxtBTtifmm73uEgUccBaRRQBqbz9CnFXikvib2tfjpmBD0Wm0HAr0J1TVU5SaNd5bl6xQGs/mclUldYE2pZbVrT969WKN8K7Q9lF9VA3XTx/MV7lvSbLWs+E1YG9+T4J2+J7oNzywM1hGXlUY5WtrfatSUI2H/beHqUuNSoxufUtZiNsc3up4A5USGi5KijMWbFKsTCnbOMWbY2sfxPFzfxwsM6MQeceIRJ5oktabeLnEsehwbi81zxXLNTqbrun25iht01c6rtn1zspO64zjrhVJkQtBY8On1emL+3O3S7XaFQ2m3abVapKnoZ6xBgRzTWR/b7XbptNukaUIUhYRBiO9JCum1ZdrW89gvjTfeoNEOOAnI2H+/u7SzunvDJLEr/n5bujHgWH3BOvCk8cEp3jlnY8nE0rKcjqPQ2iXwPQLfxw/Ev8LxPNHXuGI6uY6220Be1ZzZKvlUdY2qxfJMVebT/rb3Nhgl+iOXMPRI4oBOGjLsJhz2W9watDnspuy1IkZJQD+SWGyhdjf5d5od/o0k9WzrOlutmIzHnJ2K+fn5+TmT6WSdGiLPM6p1Omwzm3+XyYqCTB+3orS60eeV9bvxJG5aGCiSWPQ37VSTppooMgsPrXFdD8fxjPisoa8xySdeLtoUe5w9xzNcjv30DTe04XoU0YbjUakpbZTqmM8WSiWgEtH/qAilLKcUGiMFMWBQrmfEaxo/0cRtj27PZ7QXcLAfcbAXsj/y2R94DHuabksT+Q7alZBAtou/ucmv3/vehgRkBPQ9T+KcjUZirvzJJ59w//59bt8WY4CREZm10hZRGBEGIYEf4HveuoRhKCDVEv+cQX/A/t4etw4PJclat0cSxwRBILHTTFSBBr5sVt47Y+/91sTvGjU7lnx/W9C5MeBgQKep0M6yTLict3JCfD3ZCd9+uo6D52oBnEAc+7TvoTxfRGdWbGa5GcxINEXVlQGWElVVUJrftpQVmE85zhSzyvY8l8BwOp1WxF4v5c6oy91RlzuDNre7CQftiL1UQCfWDqExIpD0BwKf1yXLTS6XSy4vxxwfn3B8dMzp6RmXl2OmsymLxZzVVlrv3xTovO697HvbeED2MRsgU28/s1LSnIEHYQBJCGks5tCdtkQUiCPpC54nSbicpuUZfgNcLBezCzYWaLYB5qpSG7GbBR5FDCQoUhQtFB0UXVM6ZltiSiw6oLWOKDCGDBocjeO5uKGLF7tELU1vEHBwEHHrVsTtWyG3D0Ju70vwz2FPE0cuvgEcsYh8uV+9vMVufT+klINrfG2CICBNWxweHvLpp5/ywx/8gO999hn37t3j4OCA0WhEt9sjSUQMprU2EQIcXBPFI/A8YhMzrdNuMRz0OTw44Pbt2xwcHNDv9UjihDAQoNKuK2GSGqI0ea7NW19dJx/o1fQy2DQGa2Pf9ejtAacRWt+Gz3/XYNMky+o6yhFlvgmD4Xk+rufhWEs01xV2pMHZSMVUUupacqxUBlgsAG2Ver3fzoYKw+V4Ln6gCUOPVhIybKcc9tvC4fRS9tsx+2nIMBartVg7ImIzwp3NU12n20t9ViZg6mQ85vT0lNPTEy4uzplMxsxnm+R3V4o1d3+/d2q+lx3ejW27r10h3KZowbf6sKPE8dE3mTTDUBHHLmm68V+JQuFwtKdxXY3jGPHXmmuxHE5TdOZSvwQ6uxzObrHAswEcARALKCkOLVPaOLTMtli4IUIBG6NPWj+fARzlaZzARccuYapp93xGeyH7ByEH+yGHez6HI4+9vqbflphuWpvoFs2+bupvtxW26eUt16PX9yWRBDhorcU6LUnYN1Zpn332GR999BG3bt1mOBwxGAzodDrEcSx+Oa5GOy6uMaN2HGfD5cQRaZrS6/XEgGB/n9FwSLfTITKRoYXDNeFvMGCzFpG91As/0LXoZbDZFq3dnN4KcGgotAuTkuB9cDevok2HsiIz4/i4/s0OCjcVBSap1/q7Fa/Z7Q2gaR5TizunNV5wHBFp+J5L6HvEgUcSeLQin3bk0wo9ksDk39EOgUkvbANVXp/k+cuyJMtzlssFi8V2sYCzbbBxxczzrdIbbmybxv6oWYM7bGy5nXXeG4WnFb4nIW0C38H3RW/jOI6R3Tf1M40pxgS/3KTY3p2O7T5nLcDd1e1sT1tv4paagOeitkDPBWVzy5rrNvUIjsLVDp4vceKiSNJbt1KXjkmR3Uo1USihbzwt9bMVoPLbGYYvkc1P4wW+6G0iAQqrh2m328RNEZjWawW/Bc41r2Z+uzbemutKhk/f35zveaJvNeOxydHwuh7YGIMvH/Pylt8m2jVnfvW/rdnx5T21HZPCYNhrf1N6a8Cp65qyFqV2aRTX74126kCsc2oxGbZmtKYuJLJ7oyrXINIED/N9zcXY/U2QaYKP9XVpBieVLJSyopPBEAUeaeTTSUK6SUgnCkgDTeJrIk9EIK5zc2VkXQuXUxQFq1XGapWxWCyYz+ZrR9DlcmmAv5mL6Jt3kOuTnYzt91fQVY/U3Nb47phka54W4wDfc/B9KZ4vaaZdLemY10nLmmsO80ib4WVp+yG2f601d1vbaCiRN7+UcfG1pakf2gaszTHmOnbpvXMfhexytUL7Cs9XhLFD2nLpdjW9rke3LVGqk0g4ncCToKbXqP33StZIII5jEhO7MElNTMM0JYpjfN9fg0OzPuXLFSzJlmhsY2W2Lma7vc6VYLO+7qZz2MubA17a8ttIbw8IO+c1fl51zfUU+Bb0VoBj9QplUZIXNhvl+zEasFNFbV60qmoqE06mKITDqupqB7MtYJQN0CgNwJRQFlDK77osG6Uw+0ypCupKQsvUlTmmspGaRa+jtYPvi4itnUbsdVNuDzvcGbS51UvZTyP2ooBB6NPyNL5l+Xdf9LUkwVJXK4kiPZ1Oubi45OT0hBdHLzg5OWF8eUmWGUfQK7vJt0VvfrNmN9ntM8pO0cZgQGtFELhEoehrksgljjVJookiF98XvYFNVrZ7/83Vbd/Y3iNbm5Bkn6D5uTs5XXXcLqezW2z8iSbwNKa59aMJt6J98CNFkDi0u5rRvs+9uyH37oXcuR2wN/QZdlx6LU0aufjaWV95Q7tvt1sHvFRf34S01sRxTK/XW5sy7+2N2BvtMVynfY4kkvNL9fp6Wh9vuCFbtgHI1ufLrfW3l3bb/qryqqNlX/OobzrFvxXgAFR1RVmVVGVFVYl/gHAB3/CJXkHrSjASsKqqKKt6I8prcB5bn+vvu6KyJidj9wsXY7dvEoFt3s1yOtQi9rFWc1q7hL4mjQI6SUgnCUW0FngkvqS79rWD+xYjoK4lKVlRbPRmy+VSOJzJhsORuGub+l93kvcKQesp80a0bppXkEKkY64r0ZI9I1LzrCm056A9heNuJpzNma+izVCSX82hRONdmu/08vU2ojn7fVM24CPTvwWlHXi5+rs1plDy7o4Hrg9BqEhTl05H0+0YsVriCPiGkrpam3rYve7LVbz7zlz5jm9DjuPg+T5RFBEnyToETZJKRs7QOC5fZbrcFHNd+TxKanGXNtzPestm3/bP7e2v+PU+qNnrtqafddmdX96u8A6uRW1mi7p++dl2X+wt6K0Ap/kQVW19QN7F41xN64Yyk0RZC9iUVUXZTLm8LvKM67NfauHG9vUdGofTvKHd0DjUnKqMSE0sc1zJzxH44p8TBaRhQOxrYt81IjUTC2tnWrgO1ZarXPvlSHrv2Wy6No2W8ELVuqPs0rvpMm+iKyrrStrdZ76bilE2pbRJvOaZHDjaFlOXrjKxxRqTzza94j7Xoquux841bEs2y2a7/bf5/TragI5yhNNxXBGtBaEiTlySxJESO6SxhPkJAiVBNJy6EWfNXrF5x9e9++uf7DpkDQaCICAMQ0krYFILrPPbNJIHvkrMtV1ztv5kx1qM1rhvE2jX3xoHbV93fdbOVd4PbdX4ldX/8kbbY7fm2coWmfOs/jw3PnqrLGOVZWQrsRxeLptlyaJRluti9q9WrFYrVquMLMvJ85y8KCjKQiRI1tfPzLPyKQ95xTTzWnorwLG0qZCrqu3dkm2EsoKirNYVvMpzinKT/E0m2u016EtPZ1L4clXHtz48jrF2c4xwvDEw5FQ51tEa1/PQvk8YhqRpQqfdottu0W0l9JKIbiw5dBJPE5osotqYSV+3y0sHrKiMkcZyuWQ8HnN6esbZ2TmTyYTVKjNcTlOP822Svedune8+y+5vtqcCMxeIWK3Gd2s8Db6u8Q34aMeG7t+eOiQ981XPsXvPq55v87nL/dhfNwft7alu+4o7VLN9vOmfrlYSQy6uSVNot2DQU4yGDqOBottWxCF4ukbrygTQ2NzzTTAndMXzvESvv47jOHhaE0YS3zCKo7VxgOO+nKPmm9LulXZ/C1299btC635lJTdWbVBVlFVFUVZkuXH8XmXMlyum8znjyYzL8YTzi0tOzs84OjnlxdExz14c8+TZC548e87jJ8949PgZXz96xqOvn67L118/49HXz3j8+ClPnjzn2bMXPHt+xIujY05Ozzg7u+Ty8pLxeMJstmCxEHASMColyoUBwOv1mw29NeDYVbQo7s1kv3vQOyJ5LRFZlLWEj1maBlitMoq8pLI6GWsE0Jgitivl5adsgo4FEhuJAGP9ZI+pbUGscpTr4vo+bhAQxBGtdkqv26HfbdNvp/TSiF4c0osC0sAjdJWkFTYT6rWHw3qlI0E9F4sFFxcXnByfcHp6yuV4zHK1Ii+KtRHHtwM6u3X8unrf3fYySTWLvZjj1GgDNoGu8XWNp2s8V4p2jTOtnZ+37M/kXtvT/FWfu8+z+S3fdvdzpYhy83abvRvjg83kv03mGjXC2awvYl9IoRyFdiEIIImhlUK3A8OBw/7IYX/k0u8oklgAx3PBdcVnbLPyfxO9/I5vQ9ZoIIoi4liycAaBpCJwXVdAZ0v8+c3JXmnriusf7+4+75qaPU/AZpuTKUoBm6IoybKCZZaxXK2YzxdMpwI2l5cTTs8uOD4+4/mLY54+PxKgefyMrx895etHT/jq68c8/OoRDx5uykP7+dUTvn70hMePn/PkyQuePTvi6OjULGIvubiYMJnMmM+XLBYrVsuMvChFqmRA56ZTzFsDjkyAGy7H/Ng96p2RHcC2MbK8YJXlZHkhTqelKPKtRRk2isB62De/y2BUrGe4rTA3IkDfhLwRU9udzmvPczWO9nA9MQWN45h2K5H8OmlMOza6nNBb63E8RyZKZ1eO/SZqgM5quWIynnB+frZOQb1ardYpqDfc5/trk5fpqntdte0VpNhM02sOx0ykWoDHc020ZBsKT8LhSXOsL7Q1nBvc7utoc3zz2O2z7D7Zujlje3uTZMt1W9mK1BrFcDi+D2FYE8fQShW9Lgx6DoOeQ7tlOBwPtK7XkaRtkT/m+i/Ry8/8tiTcmORpCoJAwMaGG3LePdhY2rri+sfN71OzLca6qlS2GC7kVUXE/bIQLm2p5NO6khRFIXrZomiUnCzPWWU5q5WAzGK5ZLFYMpsvmM7mjCdTLsZjzi8vOTu/4PjklKOjE56/OObZ8yPhcJ5sOJxHj57x6NFTHj3eLo8fP+XJ0+c8efqcZ89f8Pz5McfHJ5yciNTk4uKSyWTCdDpjNp2zWCwFdHJ5Vptx+CZ0Y8C52eXfD0nDi+7IFukQbAa+rQjpRVeDYaPzb00Xjb4q27enlPWKxEwIW2BlZz/zqRrWNGvLmrWdkplTNre7Bm1Ax8ZYyzLpBIVdfXyrHM516fpvuTXlWj2OSVHgmKyNcrXN+73p6lvX3Dm6ue8q2mr79V1tz7iKNlfavdcbac2V2IWOFKWMTsfmBdIS0DQwGTa0TVvQ8Hu++s5Xb30ntO6XJUVekOey+LFlS9d6Q9pqoyaa7pZGC2/atPlLtrwEIruAUW5iRRYGDLI8N+NtozNZGc7D6knmiyXzxYL5fM58sWA2nzObzdbR9CezKZPJhHGzjKVcjidcXI65uLzk8uJSvl9ccr5VLji7uOT8/ILzc/N5IeXi4oKLC0lJv/kuv88vLsw5F5ydn5tywdnZuSlnnJ6fcXp2xtn6U/bZe1xcXjIej5lMJsxmc5YrccW4yTyj6pscDayyjGdPn/KX/+Jf8L/8L/+cH//4J0wmEyrTMDe83DVpM/j2OzEfDzt8/1afvU6Lg9GA/+KPfo9PPr7L/t5QHMFs5AHlvDRNbNvtGHFgWYq5dF1DUUCZi3guz6mzFfVySV0WVEVBkWVUeUFdVShXHN0cVwNQFDl5llHkBZeTGc9PLvj5g8ecXIw5ncx5cDbl4dmMZ5MFeVWzrGpWVUV5Ax2YUgrX1fT7fUZ7e3S7Xe7cuc0Pvv99/g9/8ifcvXuHTqcj4T6Mora5qnw3K0y5xmq14vHjx/zTf/pP+cu//Bf81V/9FVVlxZm7x9v7vmqfzJCuU6PNpNpNFYdDh8/uaAZdh+FA84PPEz75OObWrRAvCInabaJWB+37KC8GnYCXmPw21lTZWo5tQthIpIGQmmgnikB8RZSChtMm7vq5N+YfmPdqinILFDlQACWwAOZAZj4nwBnUS6hXUE2hmsv3uoAyk1KXFKsl+XJBsZwzn+Wcn+d8+dWc09OM07OCX3+d8YsvMx48zlllNYtlzWJVkxeiD8AskDZ1vz0GrkOO4zAa7fFnf/Y/8ud//uf86Z/+KWEY4jiyZq3rmgcPH/CjH/2If/f/+f9ycXlJp9PmH/yDf8Dv/d4PuXvnrhgU+D6+J744zQUfjZq8mjbPeZ0nft2V12Cz/i5Wr1Vdrf36mmLppk6lrmShKwBq91fGUlcMdirDyTT3F8XGR66sKrHurSvqCrH2reTesq9c62LLqiLLxPWkMDnIRLmfUZaVUfZvwosVZSlAb65ZlXI9GZdQs1mIOkqtRZ3W8CkMQzxP43keYRAQRTFRJIntkjghTVLj0JvQ63a4dbhPksSSkfUa9NsFOMphrxVxf9jm8/0eo64Azt/749/js4/vCeAYJb6jtXAZ0JgEzNVsR69rseqqjI9OXVMXuYBOVVFnGdVqSb2YUxcFVVmQL1eURUFd1WhPo4MA1/cBjIXIkmyVcTmZcXR6zi8fPuH0YszZdMHDsylfnc14PlmSVxWLsmZRVhSm81+HZKXrSiTdbpdW2uL2ndv83u/9kP/+v/9T7t27R7fbJVnL0IN3DDib868HOPb45n1390tRCrQBHO1Cr6W4NXL5/j2XQc9l2Nd877OYjz+KODiwgNMhbHVx14ATXwE4FjAssGwAhx3AqdeA0/Sr2XAaG1MP88xbgLMpisKATW6AaAHMGoAzNYCz2gBOvTDfC6hyKDPqqqTMlhTLOcVywWKecXmZ8fjxnPOLjLPznF99lfGzL3K+fJyzXNVM5xWzec0qqylLqWtR8FpqOmlfr+cJ4Iz4sz/7s1cCzq9+/Sv+w3/4D/zr/+e/4ez8jE6nw3/z3/w3/OEf/gH379/HNwE94zDCMdZqTXp9z9w853We+HVXrhtcjQUf69NngcZyNmVlIqoU5rdxA5FwXhtRWZEXZv4TyUNRmP2VRNPPsly+G8mEFatZdwfxZTQWaIXhDs3v1SoTq7GipMht0sucsqrIMwGfwnKT1eZatmx8B61kqOHWYfSEspB1jBhU4tqFYUgSxUSxAEqn1abXlayrw8GA27cO+OEPv8+g3yMMw606fhXdWKR2veZ+f1TbsDq1oL9UaoNVv9JgYPuZ11uNntay43KUaHpM5DURp61XMc3vlclFYsVpLrXjUKEoN5HbNiJ5Mz05Sm30N68Ue7yaBM9lgGQm4sBysWC5WErHNHHtyvciUrvu024m5Kupub9xjHlcR5np3Tp/uhKS31qnCV9hdTOvvst2F9hVym+o+Wv7yV42wd3uS01h64bkeHvWy/dqXn+ztQlqTXDb+PTIYsOGVFISX86H0Bcdj+9J6B/tKmHut55r9y3fPVWlrMbncxEfzaZTFouFpKBfyaRYlZU81Xq8bhrpdf9ebpXd9t0uzctbUFkXc38LPOXaIqwhPstylquc5XLFYrlivlwynS+YzudMZnPG0xmXkwkX4zEXl2POLy45u7jg9PyCk7Mzjk9POTo55sXRMc+Pjnl29IKnz1/w9Nlznjx7xpMnT3n8+AmPHj/h68eP+frRY776+hFfff01D78y5eFXPHj4UMoDW77my4df8+DhVzx8+BUPv3pkzpNrPHr0hMePpTx5IuVx4/Px48c8emTK+n5f8fAruc8XXz7giy+/3Hw+eMCXDx7w4MFDvvr6ax4/fsLTp884Ojri4uJyE8PxmnTjBGxlWTKdTPnlL3/Bz3/2M14cvSDLVuuJ+P2Qlc9C7GtaoU8nCiWGWRxxa29Ev9smTSKxKHNcEXOZc662FhJRQ23Y5LqS1UZVFFR5TlXkFKsV2XzJajpntRTWdblYyQDK8rXjaVVDURTM5gvGkxmT2ZyL8ZSzyykvzi4Zz5dMljkXi4zxqmCRV1RAUUNuWPrtKet1JKsRq4xVSq29u+/dvUuSJnietw6g6BtW164md1eVN6fN+eVLCdieGEDcpdfdczOJKARYfFcmzVbs0G+73Bq6dFKXduoyGPh0Oh5pIlysDmJ0EKFcCdpZK59aedS1Y2KjmaIk182aa1HOOuaZxDqzxd+Z8O13eU5r9/byX3ZmvcqI0mTZIuK13CxHLOez2hxjo1nUtQmSIeJeKqiLkrooqEtZYWd5xXyekRcVq7ziclpxNq4Yz0SkkxU1WVZTFHaBYh7pG5C6RgK24+NjHjx8yN/8zU+5vLhEKcXeaGTSPwdUVWX8dHwT904qT8mf19JLujDzPrUdx2wWglYxv9a15BmL5ZLZTPQpk8mU8XSy0XtcXnJ6dsbp6ZkxCz7n5ETSgJyennJ6csLJycnaIvT09JST42Pz/Yyz0zNOz045Oz3l/OyMs7Mz8/2ci/Mzzs/POT874/LigsvLS/m8uGBsdCLjy0vGl5dMJmMm44mUyWQdtmo2nbGYL1gsF2vxWVHka32tMu3j2lh2nuTv8v1g7RMVRZGReIQEYUAUGf+owMPzPDzPl2jrrmiXa0DVyogPK8m9Zfx/sizDcR3SNOHO7Vu00ha+kfK8id5CpLbi2dNn/OW/+Ev++T//5/zkJyJSK8uSsriZAun6pGTQK8UgCbnVS/l4KCmmb+0N+Ad/5/f5/if3uXUwFIsxI+ZSjrO9mF2LrmRgQkVdykC24W2q1UpKWZDPFyyncxbjCaWRkZZZRpnnUNfowCeMQ7wwoAYmsznn4ynT2YLxbM7Z5Yyvj065nC6YLDOOpyuO5ysuFjl5VTMvSuZFSWG4pevWnFIOYRgQhuLncHjrFj/8wQ/40z/9E+7dv8dgMKDf79Pv9Wi1Wltg880Bh/UUKyK1Jw2R2v9qFh1XvclWQzS+N8K8KEXoQeSDr2HYdbh34PL7n3qM+i69rsvduzGHhwGDYYgOQoJWl6DVxfUCcENqN6J2Y/GjUq646yvXmLdLGmkH34jbbMRnm/3TNzocK4azojXX8FNN8NnA5OaddsHGitVKYIlijiIDlka8dkldL6HOqfM5VbmkLjPR4VQrKFdQl9T5gjKbUeVzVquM6XTFi6Mp48mK88ucL77K+bkRqS2WFecXNWfnFbN5RVnayVieUWrePqf9/ma6jkjtb/7mb/h//7t/xz/75/+MFy9ekCQJf++//Ht8//Pvr0W9t27d4mB/nyAI14FXlTGk2cWUJjUBx84xwq1spA7WIdKKraySv6pE17FcLlmZ/F3Cic3J8oyiKGT/akW2yqkqmVRXWS6qglJEWVY3Yifg0liEiujLitREBCf7jJisqigayRLl+I2YqyxNxJaGJEX2mZaqbLsplDIJIk3QU9dxcV0Hx5Hkc44j0fRtvcq+jf+TRIeRPMRW9Jcb8CrLkiwXS9eqrKR3K7mvoxyj0wkJfJ+7d+7wR3/4+/yf/0//R+7fv0e73Vq3z+vo5oCzWvHs2TP+8i+vAJwbWixcn9R6eHfjkINuwr1Bm0Er4dbegP/6v/h9fvjpfW4fjHA9HzeMcMPA+NE0zATWbHVpPPIr6iJfl6ooKBcLisWCKs+YT+ZMLyeMzy7JVibnT5ZR5gVQ44ceURwSRAEVNWfjKS/OxpyNZ0wWKy7nS56dT5kuM+Z5wSQrmWQFs7ykqGoWRck8LylK4XiqxmB6HQmHo82qRHNwcMDn3/8+/91/999y795dhsMhBwcH7BujAjspvF/A+X8YwCl3D94BG8t42vdUqFomcdeBOFCkIUS+Yq/ncP/Q5Q8/99kbuHQ7mv3DiOEooNsLcP2QIO3ip10cHVC7AZUTUTkhtXLBcU1SPgEfR3k4KsTBN9lAmzoca1AQvQJwbCTpJuAIXArVSCsK4NRroJFPxRLFEmcNOGI4UNcr6qqgWi2oihVVkaHqHMolVEuoC+piQV3OKcs52WrFbL7i+GTMZLbkYpzx4KuCXzzIefgoZ76oOTmrOD6pmEwr4XLMpNUEHPvtasB5uY9sAOfVRgM//smP+Tf/5v/F//R//594+vQpQeDz+7//B3z08Ufcvn2b/b19Pv/8e3zyySfEUYznS+QB10yWV9x2TbuAY0tVb7iaLBMP+dwEuZ3N58znc4qiYDKZcjm+ZDqdSeBb48e2NFzDYr5gMZfI61VVimLe5JgqrQlzLlINq6exIv16bVBgOVR5LhvsV7aJUQAYicZavCeoYo06akT0WyNjVZnoDa4rvky+HxDFMWEU4bqaKDScix/geb5kJo4itBYph2Qr9nGNYZMYNwjgZNnGui7PM5bLFZeXY8mvZaQ4y+WCbCUxGtcL9rrm448+4r/6+/8l/9f/y5/z+eef0e12N431GpLe8tYklXR1p30/JKu1mrwsydc27dbmfdMBahNJWqw0pJSFdJQ8z8mznHxlFHArEZOtliuWi6V0vtlCnKxmC8bTOePJnMlkwWQq22amTGdzprOZ2MdPZ1xMZpyNp5yNZ1wYzma6yplnBauioqikU23VmhlLrxlvWyQrOqvMtO8j8dXEK1jST5dXiDilo4uo5RrY9ha0+xa7vy1Z/kBWtkaNJia/roPnKnwTJTr0pQTrLJeOiMxqh7JSFKWiKMXWoyhq8lxKUdTkhQR6zcuKvLDKYauovaLvrCcKKVJJL5eNDqluaOwMZ7OOx1eaxc0m+KtMYLYvVhRFTZFXFHlNnkGeKSk5FLYUxo6lhKpS8kjGjsZxJEmd1uB5Em9OzMc3dSrLNVvrTbqqA7yqvd5MYmVl4/3JZDaZTLi4uODs7IzLywum06lwGiaPVmlSmzTdHLYAZc0VNH1XpM9nJgGkDdEyXyyYzeZMpzMm0wmXYzExPr+44PTsjOOTU14cHfH86AXPXzzn6bOnPHliyxMeP3nM48ePefzIfK7LI548fsyTJ094+sR8Pn3Ks6dPef7sKc+fPePF82e8eP6coxcvODp6zvHRC06OjkT0dnzM2ckJZ6cnRtR2ysX5GRcX50bMdsHkUkRsk/El0+mY2XTCbDphPpuyXMxZLudkqyVFnlGWIitVmKSQJqxWEHhGXBaRxBFJEq9TdUuK7g69XlekHzul1+3T6/Zot9ukaYvEWKP5fmDyTLmUVU22ypjPJS3KKltR3jBo89vpcKaiw/nZz37GixcvWK1Eh3OTG9+MZMgoFIF2iXxN4nsEniaJQm7vDRl0WqRxKMc6Ej24qsXio8hkQs6zFdlyxWI+F0X7fM5iNmM+nTGfzaSzjqdMxxOm0zmX4ynnFxPOzidM50sWS4k3JD4vBUVVUVKTVyWLVcbpeM7RxZTT8ZzxImO8yrhYZMyzgmVRsawqsqqmqGqJmGC+Wwuim9Se5VaUUsRxRKfT4fDwUBJa+T6ttEWrlZIkydbxjSs0rtXYfC2SE8qyZDyeGB3Or4wOx75Fc5pr/LbGEo65sZJ9Ih5QhL4iDh1i36HTchl0XW7ve3RaLnHkEsc+YSgZPmulqZ2ACp+icsgLh6xwyAtFXtbkRU1eYkCnJs8riqwiy0qyrKQwoFQUIo6RdlDmHarN86LA+P8IbQBnG3QM2FAIZ1Ln1FVGXeVUxZIiX1DkK/JsQb5asFpOyVYrstWK5TxjuchYLU08q1VGnuVkWbm2RMqznGxVsFwVLJZiubTKKy7HNZeXFZOp9KfFAmYz0eOs1xzX6lyv7gjqGjqc5y+e88Wvf82Pf/JjLi8vqaqKJEnXMdS0dmm1WiRJshYnUQv3ZLkAy+Vb0+PSiOqLolgDzMo4Q85nM8ZG1zGeWJ2M+J2cXZxzenrK2anoTk5PTzk5PZHfl6K3OTs7YzIeM51MmU4mTCcTCYRr/GgWJkbhciVFjB9Eh5JlK7LcGOnkmcwxuehWityUQpzS16K3tQjO+MsZx1BrtrwxgrILZlNHSq0bUDliyqwcRV1J7DwJYyR1RlWjlJJrlNL4toWqqjLTo/HpWhuhSEJLrT1c5eB7knNIuCZjIh2KabSI5xyGwz73793jD/7g9xkOB0TXtFJ7a5HaX/zlX/DP/tk/W4vUbNTom13tumSrTJEGHv04ZNSK6aUxt4Y9/vd/54f83id3ubs/xPU8vDBABz4oJZ1jKZ3Eroqms/natn2Vy2DO8oyqKKVTGdPnxTxjNl0wHc8pixKHmsR1TDwvhXIVSjvUGsq65mSy5NnFjNPJknkuHM1klbOqhLPJq5qiRkCmrsnKmryqKA3XIfzb9cgxWRGVUgwGAz766CP+7t/9uxyafO+ffe8zPv3kE27durUFTleBztsCzutFao2LKgs2BmPMChyAWlFXEt5Ou4p+y2XUcenEDvsDh/u3PP74c59R3yVNNHErIEoD/EiMA0o3onRiaqWpHJ/SCagcn1q51EpROg6VvX8tRdVi9eXpEF9HaNfD80OCICZOOnjax3F9tI5wndCkrVbG6MAaEtAQ81jAscFTS6pqRVksKUvRB64WU5aLCflqSWHAJ8smVGUmE1AuCfSqskRR4qgChwKlKqhWqHKBqlZUZU5Z5azyOXmZM18UPH6W8+BRxpPnObN5zbMXJU+fl1xcCtDWJlC67V81r0KhV3WEGsdx3yhS+9F//hH/+l/9a/7x/+0f8/VXX1NWJaORiHV7vR77+/t8/vnnfPbZZ6StlH5/wGAwoNft4pk8Oa5xoq6NqXJZ5GJyXJYs5nMWiwV5LtaZs9l8HWFjlWVMJhPmcwMOWcZ8NmM+X1CUBYv5nJlZaGa5BKhczOdrXUxuthV5YcDOROywOpVaJvDaiMEsJ9YUM62nUrvN1q8Z29v0iro2fVVhF4kbnYzjuGhP4xsfO0e5Yhhk/O209vC0RxBGRuTuSUy7MCIIQ8lVlMTExszZ8zw8c77jOFQ1a0OE0hgH2ASPRVEwvhxzcXHBdDbj1uG+0eH8D3z8behw/uIv/oL/+Z/9z/z4xz9mOp2ahrHK+PdB0hCxp2lHPv04pJtEAjh/9AN+/+M73N0f4HqScVD7IrNcLhbMpzOW84WEiVgsOL8Ys1iuyPKcRZYxX4mCsCwrllnOapVTlCWrZc5ikTOfrairCt916IeSbiDQDpWqKajIVUVRVZzMVrwYrzidZ6yKUpw7SwGbkkbiOOmTlLVwOmIwcLOKawJIr9fjzp07/MEf/gH7+/vs7+/zez/8Id///ve5e/fuFjhtAw7SuXc3vZY2B7/aaKBx3FqmI78lCnIDcBqh7zxXsdd1Oeh79FOH/YHmo1uaP/w8YNSTPDhe6KNDSSte1Jpl6bOsAsrapVIeletROT6VEhP1AiiV1D1VLZNGVYsS1A8Igwhfe4RhRJK26Hb7+EGI5wV4Xiqg4waGJdPUxi+nqVPYAE5uxGiFgEo2E66myJmNx0wuL1kuRDSyWi1YzCcUhQCN9QGpTZ4l16lwnBqlKpwqQ5Ur+awLlFOAm1GrglVW8uxFztdPVzx9IYDz5HnB46cF5xcVxr7FuJnZXmYq/CW6qiPIcaLDeb3j549+9CP+1b/+V/yTf/JPePDwAdkqk8RrUUSSJOzt7fHpZ5/x8SefkKYph4eH3L59m4ODA7mW665X0XWNLBLXHEXGeDzm8vKC5XLJdDIxOaFOTebbJReXl2LRtViQGVBaLpaUVSkcySojz7P14rgw/ip1w+igrsRsW/zzBFwsJ2anSqt3sZ+2nhpfG3RVPb+ONm1gx6pyRFOoDEfiuGKhCsLtuI4BJNc1iycf13AtcZxs4tqFIb1ej16vRxCGpGlKu92m3e2ug6z6XoCrPZSjyPPccJSyWD87O+X46ISLywuGgz7f//xT/tv/+r/i9q0D0lQkKW+itxap/fwXP+enP/0pR0dHRqS2aZD3QwI4rqPQjoNnVkOh73PY79BLIiJfm1WJWJ4V2Yr5dMrs4pLZWMr44pLj41MuTMiG07NLTs4uOT6/5PxiwokpZ+MZZ5czzsdzLqYLZgsRpbnGD6Sua+ZZzmS54mK+YLxYcTxZcjRdcjbPmK4K5kXJshAxmhWlFRZkqnodYeCmYLNLvu8TGbGaXdkMBwOGwyHdbvc1HA5XAM7u/iZt79sWqVmzaPsu0l4oq2e3DmbC0m+exVzTcDjtxKXfEjPoXttl0NXc3vdopy5BoMUIQGmqWpMVDovMYb5SrLKaLIesUGQFZHnFKitZrAoWq4LlMmexWLGYLVnMFqwWK1nNFjlFJg6WSlX4voOiQlHhOGJqKnOqEU8ojBit6W1ljAPqTBw764wyn1FkU/LVlCKbMx1fMr64YDaZMJtMmU6mTMZT5tM58/mKxXzFcpGxWOZkWUGWV+R5RZZVZKuCfJmTLwvy3EyMShz3ygqm85rprGKxFKu06axmPK1ZrmqMVMUsBG371S+1pdDutk2/VEqRJPHrRWrPn/PFr7/gxz/5Mefn52Qm7bkFjLqu5RzHYblc4jiOrM59n6oSy6/C5HxarVaSbHAmPj3T6ZSTkxOOj484Pz/n6PiY58+e8/jxY168OOLo6IgnT57y7NkzXjx/wfHxMUdHRxwfH3N2dsr5+RmXF+dMLi/XojO7el8tl2Sr1UYkVmws0Ky4S4Bp2xBgW7/3PsjMDua+lvOwEU3yzLhqrJYs1+nmF8IJmpJnBrDN+zlK4WoXVYvjukS4TwkDsXrtdNoCQq02aZqQpi3arRatdhvPE7Npz/MZDPocHhxw9/YtWsYV4zr0DY0Gvm2SFUdZ1WRlyaooWGY5k/mS88mMs0uJRTS+GDO7HDO/HLMaT8hmM/L5gny+JF8sWS1WLJcZy1XObJExmWeM5yvRuywzJquc6SpnUZTkdb3OM689V6w+Ah8v8FHaJQcWRcUsL1kYcClqY6NUS6lM37SfdS12TPbf25IF+aqS7KurlRgOWKVsYQeNcVi1K7UN7U4wvGHwvG7fVSTHK5PF0hY7R8m7m2NUjVoH6zQK8LUSXEQLylHUyqHCoRTkQvuaMPKIYp848UkS8dFJE48k9ohDn9j3iT2fyPUIHI2Hi64dVFFTLguyxYqVMYGfjyfMx5fMJ5dk8wlFNqUq5tTlwliNrVBkW4U6g2pFXS6oizlVPiNfTVhOL5lfnjMfX7CYjlnNZywXMglUZSmAZqwNwzAgikPSJCaJY9I4ohVHtKKYJAyJgsCEhfHQrsZVDk7toGqT3NrmZXIVrmsMByw32QB4ZXVSV1JzAr1pW19BtRgS2IlytVoxmUw4Ozvj5OSEF8+f8+TJE77++msePnzIV199xVdffcXXX3/N119/zVcPH/LwwQMePHjAg4cP+frR12snxufPnnN8fMz5+TmXl5dMxmMW8xmr5YIsW0kIqiI3URs2kUTYLIXeCdlrNcubaPd4hehhrirSZmah86qLr40sNsAo4XUK8lyinyyXC+bzGePJmPOzM05PTzg+OubF8+c8ffLYlCcGsJ9zdHTE2dk5i9mMopDMx76naaUpg35PIg4kCZ4nHOl16a04nMl0wi9+sTEayFYZ8L45HCFlV+Q11GYiS0IPRU2eZcynU/LZjGI2YTWeML+8ZDGekE1nLGczppM555dTJrMlk/mKs+mSk+mC4+mSSwM442XBNCvISlGyedoh8DVx6NFvp7TTmDAMWNVwscw4ma+YZAWXWcE0r5gXNbkFmx0BRnMof/Pakh7oeeLkGUURyjiFjkYjRsMR3Z6YKwo73phw1Ob8V3bkV5KcsM3hWKOB7WOUoyRWk7ZiPdkrfcVMALWI2LSGXstl1HXptRx6bZdeR7M39IljjfY0leNROi6Vo8HV6CgiTGKiJCROQ+LUJ237xLFHFHkiLtMegRagcUuFWyoDOBXlKqNYrChXOVW2osqWZIsZxWqBoypcp0K7JXWVgSoNMBagxJFTxGgrqObUxRiKCWU2Zn55wvj0ORcnz5ldnjM+P2dyOWY+nZHlGXVdieOqJwuYOIlIkohWmtBKItpJRCeOaEXCuQeuEt2hdtDawVEii6zKmuWiZr6sWGU1Va2YGQ5nlYluULgQcREQBbOl6/dA4XDeYDTw/DlffPEFP/nxT7g4vyDPc1CbRVFtDAEWyyXjy0tR9o/HnJye8uzZM548ecKzZ0958vgJjx494ssvv+SLL77giy++4KuHX/Hlgwc8fPgVj5885unTpzx/IZzMxfkFExNUcmFElkWeURa5xEm0qebNaq9ZAzfu+oYsUFxVXkfr49bRRhrj0kgBrgQce/KV99huUws+G67IGlwINzefTcUB9dIYWJydcXR0xMnxCZeXF5yfn3NxIWBTlSXadcBwp2mc0O12GY0GjIZ9BoMeYRgYEd+b6a0B5+c/F5HaixcvhF0WBPh2aJ2sSG4Yaoe6KslXK5azGdV8Rj2bsZpMpUxnZPMFi9mS6XTO6XjOdL5iMl9xMl3yYrrgeLJissqZrARsZnlJhYh50lATBR5JFDDotOikCWEYMi9KjmZLnk/mTDLxs5kXFSsjLit31otNsHl3JME8tSf29gBae+zv77O3v0+/14e1kYG77sTNHvxuAce+odxDAgOKc5oygCN9RQaGkQzhKOFmBm2XvZ5m0BYrtW5bM+oHRJGHq10KV1M4LqWjcTyPIIlI2ilxEhCnAXHqk6QBcaQJfQ9PeQSOh+9oAzJAXuNWijIryOZLsvmSYrmkzFaU2ZxsMadYLSThm1fjeTV1naOcWnxIVdkAnALqJXU5p84uqfMJxfKS6cUx58fPODt6xvTygul4zHQiSuyyLFGugx8GeEGAH/qkqQGbNCaJQ9pxRDuKSKOQULsm4Vy9znQqK/eKqqhZrUR8tpKYs0xm4oOzzGqqyk5x1vlPyaS01Za2vJpuBDg/+Qnn5+cCODVrX5miKET/Mp1ycXHBeDzm/OKCk5MTnj17JiDyXMyVHz9+zIMHD/jyyy958OUDHj16xNdff82jR494/kxCq5yenHBxLskHp9OJ6MeWS/LMgk1hwMYATWPwNd/29W9+NTkNj6zd0qSr9lnLss2nY6zG5HMNPo0FgmIzTnfvsSH7gsbQYYvLWbFaLlnMZ2tT9UsDNqcnJxybyAnT6UTMtMdj8myF1powCHCUQxJFdLtdhsMBg36PbrdDq5Xg+dfncq531HeMKmoKmw2vKFksM6bzJZP5gul8wXw2Zzmbs5rNZUJZroyZqZiWirlpYXLqFCyzgmVesMhKlkXJqhS/jbLaiNM8zzWchOT78HwJrVKhyKuaVbGxQqskJuuV/9497MhqRmS7spLJ1ukKXk7Gtr7zu3yEK6kxpSnhdGTAvEqgY9wqHYkY7dq8N84muKAEcBWxWi1LxDX3pD0X7TlStEJr2e7agYwjqv5aoSoHKkVd1JR5SbEqyFc5+VIGZbaYky3nFNmCslhSlUvx/K8yiQpAQU1pPk00gToXsVq1pC6XlPmCfCXgJddbkmcrcR60uUSwJvwSisnVem1p5GktxdVoV6ONcliKmKau38l6mK/FaY2V8lqkJqCxBp3mDPYeqa7FH66uxLPdAs5kMlmbJotu5th8SgiZ4+NjKUfm0+yXMDHivyJWaRvz5Wwd8sWKkq0/VNOf6t3SFqBY0dcOwOweb8eA5V5Yt429zgZwNuc0z38dbYvX7LxgfaNsWvrZbMp4IkYYZ+fnnJ+frYv1ERqPx0YPlFHkGVDjaU0UhkShRBxwnV0DmtfT23E4k41I7flziaX2HtryDSQN4joOoadxFeKoV5ToqkRXFUVZMM8KxispF8uc82XO0Tzn0nAkk6xknpVkZY2jFIHrkhg/n1EacdhNuTvqst9rM+q22B/06HXaxHHIoqg4my84ny3E7LkWwLlJuoF3QY7ryuRkzBt93+fg4ICDgwN6vZ4cYzyWHZNmVMRqpkNfv78YkhNez+HIYWI94+CaUByAWXE2BhfgGg6n33IYdRy6iUOaOLRTTb8fEEYu2nPB81C+RnkaxxUz5aKA1apkOs05P19xfLrk6GTJ0fGS58crXpwtOTpfcnSx5GSccTYruFiVTJY5i6xgVdTUSibrwAPPAd9ziGOfwHfwtIK6xtEejmcjWNgJrNr42SwuKVZTsuXGt2u5XFGiyErFsnRZVS4ZHrnyWFSaaQ7TVc10UXI5yzifrLi4XDIeL5mMF1yMhStfLpcSHqUsqeoSxykks6cLWVmzKiuyUiweJ/OK8bQyHI8CHOpGjKe1Pm+Ldn9v01tzOA2qERGfFbGBcRYtS7I8M1GQM1mJLxZMZzPmc/GLydcLqYyyEEdd66dii6rl+mAncXvfnbLT31//5tukDIeilQSSdU2+pmYaLOyY2gEf6e8bQHHsxoY3l8SYNf8ai8R6M2xu9LwbsteTz411nuWETJ2CRKS2ZvqV+IFNJmNWqxVlKebjuQGgKApMJITr8S5vDzg//4URqR2tdTjfHm2aUDkKz9jtV2VJXZR4dYWmIi8klMzpsuBkVXC6ku9Hi5yLrGRaVCzykryooAbfcWiHPv0ooBcG3OqlfLTX53t39rgz6nHQ77HX79HvtoniiGVRcTpZcDadU1Y1RSU+NoUxrfy2SFa3rpmAwfMEcPZMaJvayF+tA55M8t8e4Lgm34ajFKqWAWVv6ViFqUkqNmgr9rqKbqJoJS5py6M/CAgjjRe4KN/DCT1cX8yTV6ua2TRnOsk4OV7w+MmcL7+a8vXjGV8/nfLV0zlfv5jz+HjO0/Mlz8c5L+YVp4uS6Ur0dHktIUQ87dDyFaE2JXDxNbiODE7HC3CDCLUOrV9vACefs5qdkS8uyZZTcSxe5uIHo1yWpWZeeCwrj2WtmZYu50vFxaLkbJpzdLHk+cmcZydTjk5mnJxMpZxOmUznEiC3kpwqqAo/qPB90J7hsCvhymvEam08FcfPulbUtVpHKJCJy4g0Ny31RnoXgLNu9PUzSPDc0uR5sU6wFnAWCwmrYq3XbM6ZV3ErZu5eT+x24/ZkLfOGBZ2Xr/Jqstd1FXiOwnOluI7CXetddsaT5Xrs9obuRpmNtbJ63o3LxOZ5jVxkt71uPGZ3abMq3hgZSMlWK5ZLseBbzOdMJmNOT08E/I0VXJatUKqm3W4RhmJSfR16e8D5xS/46c8M4GTZjRrum9Mmai8oHCSiaVFIIjWfGp+aoiw5XxUcr3KOljmny4IzAzzjXPQtWSEOXS4Qapde5DNKQwZxwN1Bh08OB3z/3gG393rs9zv0ex067TZBGDLLco4upxxfTsnNgM+NqO/brI9N5xXg9TyPw8ND9vf312bRvucRBGKfbycJ+bCirpuQnHB9wBEv8/VtasT4w4INZhBrxaDtMDKAk6YOrZYnHE6s0YHGDXzc0MfxNVVVM53kXJwtGV8sefZ8zsOvp/zqiwlfPZry6NmMh0dzvj6Z8eRszvNJztGi4mRVcb4sWZWiZK/WnLKiGygirQi0IxO6K46YSincIEKHCY6rTZ2ZKaHMKFdzlpNjsvkl2WLCcpWTFRVF5VApl0XhMcs95oXHrHAZZ4rjecXptOR0kvH8ZMbT4ylPX0w4Op1yasrJ6YzlMkNVJZ4LStU4bk0cV4SRwvMFcLJSLCRrGhyOMSKoKySIp53ErNWibaRr0DsBHEsW8Cqb+yVf+9uslmLiu1ybKm9MlNee91eQBYPd7/ZomdCbIaWu996WlCk2ZcbaiMOAjXAsFnA2MSh2AUeK+NOsAccCi2mTusG11da69arHtQ911b5rkDSDDf0lwUYz4+w5n8+Zz0X0eX5+wdnZqRhkZBnLxYKqLPA8zd7ecO1Ieh26Hh90BUnFXIG83yLZxilrcbxcO89hnKUcV8xpjYpPGam3i4OnxJcndF1i7ZJ6mpbv0Y0C+mnMoJ3Qbyf02ym9dkq3ndJpp6RJQhRFhGFIGAYEvsjbfdc1cb7MEutbpBpJsFWaAIPWj2FtIr2SCLD1lSGpX9rwBnqbl9uIB5TJCeQohascszKUgSjhMddrUBngZrKTYp3brIOgS11DntdkWcVyJb4os3lpSsV8WbFYVcyzmkVWM89hUTosS5cMTen6oEPQgYksvQn4WlcyEOsypypziYe2vRYVDqeuRKdTFVRlLufUlXAXygWlqR1N7fgSikd5FLVLVipWBSzymvmqZLbImTbN9GcrxvMV00XGIislFp8Rmykl9eB5eqO/0grtqW0dlqtw3M2iYtN6NhnUb47qtUm/CRVl+q4tG7P+jf/LVWQBZv35mi76un2vojXQmKKVQjsKz1H4hsvxHBGx6XW+K9Nvm89kwcbqa2wq8AbHI1a4G73l+vgGtjTBSwwPXl+a526TBbWGvieXsD2r1ZL5XCI5XJj01GdnEi7o5OSEs/MzptMpeZ6LKuOa9NaA85unTedbN4zRU4SBTxJFpMbSpxNG9IKQXhDQD3yGgcco8NjzPfZDn/04YD8JOEhD9jspB/0OB8Meo0GXbrctVlBpSpjEBFGIHwYm34RP4HmEnib0NJ7rioL2iqZ9r2SCH5bGY90CzmIh7O9ysRAnPCvqu3rcGtrq2leUm5JdtZn7KnAdB891BKQdEUnY6ANODcrM5arahKJxarNYUC6u6+G6Pq7roxwPjJm0MtZ6QRgQRiFRFEoQwzgiMflAwiDE90J8E8omjFuESYcgbqGDmNrxKHGFMwBQFbUqQZXyaUxCmp/r73blDiLGqhVV7VDWLigPnABH2+KLoYArRgCu6+BqhStBrkFBpcT4ROLuVRIfrjJ6GcfFcT1cV/xyBIQlj5B2reFEw4jAtt7WpP027fndoXWvbHIOjcl6g0KNyd9O6I13t9dxlBitrIuZsF2jq/EcI0pzFIGjCLVD6DoEroPvOma/6CPtQsourjZAY7+LoYfjiGGLaxzZtSuxzaQ95bd1dpfjxMfKgp9rgM7e23PAN0WexeiYrjGCLfiI75SI16yxwWq1YDqbcnFxzsnpscShm0zI83wnm+zr6d0BzvXv+Q5JnAUFaFx8zyOOQvrtNgeDPreGQ+4NB3zc7/FZt8P3Ox1+2G7zh+2EP2rF/HE75o97CX/cb/HHwzZ/tN/jj+8d8Effu8cf/eATfvC9j7j/0R2Ghwd090a0BwOSToc4TYmShCSOaMcR3SikE4Wkvk/gus1+Lh35Go39Tag2+qvcrE6Wy4WwwsYC6Pz8nPl8TrmVkevbo3UgwqrCqWt81yH2NImviTyXQCt8p0YryTijqk0qGVUq3MrBrV00Gs8N8b2YIEjw/BjXj6m9CLwAHcck3Rb9vS57Bz32D/rcOhhy93DE3cMRh8MBw26fbqtLp9Wj192jP7zNYP8e7eFtgtaQSsfk+GS1S6mgVpWEklHyQNYyzRYJ32rSXdhBUCuqyqGoNFnpUVQBlYpx/BQ3bOOFbYIwIQpCojAgCX2SSJPGmiTRRJGLFzoo36H2FIUDWS0OxsuiJqsdlBOgdYzvxQZAfXxP43uawHclwnYgEbY91046xjT4N9AH3jVZoJHFipm8DTfnOPbTTPiSL1Um+YboS87dLptJfTO5ayNCC7Ui1opEK9q+S9fXdENNJ3Bp+Q6J5xB7DqEWzkdAwhZ5TteRHDWu60jEFNfB15rA0wS+T2hK5HtE9rfn4WsX33XxHWerBI6AXuRJiZtFi3hYRH9SdAN8rqIN6FQURU6WLVksZ0xnU05Ojvjq0Vf88le/5MGDL3n2/BnzxZzyypQkV9M3Bxy7cv3WydzUrCIk251L4AvotNOUbprSSxKGccxeFLMXhRxEIbfCgNuRLyUOuJMG3GlF3OnE3O63ubPX587+gP29Af1+j7TdJmq1CNMUP4rwgmAd9C70PekcplO4jpiqmkdbN+zu57ukGvFJWqfIzXOWS2GJp9Mp89lsndPiVWKJ90VW7GrvrQDtKHzXwdcy4HRjNelQoyowzASqUlJqB6d2cZVGuz6eG6B1gON6KO2B6+H6PkEUkrRi0nZMu5PQ66T0Oi167ZROmpLGMXEQEYcxcdwiSbsk7T5h0sELE2rHp8SlwBGhmTIsly3CcxgRjwUaK14zVlI1wt1UDmWlKWtNrTyUG+B6Ea4Xor0Az/PwtZjaB75LYFIw+L6D6ynJEecqKkegLq8gr6CsHZTycB0f7QaS+8SIdLXeiNY8rTam5Yhh3Vr7+e12g/dClltxGuIlWYBa5saMtq0FoIDPRoS1OUd8YTaAZLcJhyHcje8oAR9XEWmHWDtEWn6LXkc4oKb1mjyXAbX19TdAKZyNK2PBdfGs1anWeFra1XMEoLTroM3zXMnZuM1iRH2GE7L1s6mLV5ERtVWlWKVlGVm2ZDqbrp1Ej09OGE/G5FlOfUUalFfR2wPObwxoWN/YVp61hLJcThSFpGlMK43pJDHdOKIXhQyikEEUMIx8RmHAXhSwl0SMWgmjTsqo02LYa9Hvt+n1O3S7LdJWQhBHeGGIDgK076FtZFZX42tNqDWB1eMosUvfkbpuPf2rG/otySgYm3b3mRGpzWYz5muRmuQeeX9aN/tm2++9UYCKDklk4AI2AjibAeQqhYuJPlCbSXJdFI5ycR0toiTt4fmBRM+NQqI4Im1FdDox3W5Cz5R+J6HfSem1Y7ppRCcRzrSVRBJKJpEAh0EUoYMAx/dxPS3WaI4y0QVMh7d+HQ2QaQ4GZV5bVtnuxrfGhHwPg5AoCohDnzT2SWOPNPZpJQHtNKCTymcrDcWBNQ2IkoAg9PF8z/Q/uaYAjZb6aIpcTIpubcMCvT632W8nmXre1WXYSX4tcjLiLdcxorG1mElAQRulv2s+bV+U33KsNYHeTOgCLlKEy7BAs7Zec+y1mtcV7kY70ufl2gbQlOF4HCVcjyNiOt/mhdIOgXZEjKddQs8l8jaf9nuoXXOMQ2CfyW2OrwYIvnYuMnNKKZEKiqIwep0Zk+mY2WzKcrmgLCXL6XXp7QHnO0KOEtT3PMmVHsYhcTsh7bVpDdp0+i16vYRBL2bQjRl2Y0bdhFEvZdhvM9zrM7q9z+jeLQZ3DujsD0n6XaJuCz9N0FEo/heOpHV1lDFEULIaCbQm9qWE2hVPcMO2islvY4VjzBdUQ8z2zsg0em3Chywbya/G4zGLxUKCVTZ8F94dNbvu1W9lV/4OMpg97RBol9CKAnwpobYD3tRfLRwPpTAYTu3gKo2nPcIgpN1pMRr1OTgYcvv2kHt3hnx8b8gn9wZ8fLfPR7d73D/scf+gy8cHXT49aPPZQcpnBwn3hiEHHc0wVQzbLoNewGBPRHLdYZekHROEPlrbNL5swMXoa2xucNXQAWitCENNqx3S68X0BzHDYczeMOJgGHJrFHP3IOGjwxaf3m7z2e0On9/r84P7Q3748R4//GSfH352wO99fovf+/wW3//0kE8/3ufevSG3b/XZ2+vQakWEgScGA66skq3IaFck5Cp5bml321W2gfJ6dHXb/qZoXecNkNEKfFXjqZrAqYnWBWJbNCS6JjYiMit6CrXC14b7NtyM6EMUoSvcTKwdEu0QaemrgQuB3uyPXIfYtSItEbOty/pc4YhCRxE4EDjgOxW+qgkcCJ2awIXQhVg7Ir4LPfqxzyAJGLUi9tsx++2YvXbMqB0xbIUM04B+4tONPNqhph1qWoFD4jffUUCzCUB29L62ddfdxfSjhiHQTeitzaJ//vNf8NOf/mxtFv3tklSPJAty6SQxSRTSTiL2+x0+vr3H/dt7dDopUeAJ6+s5pIEmDTWJ75KGPq00oj3q0d4f0jnco703oHMwIh31CTspfhKhwxDXM2mKERNTKkVZVEynM87PLxhfTqjLktkqY7xYMV1llHW15sDWT2x+NBv25k32elIgMY/SdJ00yXVdev0+w9GQKIokzEzTMsY+2PoK16OXzaKfbndCJX+aSlNPO6SBR+S7BNpFOzW+WxG4NZHv0E8Ug0TRChVJ5JImPt1OSBiIQYCXpPhxgo5iXO3jBzFR2qLdadHptOh2W/R7LYb9FoN+Sr/TYtBJ6XdSBp2YYTti1AnZ74bsdwKGLY9u7NCOoZMoOi2XVtsnbfkkEQReiafB9UN0kOIGCY5jfA7Mq9ZVQVWsKJcTyV2jKrQf4kcJcZqQJCFxkpCmCa1WRKfl0Wt7DNseo27IXi9kvxdyMEg4HLa4tdfh1n6X2wc9bh/2uHvY5fZBm4O9FoN+Qr8T0Y5FBOcoWK4y5osV82VGUdRMJiWX45LVqibParJVxXxekuc1VWlyuWz1vTf3QvUuzaLfATkKHGMQ4Rig8RzwlOgCPQW+gsCARuCKoj9wEJAwxTeA4TkS+NRyIlpJ5iONnBtrReo7xFq4icQX0AncjaWla/xzRB8kXIxnuSBzrO9aIBNxlxV5aSX39JzaPK9wVKF2SH2X1HdphZpW6NGNA7ppSDcOaEc+rdCjFWrSQK91SKFWBCb7q2tEap4Vra4XwVKXb259XpoX+n1JwPbHf+fvsDcaEUXR1v5X0TvicK4/Sb0rWlecNRjwjXVSHJJ0UlqDNq1Bh+6gTb+fMuonpqTs9VvsDdrsjTrsHQzZu3vI3kd3GN67RedwRDLoEnXb+K0EL7KAoyUEybo4aFcTaI/Y90h8j1CLHHZtpWJEa00hm7Nr4rj7Yt+EzOrDcjjj8XgdTXc2n5Hl+Uas9hark+vRy29W12I4gNEfaNdwOJ5D5DskgUsrdElNps9AKzwz4IXDqbEhHCQysovn+kRBSKfTYn+vz+GtIXfujLh/d8Qn94ebcnfAx7f7fHy7x6e3unzvdofv327z+WGLj0cRt3qavbZi1NEMeyHDvTbDgy79vQ5pJyaIArSRoztKyfCsK8PZiMOwHbGOIxZm2lOEkUe7HdDvxwwGMXvDmINRzOEo4s5+wv2DFp/eafO9ux0+v9fjBx8N+eEne/z+pwf8/meH/MHnt/mDH9zhD39wlx9+fpvPPjnk/v097twZsrfXFQ4n9PG0Fg7M2SjErQjHc2WiWT92Q7T5/tr/W6KGKG0j+qplwlYQKIhciHVNrCF2hatJPEi0KZ4i9RWxt+EABBiMuMyAVeiIvibxHBJfFq9rDsdM7pHhemLPIdEuieeQeg4tzyX1HdL1pzEuMPeLtCJyFZELoSNcTaSFC0s9RctXdEO9zd10Yg67CYfdlINOzEEnYr8VMTJcTi/26EaaTujSDuS+ia+IPYg88LWUtRFBQ7fzWjIcji22B92kJ70jwPnNkl09iyJOPO5drXE9KdrIvj2Te8MLg5eKDgPR0XgejuuijIhia/VvuQErIrO6CEcUfdoM+vUpzVM3X9fKyvdFdS1xq8SkUUKCNH0ado0HNmKW90TNa9uJwgHXAo/vEgaa0NfG8GJjJq1qbKRWU4wxQV2jTFh+rcUvx0ZTsFkQpXiyGPG13CPQRIEmNEp631N4noSv8Tzrx2KjW8tzbDGAW3W18WVRmH5h9sj7STw4raV4nsL3xChAjAQ8Qt8jDDzJRxKEouMxsaqiMCQMQ4IwwA88fE/jeWIuKwpoU0eNhY1ViMsix8RaazTB+2zmb42uGFfK5GIVvYzoZkSnYsRjbvO76EhEzyKfrmu4JhnmDTGd0bWY8EvNkDb2eMfe1/iVWQMDUfYbfx1HbfQya/2MKVZH4xn9jHbXrhahp4l8TeTLwlas16SEvkfoawIt0gJfG4ODtQ7J6kfVWle0NlwwXKIFGmUq8ep5aXurdWs1jgM3orcHHPuU14LGd0ubTraxqRcrEGse6aK0xvF83DBCpylep4PX6+IP+gSjIeHeiHA0Iuj3CDpt/DTBjyNRFitQVWXyaGwsj+SmEgZFmYx6YeCTxiFpFBEFAb6WiMy2I64bs1llCOi8D6qN8UCWZcxMzvfJZMJsNmexEEfQ3CTG2l3lfmPQab6srTAj77VclUICc3oaQl/RTj1G/Yg7By3uHLQZ9WJasU+gXTyl0IAqKshLyGwpICtReYkq681U63g4boByYxwd4+oY7Ud4YYQfRvhRSBgHhLFPlASEiUcYe4SRix86eD5oXeC6Ga6T4Tpiq+ZQ41hWxn7UGPdvB1W7MrnbIJqOktQGKsd1MrST4emSwIcwdAgDTRD6BGGEH6b4YQs/6uJHfbx4gBf18cIuXthBhy1cP8bVgeGyJS+QUpbDKnFqMSffcDhGr2li2DnKWT9zXbN2rb2i0d4ZvafuvSapeXBUjatqXCOKCl3hGBJP0fJdOqGmG5kSe/Rio+OIPNLAI/FFRBa4DlopHGoRjSnDbZjrhdohspZoa1HYxvDAd6xS34jcPJeWL6Xta9qBpu27dAJNN/bpJyHDVsywFbPXTjjophx2U271WmIpO5Byd9DhzqDL7WGX28Meh/0Oe902w3bKoJ3QS2LacUga+iSBRxJoIk8bAwIjyrO6JhMdwXfBs3ocVxZGTgNEX9V0ayC2df8WveftAWf3Vu+7h+3Q1nBRykQEFtBRroujPZTn4UQhutVCd7t4/T7+cIC/v0dwsC9lOMDvdPCTBC+KcLVG1TWUBXVZUlcSE0QmYyXuwY6Lo00K19CEko8j4iDA1xp3bXL5svjsqvKuqaoqlqsV09lM8l6Mx0yn03XK3dUqIy/EukRA55sijX0Re63N9eTXJno2qka7Nb5WhIGi0/I4HCXcv9Xh/q0O+8OEThIQeq5kda3BySsDMgWsclgVUvKyESnVAaVBBeDEKDfB0QmuH6MDAzpRSBAHBElAkPiEsU8Qaymhg+dXaDfDdVa4ToajchxVbiIg1E0uS0HtQK0BF6VkYhfrNHCdEkflaLVEqxWeW+D7NYGvCAJNEAT4QWIAp40X9tDRAB2NcMMhbtjDCTo4fhvHi1E6ED2iY0zODNhQlai6aqzGrRWUcR50xMCFWlFXEldN6ut99b5vZypQYBYCRneiZCKNHEi0ouU5dEKXXqTpR6Jw7ydSeolPJ/JphZok0MS+i+86xkelxkXAK3KsUYFDbEyhQ0eKZ8BmI740gOM5xJ7oXCzAdHwtn6GmG3oM4oCRAZr9tgDN7V6LO/02dwdt7g3bfDTq8PGoy/1Rj3t7fe7vDbg7GnBn2Oew32Wv02bUadFvJSZvUkgaBMSB8eFpgI4V/QW6EZLHgk7TgMDZRD9o1rMtToOLfBM4vYq+AeB8d2jNFiplMkNK7SnXxfF9nDDCTRLcVorbauF1unjdLn63g9dqoZMYHYW4gS/cEVZOv2PRVcvNxEpN8or7vkfoB+Kk5Wk8k3NmF/3l+8sA9D6oquu1L85sNmc+N6l0VysyEzJEog6/A6C5BsnKemOOLZZcEHiKJNJ02yF7g4RRP6bbCogCidrgOlKPlBUU4oRSW2eUopRPG65HsQEdJwAnRDni0a89fy1W1b6HH2j8QOMFGs938XwX7Su0B45TCNCQ41Di2HTTa6dJi6cWcOyniF+Fy5CVt0NhrlOgnUoGuWdTXXh4XoD2IrQX4/oJ2m/h+m1cv4XjpTg6wdExjhuCq3dmgxrMsykz8TooXIyZr3IkK6hZiGEFIGsO57eXtiZBVa/1OJ5q+MnozcSfBpqWKWnokQaaJHCJjGWpNT8Wy0jhZrUBsMAR7sA3Svy1B3/Td8yIrURkJ8YBkbFIi81zxNol0ZrE07QCj1bo04kCuklIL40YpBGDVsSwHTNqx4za4qqx10nY67QYdloM2y36hqvpJBHtKCQNQ+IgMCI2cdHwjXhNRGxGvNYAlmZxG5EVmubzu/PTpr4NJ/2W89dvN+Csx56ZBWoZhFuLbKVAuyjPl+JLcXwfpT0BqaqEPIMso84y6pUpWU6dF5sw6PZ6houS9MAiVgsDSf8rYoyNjP1l2oDO+6DayE3KsiTLJMSNpJjdFEk/XRpF/i5tzapvT694QWV9EbSL52uiyKfdiuj1Enq9mFYrJAo9fN+a+5oVeQl1WRvwKaWUpfyubE6Iei3mAolhppQnYWWUB8pHOYEBJB/laFM2YiqZwEu5IZVpq02Lyd9mMi871RstipnkRcZdQZ2j6hxFjqIwxVgwmudTykepAFSAMgXloZRwTmCBbSdfuS2mreQ52YTVqeRTIkZbcdo3bNc3UHPRt4kHtnvUO6CG7qGpu9noS0RvY/Uk4lS5CSPjqE2dWHKMyb6AhzWHFpNnsTSTSA6etjmKtCQ/NLH91npELf55gacJPHfj4GzmBlDUdU1p0m9T17IIMz5Awi2JXibwXHzPAIj59EzIGynyvLLGFu56DR4GDO1CyLaFfJrvpg43i/bt4iij/zGcnNVjidj45nPZNwCc3YnpTR15/Wo3fMSXqcZGT7X3F25ERAzmuwmlIj3TkRWi66FcY+JstIR1WVAtF1TTCeVsSjWbUc3nlLM51XIpoGMnNQRsMDoi1/MIfJ8oCIjDgNCEF7HOjK6N6dTEPzsoTeO+D6rrmrJoBuITJ9D5fM5sNhM9Tp4b7m337Ca9ducVZF7oVe+lJM6VqzXa1ya1cki3GzMcthgMWnQ7CUkaEoYevi8m3QozOVQGcMoG4BQlFIUBHyteU4bbsWI2X0RtKqRWIbWKzKcP1q8KY4hQW91d2ehoMkk0B6kgjt0mfUzAxjV8BgJcdS5J26qcusyhyqGWEEO1NbxtAKIUAZstbqauN3273DagWA8D06mqWhlcVlJNtYg0LdwYL4qtpnkXpJRRSq+zvIo152aie3d93o4f4ehEtOUpCzICNN7audhMyqatamOHUtgI76WMAzEC2pgyi+WZkrAxvmSQDX2fwPfxPcM5m+J5G0OVwPO2iq8FlGxdlFXNKi+ZrzIWWU5mksZVVWEWObXophzRJwkXZQEA44hcrR2SlSMhvuS3rWfbUaWyavvbNoD5LvrvzS7pt1LW4kJjaOGtDS0s+Ny8Pb8B4NyEZIK1LKi80A2f9BVUYwdiAWVudC9G/1JWMqE6WqIBewF4PnieyHQch7rIBGwuTk05p7y4pLwYU05mVIsVdVFtkgYqMTtSno8OAqI4pp0mtNOUNA6FtTUxj0R+vg3Lsh7eNO77oKqqKYpNeJvZTNLK2jzm0+mU5WpFeYOQFNenV72VaXXHNWItnzAJ6XQT9g+63L074N7dAfsHXbq9hDgNCSPhGpUyGTpLqIsK8gIy4UjJMshzKYWkXd6AhAZCIAJiamIqUlNa1ETUeEYgpYwYtdgUaXDR0SDAJyIcq6S372XAxtE4SuMqOZa6oDZZQLGlXECZQVlT19ok0gjMc9pnDcyzmwmhNkYsZQllYfp4BaUEWpRgvcJhgUNVOeSFw6pQZEbVZfFpuzfelF5/nlJiUOOalb9rjBwaYZHNcbtnXp+ak6IYSEhNeQrhQlyJAG+97a3i3LorKCNarGrIi5qsqMhyScnsOAI0Io5zSH1xumz5IgZLo4A0DEnW1oMRfhARBCZ6fBCa+HghSRiQRD5x6BMGHp4nUSFQLnlZMVtmXM6XjOdLFqtMgmCWBXVVoCjRSsR6NjqCY0zulWMBpsZRlSmmTzZBXYk0QaS9Umkb0LGVKZ3YcqTiOLwpWlkRoUvobgKVhlq4RgHxnQZ6A31DwLGd93Ud8eUn2nS4l/ddl9Z3rTGygg1nI9yNrApFyuJQrzv+pvPX1NRFSZWtKBcLqsWCarmkWq1EtJZJXvRNZkHWFj7KOncZazXPkzQF2jG6B9O5X3rHnTZ/PySsuo0cbc2jlyaxlU1XIBPq69ruXZNh7x0HR7u42sUPPKI4oNWSsDRx7BMEHp5v/EtcsUCrDZdDVRuOUybcrU9poAZZeHdFuV97UGvq2pPJfq2DEa5QSimc8trHRq05nPVbKJlcsYCgZLK3IjXLMUmflLQFW0BWSQw2M+LNc4i120YvJOmwhZocjpWNNfxp1u8sz1TXSELAUpIClpV5v/fE2VhSyvhIeeKCoD0PV0u+e6mXdwM6mHspA/rKmIE71oHShqUxoiYRK0n11Mg4roxIqyhriaJuLP02IjVF4FifHMfoRDSeZ4oRq7n204rW1pGejauEKwYcznrukbbJyopVVrLKS/JCIjMXJsHcWmdstW1bysP/f3t/1itZcu15Yj/bs49njBMjmSSTl0ySVQU+qdUFVL1Wv9QXaH1IQQ+SUJAgQBIkdTcahW6hlLyZ5OWQjPGMPux526CHZbbdz4mIzIjI4ebtjhWwcPft2/fZg5n9bU3/Jc9e3VJvd2ruLlQ5PGm50c5PPGGv8Ybsdhnfq+Cn2TOlhXbXNBm013eVbwk43yS+c/kOEi5iXKbs7fMhIjdPwEbMIR54fHPjJCQ2dwV7A1dWirbvsU2LqRsBnb7HaSn25HumuIV8XXYXAM3I34zGqA1/fSHWPXRydh399Ut9bcN3Ju4ut9pdwBkGsR9/Z/Ju1+KCJch540GocZMme00GbJzERLFoifLjgJF7vozwzPc/7w06ufnqTlcP+1ic0zgXNBoPBnsT+y7jIAzQ0JAFRQCbADR+YhENh7GOixxTwGcENev/ttPeZ+SLvWH8hOJ9SbdAcK9f3pqH/E3yk6k2jkGHCVVq6Iy35XuSOI7Ji4LFcsnB4SEHBwfCUefz2+I4gI+/f+/WZV6X8Hv/f5g7d4eTC5UxIG1nPpOii73emdO0vz/K53XtIv0CF5nk2u0A5TbAxB5YghlRJuKwSPEaFWIJ9bEvDMYXzdOWdjA0g6HtNG1v6D0IaSOLxpBDZ4zBaCMF6fQgzYT8ul1FVOvsmIbgnKQkWOQaw/okvAYJ9248a2+NCvcgiRRpIqSiWZqSJrvqwe869vlOAedOZx7X995uGgWq8Deu/t/9hIFAeytvZY1I5Cyxs0RhYHvTw64NoHvoW1xT4eoSW27QmxXdzTXN1RXdzQrdNOCcTHSRrKytdVhtsYPGdh22aXF1jW1aAazB4Lw5R+HEWeqdpi66bWrfu4hbn75LCWBj98Cm8iHSNzc3wq3Wtr6jfpMf513kG65FMc6Mxlra3lC1hrLRNL2VCGerME78Y0mWkhUpaZ4QpzEqlns52mPxxxsBJwzp/Rac/v6ZjO8HIjoi14CtwWxxeo3VW6yusbrHjjZ1P0gD4IyrVN+iSHwtUSSmViU+GUWMcxHGRmgdSfczFmN7MbGZBmtKnNmAXoNZo+wG5bZElL5VRK4msg3Ktijbg+3FB2SGnb9yD2Cdi7BW0Q+OptFUVU9dD/S9f86Ea/lQ+frnPJlMOLt/n1999hm/+92/4rPPfsOTJz/h+OSU+XzOdDoly/IxsZrR/3X3SO8h/rdunNCdTOZa+lnTGapWUzaaTd1zXfbc1D3rZmDTaspeUw9S2E6hyFREpmKyKESvSVkAKR8gPltJ2PWfU0kqznx0WOLnDesEWHoDrYF6cNT6dqsGx7a33NQD5+uWF6uGV6uGi03DzbZlXbZsyoaybKjKiros91pFU1a0VUVb13RNQ9dKldR+GBi0ptea3hhfhXhP43VSY2lkHPETQBhiEnwh9DpFKMuQxszyjMV8ynKxYD6fM5lMSOLb9EbfJN8N4LytB/u+JBfiyQRvRUzsg877ShhoMoQiLJEzKGdQRhzK4scJgGNADzD0uLbG1hW2KtHbDd1qRXe9oltv0G2Lc04GhI8osUZKWFttcN0ggNO0OG96Q2uc9oZyxQg2YYL0FpLxjH8I2ddwel82NpB5brdbWg84O/X9u5A3LCD23jpvxugGS9MZ6tbQ9JbegHESfDzmOGUpSSaAE8W+I+13lXDaYcJ1Vhz+XkMIYHO7nxgfLdah6MDWOFvhzBZnSpxuBHCMDxv3YOyIxCw7muhug49Ek/mgZKkpgHMx1kSY4Lg3xh93wNkWZ2v/d7dgt2BLlCuBCqjB1eAaoEG5Dmy3AxsbwCZoYoydzDmFDve3GWjaPcC5s6r9riUvCk5PT/n000/51We/5tN/+AcePHrE4dER0+mMopiQptkdE9tt687XyWu7+YkugKj1E6m2lkFbusHQ9Iam01TtwKYZWDcD61rApuoN9WBotUVbUChSDzYS4uxf44g0Fib6/baLQvNlBHxTkQTTD1bRG+iMozWORjup7urBpzGOarCsas3ltuN83XKxbrnedKyrlk3Vsq1aqrqhrqWYYlPXtLUATVMHsGnp2o6uE1aRYRgY9IA2Gm2NBxqHcR5s9uJOxj7hS4fE+7x0PtIv+MImecpsMmU+XzCbzSjywms5+w/l6+W7AZw3iZIHqNiZ0/bNasEGK+f6Hme8J+FCBXB8G81pPmlzbN7ZOvS4rsU1Nbau0VWFLiuGsmSoG0wn9R0cCutAa0PXD/RtT9d09HXDUDf0dc1QNwxtx9D16EFWxeME7gfTbrrbyfc56IPc1XLatqUsS8ptSV3Xt+rjhPbtJDzDvWd557EGE8cIOJ2sQNve0A5WSihb8bkRx748wG2H897BboGNfPag4wLo7JmonJHwZNeBC078BkwNpsKZGmvaEWyC3056l5KhclfDwWs1vikfoQaxLIGcwliFNV5LttpHq/Vgur2/XYGtwNWosTUo16JsC64D18vCyYpjORS0c87umfCFXFYbR98b2s7Q9YZB2xGXvk/J85yDwyOePPkJP/vZz/npJ59w//59jo+PWSyXzDyhbJpmnlR2Z2IbNZ3XUOV1CV/LJatxMSdR8w5j3Gg6a3vpX3VvqDpD2WrKTlN1mkYbKWhnLMbK/RNvkBpprWS+8gwmar+gWqjYuZvPwjkZr90EoOm0vLba0RlHb0NtI0VvHHVv2dSam2pgVfes655N07NtespGiFmbpqVtWtq2oW0a2ka0mjbk13mw6YeBXhsGI00bi7ai2exAx5u09xVk5edR7/saw8x9OYYsiZhkKbPphMV8zmw2Iy9yb/L+hge2J98f4ATxyxd5iEGzud2n3v10g+x+oYL2tNciPOmjk7s6ajxa4/SA6XtM12P6XiYXwEWxrIGtYxgMfaep65b1tuLqesX55TXnV9dcXN9web3i+mbN9WrD9XrLzbZkVVaUTUvTD2hjMFYiX/Yn8h3wfBuzxvuJ8/6DYFrrum7kVntTqYIwj4/z+beRO793PoJuGAxtr6nbgW3Vc7Npubyuubyuud50bGpD1TsaTyqgvd9HJv67QLMDG2nB36FFI7DdCC7O1lhTY3WF1RXONDjTYU2/i2zc9wd52Wnit01nu/e3wUcpMauBz/D3jnzxBVqxtRvtgSeATwu6AV2DbkF3YHqU6VFmQBmD8gEH4gvyDmYbTCN7vjEr99kYtxdL8aaHueuR34XEcUyRZywWcw4PlhwfHXF6esrZ2RkP7t/n3r17HB8fszw4YLlcjv6dADwj+IRp4y0ynrF/TNY3Y2UlPwSzmveTdMbRa/85fB9iTRxYp9BWwKA1ltZYGi1NzF+WZjA0g6bppVXdQNX2lO3A1mtOK9/WzcC6Hdh0A9tOUw3GL6YsxjkiJUEIRSrlTZKQRYqAQmcMdS/AWPYDdT/Q+tZ1A10/0PVaFsK9lveD+H66QbQ7aXs+vLH5p+5votvH+BCCfScUWykJvEiz1NecmjOfzz7IpPbh5Qm++ILP/+DLE7yBhlxWCAIGkY9oCNFbbnQah8t9H9mthJJIMUkTTqc5h0XG0TTnZDnn0ekR948PyOKEREW+iqTFDT2mrRnWa4aqYqhrhqaTOjFO4eIUE6cMxHSD5Xrb8uJqzV9eXPLs5SWvzq+4vrzh6uqay8trXl5c8eL8gheXV5yvVvz18pq/36y4qGqaYaA3UoterpORSFGNXoVdrcjvS5RSZFnGYj5nMp2iUCzmC45PTji7f588z4kiWXeMK807v3+b7MoT/IEvv/gjT5898+B154r2Fh0KWXBoI+a+EGDRG8PlTc3NqmJdNpSNph9kgKSBtiWOSSc5aZ6RZAkqjnZh7mGERImYM52VHJgAOqbG6g12uMEOK5ze4oYVTm9wpsbpViZ/LRqusg7lV7xRFBOlBVG2RGUHqLgAleNU7kOYlWjTukE5yaWw4IlSnQeqxMe1+uV4mCWt9oAyoHSHMq2AjqnBNCjTwVBDX8PQgO6kH3cN1kcgVq2mbA1VY2g6y4vznqcvW27WmrazaD8BCbNEeDZ333+9qHcoT2CdAyV5VtOpFLbL84zlcsHR0RFHR0cUhZTDns1mZGkKKKwNibDR3hQY+s1OBIhk/EcjlY+MKXwCKE7CxAcLvYXOQGvEX1J630lnBHRkDgrTrejEvZHvjXVoFzQS6J3CGGgH0Y42dc/GayM3dcdV3XFR9VxVAxdVx2XVc1X3rFtNNWg67dA+TSP2PqFpnpInMfh7Z51obBYBymbQtIP2lTd9Jd+up+3EfNZ2PXU3jC2AYd0bOi0g1wyWdpDjjSQdXtPZ7wFBm5OgCbUrkBhe04Tl0TH37j/k7MEDHjx6wsMnT/jJz37BYrkkzbLwmL5WvgXgfCmAc74POLuOqzy4yDywy7IVwJEVn91d7e2O9prsOkX4qEbAiTmbFRxPcg6nBcfLGQ9PDjk7XEi9FaUkgs1aXN9h6ppudcNQleimwQxGwEbF2ChhIKbV0PaGi9WWr15e8cVXL3j68pxX51fcXK+4uV5xfb3i5eUlLy6ueHl9zflqw7PVmpebkpumpTVGbMl+9SmnHQbH7vrfMD1/pxJFEWmaMplMKPICgOVyyenpKQ8fPKAoCh+Dv+9X28ndz/tyC3C+/CNPn+4Bzvi725OHc2CMox8MvTZSsNlamm7galWzLlvqVoIJtBHdYZpISYM4icmKjCxPSVNvbkvTHeCM5i4lJjQ7jLkvzlbYYY3pb7D9DW7Y4PQWdCXahel9Hlfwj4SoQw84SSFgkx2iogku2gcdJWY8XRNZg/K+hKDlgg8u8P4f5QBjUcaOfhnRZFrU0HqwacF0KNML0Aw1DC1O9wI4fYsZBvSgvanIULaWprU8P+94+rLlejXQdQbtV7o7Zon373XvAjgqikiShMlEzC6LxYLZdMrh4SHHx8ccHByQpilRFDGdTlFRJKH7esD5hUjoP+PZ7fc//14pWbxFkYCOQi4nQlQeGwDHOE+756i0pfIaS+99GCH/yvkQk956E5ixoxbUGUvvuWO1sbSdoWp7VnXHupbX67rnvOp5VQrIXNY9V03HTdOz7TWttqPLDQVFmko9riInTRKsg15bNKCdo7eW2ms23SBardVacuv6nq7r6dqetu+pu56qFbCpB4lyqz3YdB5sOiMan/amPu21Oud282pwdUh0XmCZ9omePvXj5N4Zj37yEx48ecL9h4+4/+ARD548YTZbkKTp7jl9jXz/JrW9VX2kJH9FVjOvLWC87G7Crr1dwnEDMkfepOZhzTtWfcKc1jitsYM3q/U+NFgpYSII0SXa0veGuunZlhXXN2sur1dcXt9wNZrT1lyvtlxvSq63FTdVzbZpaYZBVGcrk85omQlj3Lf3G+7fTqw3qQ3DzqRmdAihvO3DuevL2T/t9xLH7WfnD2Kt8/dX07QDZdVxs2m5uKm5uKm52XSsa03ZOepe7N47k1o4kHySnIoQaROc6PuJm4OYq2yLM60ECZjaR6PVONPibI8zg/f5+VB6uzOpKWSyVQRAi3E+MOB2S1CjmS0EF0iOjTS5t7vQeoOz+xpYh9MdTje3TGrOCEOB5IOFsO3QfAisT/50vl+JSW0XW/D19Y/etv39JYoicq+9LBYLDg8OODk54ezePe6fnXHv9JTj42MODw9ZLpd7RQJTn3OVeMvInl8H3jBZyHsXNAPPRi4mNR+pNprVrICGn3QHv4/kJu2uXnJjHJ22tFr63S2TmjZeg9hpFGXbU7Y927YfAxJWTc+6Hdi2mm0XouAMg/elWCfmqSyJhfssFaoa5ZkzLTAYSz0Yql5T+b/Z9JrWm8/afqAbgllNzGndoMdF3LAX9r2bi26nq+1L0BoFyINJzc/b+ya1VBYT8/li9MfFUQiNfjf5QMAJIBIG491v95rvOGN+igeF8UfBQvYeJ33r+LeStQLFuNCUiBqxy84Wp6uRY0SR0NMUBel8Tn5wIKzR8znZdEI2yck8P1oRR2RK0g/boWfdNFyWFZdVxUVV8aqqOa8bbtp+7FyS+xAm8d25f9Dk/S1EHPWWYRio64a6rqjreuRUG4ZhzMkZQefuQby8bbtI+Hbv9S54hUdiLdpYhsFS15qbVcuri4qXFxUvL2vOrxvOb1quNz3bWo/BBNY5rPW+uGHADb1w4A2dtL7B9Q2uq3DtFttssM0aU99gmxtstwVdo1wvnGbKygIoFnOXI/LdxWF7h+0ttjfYwWC1z/S33kc0epV212s9oHqXIWZwaC0mLSOk47tfjMqYN67aHqcbnK6xfY3tK1xXy7V0NbZvJUF5kLBtZwzWic/JOTHN7vjTZGIxPkgjTKxv9uO8+7j7JpFxvkuGzvOc+WzGwcEBx8fHnJ2d8fjxY37+85/z6aef8otf/IJPP/2UTz/9lJ/97Oc8fvyYk9NTDg4OxrDbNE1lrI4A5GmOfH/aXWswozm60WEPjYHGQjeu7Hf3IQo5dGEi9GYt4xydtdTGUmrLpjesuoGrduCy6blqB67bgVWnWXtQafQOVJSCLInHwozSEt9iKfQWQx75ktKxksJtmWTyK6UYjATRNINh2xvWnWbVBt+QbCt7SzU2CT6oB4mEa7Vod4OR3J8xKm2/1yr/zILrIygEhDnba/dxQhQnJGlGlucUk4I8z0kz0VbfRz7QpFbyxZd7Ppy+lwWIn2CUX+2IScKTNcbSEaNI+dWITMrhwgmgE8AotDeI8jbcNBYm1vvzCceTXNhXF1POjhecHszJ4kjAx1oxqWmN1QO673HOoeKYZDonXS5JF0vi6ZQ4kwqfcZYxWEvXa5qu8wW/oB0Gqr5n03Ws2o6rtuGq7Vj3A5t+oNKazgTNYTf9yuXstD3npyx759q+a1HB9+Ejg6x1HB4ecnZ2xsNHD8nzfNwncF+Npgs5wN1Djo9lZ1L7nC+//NKb1N7glfITxWvi74+xeI1S0/d6DCrAGfIETmZSGTRNIoosJosVSYTcxRDJFhJ9fSi8GzpcX2PbLaYtcZ2YzhQ9UWSIlJNUmiQWwCGS8PfOYAeHM05wxXjqGJWg0hkqF1OQcJ2JdqOsAdNj2w1Wt9hBgLzve4a+x1kn1WKThCgJlWM9yafyN8JHrznd74IJdCef+xY3dJi+w+phL0/IoK1ogmUHVQ9N63h+0fH0VcNqPdAPfvFzJ4DlfUW9i0lNdpQ+vmeiTZLEF8LLBITmc46Pj3xujmhDBwcHzGcz6YueBFMpP1cYc+vvhL+l/GqcMPX4Bc0YJWaht4rBweBjFp3zY8KTc0oxNTlImL2c/2CdmMQHK2au1jgqbSgHaZUxNNrSOdEgrL/ePI2Z5QnzPBVm6DzlIM9GwJlliYBOpFDOSiIwjiRSgPh62kGLRuRRQlvJLeq0kcRVY+m0D7XWllYLyPZGrnvnr9mLSvOuQ5nJwjMKoOPnal9ELlZiSst8omeW55yc3efs4SOOT++xODhgvjjg6OSUwpd1eRf5cMD54gv+8Ic/cO4BB3aAE9Ay8oECu6qMQt0f1F+zn3TowUaNGtNbJqndrqRRxDRLeLCYcDIpOJrmHMwm3DtacLyckyaRRKsZi7IShWSNlnwaFFGakS6X5EfHZEdHJNMZcZYRJSlJmmKclTDDtkM5qZS5ahpu6obruuG6bblopK37QZyDxqKDA3DvhOVqdtcWAOfDp4B3Fxn0kitijBkB59GjRxI0EEsGcQAd/6Pxt3clbLkNOH/k6dOnb5/Uwo/CxIBYwIxxYhevB8pKzAR9r2k6YVWepvDgMGVWKPJUkSW+AJan+xhznuRgo/ZjvaZj6g2m3WD7ElyHig1RgvBRJaFQXyqMyoNFNwOmN8KfpwNZKEKomU1R+UzIXwNJp0rAGYl2a7fYvsUMAjR9JyHzxiKLmyyTekshxDZWouUgAS12aHFDK4DjNTc39HLMvsUMHdYMWKulHzsxmdQDlL2i6qDpHM/PW5693AGORCd9u6WNAM70awGH8Jj9OJZxn5BnGUVRMJ1OWSwXHB8fc+/ePQ4ODjzYLIWVYDZDaz3+1gFaa6FhCmPF950wB8gUvdOejddkeg84nROHvw7j0a/oUyUTfghICce3KHAOjUS0dcaKtqPtLbAptaHShsZYeudwXjuII8U0SziYZBxOcxZFyjKXNs8TpmnCJJWibmkkxeMUUs8ojRXWWTqt2bZa/Do+r0hMfZZ28EwJ3tdU+9yeRjs6I0ESnRHNZghgo8LCNmSmSSh5cEcotUvMl5IWikjtco9yv1A4uX+f+48ec3zvHvPlAfPlkoPjY7KiII7fDXDeTx8KcmcOen1Kuo2e4X1A0XCRsuOtl/DjNx4Tv19o4XPgUYr2OqH0TCcrX7/6ldU3qFi4vKJUJhuVpkRpRpSmRGk6lqZOU2GHnebSJnlK4ukcwkPULjTxNZhxFfFmMAnb3/Td9yXOrxKHQWL1gx8ntGEYRj6pvR/t7uN3cdZhRgjH8X4FbSz9YGha8enUraZujQQOdBLmqYPJyF9LyC+yxowrfjv02L6TyblrsF3jI7kanG7FP2IGlBXaGPHx4alofP7M6NgPfhfl/SAOa6yEMuudFrJr4mOxPhw+UMk4p/Yq1YhnUd7v92AAJyXqnME6n2djBpwehFzW+2/caEKzoEKMhHR6MS8JS3RwQ1nn/Vzf5rm9q+wBzzhG/So5mNeKScF8Pufg4GAMJDg9PeXevTPOzs44PT3l5OSEk5MTjo6PWS6XzGYSflsUBVma3dHCfbSnX8GHHBPtQWd/bN5aAPqTDOcZ/BZK+SycAEBBAx+1Ju8b8sc1KKxHvmiPcyyNhfAy9+Wipfzzjm1ZAh3EsLVPjyUccLtlqdvzLe1CtUNgg5gMb+f1eI3GA014lWG9M/7i58lwA8I8PYKP8uWoA22PZ8aPE+GOi/3iVPnE+PeRDwOcPXnrn7sFNoKYO46xO7+S3jlesHz7JtCRyWq/o+zdt7G9NkHuO02V+G6iTMBFbPeidY1mMN+J4jgiS1Nmk4L5dMJ8UrAIrciZFzkzX2EvlCYIhHaj7IFneOA/wPB/TYxPAA2mnq5rJYHMJ45pXwH0m8/ua75//YF9g3jg8eYeE3w7Zi+HIICNT/ATB7H4L4zVGBMCQDp03zK0NUNbMXQVum+wdhCThadzx/cshZBjKqdQVkn4s4qJk4w4zYnSDKIEq2KMk/wsowdM32D6CtNV2L6UNpSYoUZrCcYwxuFchIoS4iQjSTLiOCUmlgnN+Ug1b+Nwe4Ebssn5YIA9jiznqWmUsP+qJPILpgQXyTkOWhzj+ya0t2qc34eMasdu3O+3OJLJK03FvDaZTCS4wIPPvXv3ePjwIY8fP+bx48c8fPiQs7MzTk5OOD4+Zr6YS95Okoz0OEKw4JnnAujsmatlkSKQfrd3y/2UiVghq/vEJ3WmkZBvSpOCgKm3BEitm5Q8zcjTjEkmc8DUtyJJRjr/UEsmLDMc4Lx1R7jSrM+X8lGEnvcx8g58hfiUQiJpF3xU3l81As0e4IZrvisK/4z8p9vzc9DQxPWR+GtNs5Q0z8myTCIMPZNC8Kv5g976O18nH2ZSK7/epKaiQGS3O/ksjUkTYVI2fmWrjWQhBdUu8g/mttyerpVfjcRKVhLTLObBvOBwkrGcZCxmBSeHc46XM9FGwqTmPFRFkddocqIshyzH+gErk7IRGht/js45IhSFHyQKRRYnTJKUIvOoHydMspR49E9JWPAOAMOV7D5J5787BL57CeCnlBR9stawXC45Pjnh5PR0JOCbBkegz40Yf3v3cexdx86k9v8TH86zZz6z6H1k93yjSMKfk0Q04vkk5mSZ8tMHExbzlDyPyGJHEluUMhhnsC4QlA4MXUPX1nRNydDVGN1BZIliRZTKBC0rNV/cjBjlIpSNUFaJPyZOiNIMleZYFaGd+ACsN/E423unfiOvQ4XptuhuK3936NDGAIo4SUmzXAZsmskAVjGxUz7PR9QRZ4SQMYCLc26kwbFWTGcOi1UOFytUGhEXKXGe4ZKETQPXW8vl2rCtNM9fNbx4WbPedGi9n9wb+trd128WpRSz2fwbTWpvEzWOB1/CIIqJI6mYO5tNmS8WLJdLDg6WnJ3d5/79+2PwwHQ24/DggCRJxpIaYVVufaSimIp2fooRdLyWonwotRotIVJYLEy4eNLOOBJTUhpLsbM8Eb60wpuWCt+mec4sz5nnsvg8LAoOinz020zThDyORaMZKyTJHGmMxRgJJul8kwgzIfJsB2GRDiA5eC2nN4EpQHKGNMprNWoHNOP9lqE1rgH2a3PtLQoipWR8+HDoPBSQS1Mmk4LZfM58uWA6n3Nydp+Ts4csj44ppjMmsxmLg0OyLN+Z4r9BPljDeX0yvS3jRUbhghSxf92Z1EIX3NNW9tW9N0jYLNE9PpLez4v+dqJw3ny2T93iASeOidKcOC+IsxyiWMBFS+ll47OBrSfwzLOcxWzGwWLB0WLOyWLO6WLOvcWM0/mM49mUo+mEg0nBNMtI44QoeDLHiwmyb+KQrvHuQ/7DJFz/vnbTetboqqqoqoqmaRg884D/1d4Bbn98y2PxX3zI1YQ/sFuRjwPS+MgvFXkKE4VRDo1FW402A8PQMXQNQ1vTNxV9vaWr1nT1hqGrsGYQ7Sbyk556g3ZjQLmIOEpI8oKkmBDnBS7JMVEihaKtQw8tutmi6zW6vkE3N+jmGt3eoNsNemgZBi0LFRWJj7CYkuVT0iQnUSmxi4isIrJKAhK0D1DYS0S0OIyzosFZLdocDitVDCCOiLKUOBfQIU4YrKIbHN0gLNHGsxAE7XGn6dx9/W7krf1iT5QKUWwSFFAUhSx+jk+4f3aPR48e8Ytf/IJf/eof+PWvf8Wnn37KJ598wk+ePOHhw4ccHR97AtBMFg1xBMr7KNTIrb1re6btYB5j78oD2571s1DsI12FPy2m8EAzCS3LmGQeaAqxdCwnBcvJhOUk56DIWBY5s0wSOgPYRHjm8JCh4Zm8u0Fq8Qg7dIhmFPtgYKBX/jp662itEIEGLUfeMwZFBJN+uF72ZthxfhxBNkxPYbEvgV5xHJGG6qJ5Sl7kFJMJxWRCmufEqaSPEOrovOOzD/JhgHOrr8qH11S4MLBHdc1zE4Wys3s3YWx7wLF3i+4c985vbv3W+x38ai6s6kJnk6ZwkdTHsSrCWMcwaOEi6nqGXoBHGynBLM48idYoEul4s3Qv3HGvQ+ZxQhLCCu+e9xvkB7GtI6ATcnG01vTDrjibhEg3I9XN3q9uP+g3VVf4zmT3t+Rcd5Qc2vqJQUUYFWEVOOVwyuKUHU1r1gTK9g6tO4zuMKYfzVHWyUDXvUN3Ft1ZTGswrcG2BtdZnBbgiVRMFIlPx6kESyz+EW2xQ48ZWh+m3GD7RsxsQydaSiD9tEqORUxEDDbCDQ7TWUxnGFrN0Gj6RtM3hqHfadeiYdvd0iQY+T3BlQr+xyxFJSlORWgDXW/peosevJkmAM34GMOb76ffvTYm7zT8PCDhthFZljIpJsznM5bLJUdHPnry4UMePXrEo0cPefjwIQ8ePBDT2vExi+WC6Wwm+TtpJn4EbxZzeyBye8yLKXJfnNcIRDOQxYzyGk4SzEp3TGvCCJ2QxTutZ7/laSIaQhwTq53B3wWtywXqHUlKDdQ74XXw5jVz5/EE/1TwE2unCAUtbKCq3btexvlw90be7x10T8sZWxSqtYqFKooj4UqLhRHdOEc3DDRdR9sJb5u17+cj/DDA8eJGh9Q7yp5Wc3e7inxUm49DH/ccd939ZgSsWzfMa1RhJ3/3x47nfQS91lRNx6ZuWFc1623Jer1lfbNlc7OlXG2oV1uadUW9KqlWsq1cbSjXW9ptTV+3DHWPbnp020uJgm7AaY2yQiJ69ypvdf7vbch/vTjvGxiGYWSP3m43lGVF1/WYbyhX8Lbt343I3bLB2RkibYzwqXVa0VuFjWJUGhMXCVF+u8VFSjzJSaYFUVFAkqKtom0tdanZrnpW5zWXz0qunpbcPC/ZvCjZviopL0qay5L+umJY1ehNB50lMhEJOTE5EQUw9dVDJziX42wGNkXZhMjERDYi0uA6gyk7+lVNd11TXZaszrdcv9pw+XzL5bMN519tuPhqw+XTDZvzknpV05YNfSsDmTRBFSlRkRFNcuJpQTwpiPIckhSiFEdCrxV1a9lWmqrStJ2QNu60mh+fhLEh86H4eOM4Jk3EdF0UBQcHB9y/f8aTJ4958uQJj5885snjJzx5/JizszMODg5Gc05Iw9it3L0fJJjQ/JiTiVs0gj7Q31gxT5koEk5Fn5PlXCBd9WPCRyeMycF7NH7ioI8wTtFbaG1IHPURbsZRG6h8q+3eewO1hto4Gq+99Hu+mRFEEOVizDmMIzFB+6qgYU0SmviBxAp0e8rd03gVoqlEknCLimVxh6LXjrLtWW0rrtclL88v+evfn/LHf/ozf/nrV7x8dUHdtBjz7mb0D/PhbLf84z9+wed/+JxXL1/R+7yWICrkdfjEoZ0jSqJ1Bh+ZNGhhGYtGrjXpNIxg5l7TFSLvhAu21mmWcn8xGX0482nBycGMw8WMNParDD/Da+PotGHbdmzbjrJp2ZYN221Nualoqpq2bOmrlqFqabYV1WrL9mZLta4oNxXrdUlVNtRNS9V2bGt5HQahnRAONTNOzm8GF9ny+vbvUfZu43Q+Y7FYSt6Dd+QenxyPyXbhB2pcINwW2b7vw/mDz8N5/oGgFNTW3QLCoZgWCUfLnIdnUyYTobOZTiKm04jJLCZOE1SWyko/i2WCzhJUlqEymZAHHdH30NaWeq1ZX/asX3VsrxrqVUe3aenWLf2mQ9cdruuxzYBrNc4oFClRlBGpnCjKUaoAVXgOtVyqiJoYZyLRkLRDDUBnsFWP3rT025bqpmJzVbG+qlhfVqwuSq5elqwuKsqbmqFp0J1Q11hriNKYdJYS5akH0oykyIjzjDjLUUkGKqXTipfnLV89rfj7s4r1puf8suHqpqVqJJfju+hp6h3ycN5XwtgeLRve5BYnu+ACyWyfs1wuR7/wdDohy1KctdR17Vna/TGQGToAjtoz14uxXe5GqI4kwfcRxClRIv69UJYEH6ihwPPqyVyinACkklAT7xuScibWqZE4tNNCHNpZR++UmMGcZ462vhlHbSyNsVI3R1vqQZgNhI5mr0Cczz3MfeSblM2GSDlixAwXatkEPtAoCjfAz6uEQAlvfYpC/p341MRUGUMUox20g6XqBsq2Y9t03Gwqzi+vadqONE15/Pgx87kEc7yLfLCG44LNfR8t3yJ7ULRTWfwyRPkIttgHGgR1+240261ufVcV3G9hn5HrQ0wLoU5G2w+sq4abTcXVuuT6ZsP11Yrri2tuLm7YXK0or9dU12uqqzXbqzXryxXryxXb6w3VuqTZ1nRVS1+36LbDdD2u62HQKGtfi54bTyncNw+oP6QE7cZYqY9TVSU3qxU3NzesNxvatkUbb376oHP80Iln73c+lDdUq+y0o9XQDIp6UDQmQkcxZDIBx9OUZJIShzbNSWYTkvmMeDpD5QWDiWkaR7UxrC47Lp9VvPzLmpd/XnPx1zVXX61ZPV2zeb6herGlvSgZrir0qoHGEuuElIKECREzYAZujnMznJ2AyXEmB5MR6ZhYx0RaQWPQ647+qqS9KNm82nL1bM3531e8/OqGF39Z8exPNzz70w3P/7zi6sWW7VVJs6np6h7jHOQp0TQnnhUkswnpfEoymxJPClRa4OIc41K6QVHWhtW6Y73pqRrJ4RAzy/sYPL5JvrsjBQkG6Mjn6mW5aDez2YyTkxMeP37ML37xi5GVQF5/wU+ePOH09HSkxpG5Y2ftCJpNWO2HqUQ0HKlV0+01rSJcnIzcfMGM5M9O/ne+oYhc5FuAuQhLjCFmcBGdUV6j8ZqNhcopat8qF1HaiNJFVFZRhn0MXsvx4c7e9CfXJIEOaRyRJVKnR6LhAtOK1LKJ/WuyB7p35yGRcL98InMkdZ+sitEoGm3Z1C2X6y2vrtd89ewlX/zxz/x//8vn/OGLP/L3p8+oqgpjzN7Rv14+GHBgnEG/Wfx+fv5/owjwhGiKu9+KCJyEL1/fSQ69O6mgJQklfHBEG/Fh9MK22nVC8a19M4OWCp6DpzQJTVusltLSLhhVvVotf+j2/did6e6sxi/fcg++bwkLg+DP6fvOtx7tudVu2/y/b3n9GbJnArW+tstgnCdP9I5g5X2CcSw+jTiSMOExVFhC3lWSQpQAiVTgNArdw9A6+tYxdFZq8g27Gn2hfJKzCue99Mr5cgMuBpf4FoOLcP7VxytLTRW382RbqyQvRqj8GDT0A3S9o+8MfWvoO4MehOBRMvJkaapCTaA4kWuNY5lNVDD3iCln0I5+cHS9cAAabWW99cM9yHeS/UXY3YUiaqfhiGldtJw8z5lMJkwmE2bTKfP53EeuTSmKXHJExtycHQVO+Dv7JjU5B3kn610lyUyR8LilWUZe5L4VFEVBUeS+hc8FRZ5L29s3Lwoy/yrvczK/LSsK0r3XpChIsswnAkuiuYoTqQOlxCAftDE5Vx905dNK4sjXrIl2CZu3gq72b/ibZH8eduxmqjCl+SJt2lgGbcTH3fe0XUvV1JSVp8fqejHd7h/7G+TbmdQ+/5xXr8Sktj9LCXhIBnhYcYSb5RxyEVrCouU7iYwIJjXrHcfW8xLtixxbWhIpijThdJazLBLmWcq0yDiazziYTYiVktDDXtN2A1XTsa5qzm82rLYlZdWgO40b7Lh6SYnJiEmIwTisliZJIEoip6ySGhoOWk8OaIHOWnrfrL8d+6GKcPfDDyz+XhZFwXQyJS/E/l0UBQ8fPuTg4EBMap7+Qxyyu0E6HsY/lFtMA7fKE7yL3H2w+yNGBluRx8ymKYfLTFavEcxnCfNZynSWQexXo5kk76osJyomRMWMKJui4gnOFkRMQOXoPqGroGvAkRAXU+LZHDVZoKZzksmcbLYgLmZE+UyobKICohRcgiMDUgEbG6NsAtYHBJgIp5W82gBMKSrKIZnSRzltnDMkE4zK0FYxdBKYkmQxi9MJ8+Mps+M5+WJOfrQgO5gTFYUHUMk9gQhtFV3raBvHdjPw16db/ukva756umVbDqy3PdtKWAa+qwWE+h5Mam8SDwcjAO0ARDEMUjoiz3O01lRVxfX1NVoP8puQ4G3taHofkyk9KWgUzPFJQp7lFHnGfDbh7PSER4/u8+TxA85OT7l/74SHZ/d4cP+MBw/u8eDBGQ/un3H/vt92/4yz+/c4u39Ptj28z4OH97l//x73fDu7f4/7D864/+A+9x/e5+zBGWdn9zg+OeLo6JDDwwOWywVplnlnfaDzwYfWO6JIKJ2kfk7CJI2ZZjGT1JvUbiWQilltP3J3XPuMEXlSklC8zAGkZQFjvNtByD+FLLTtpf7OYAyDllw+PRiWywWPHz3iX/2r33F6erpniv96+Y4Ap7u1j6h/gSdqBxIKyQUZfAy6sVYiQ2K5oXEspjRZ3YoJCPYnPOl8ckM94CQxp7OMRZ4wzRKmRc7RfMpyVhCh6Acp9FU1Pdu65XpT8eLyhqvVlrKscYMjdjGZSoiJyFVCriRfQkJmFRhF5CSaXkgk5QFpB60V6guHEr4lDzhibtxFj8A/M9h4UUh9nCzLiFNh5y2Kgke+FPBsOpX9fBBHmFD2QeeNgPPlH70P510u8g2TVAAc/8GhyNKIPI+ZTRK5d0qxXOQcHBTMFwUkCSoXp7rKE6JiSjRZEE+XRNmMKJkS2RlxPCVSE3QX01WOtnY4lRHPlsQHx6jFMfH8gGR+QL5YEhdLVDZDxROUysRPMzav4dgAOjEutAA2NgWVo5IpUTaDdEafTujSKbqYY+JMNJO6w+FIioTDB0sOHhwwPzskWy7IDhakiylx7gEnSYhi7yMYoCotVWVYrXv++rcNf/zzir/+fcO2GthWA03rfaRh5fMtO98PBTiMXcH/2wMe5xyJL3+gtaYsSy4vLxl68eGM1VqN9WATkcYBdMTXEnn2gzxNmU0mTCcFB8s5P3n8iE9//gmf/uJnPHp4n588fsBPf/KInzx5xJMnj3jy+BFPHj/kyZNHPH78kMePH/Lo0YPx/U9+8pgnP3ks2x8/5PGTRzx+8lC2/eQRj3/6iMePH/Hw0QPu3Tvh9OSYo8MjDg6WJEmKc27MZbHO0useB8RxJECT+ZYmTNOYiTepKZywZ3jA2QcbAuCgMAqcZ2UIgOOUgI5TkQcbfEkDTdvtwKYbtIDNYKS4pNYcHBzw+PFj/s2/+dfcew/A+XYmtbeIqGY7LcX6UE/jzVrWBp1OOlVEUBV3gQPhpu1Nc+Okt+/8c0i4YeBmG8NKtSQECg1+R9V0bKuG9bbierXl6mbN9c2GqmowvSbSEFlF7CISIlJiUhIylZBHGUWckccZeZSTRRlpnJHGKUmUEEfidIsi70Dcmz/H83+nifj7F+dzctq2pdyWbMstZVXSdi1D3zMM2kervaabvaN80wT0lu/9wxSQFidprx1NZ1hte643PTfbgapz9DbGRBk2ziCRAIE4z4iLgng6I5kfkM4PyWaH5PNDitkxxeyYtFgSJVNfx6bApnPM5BAzO8HMT7GzE9zkBCbHUBxBPMORY22CMwmYBEzqX6Xd2m4zsDmOHBXPiLIl8eSIeHZMPDtBLU9Ry1OYH+GKOSTCZqDilHg6JVseUBwdkS8PSOYLoslMuNuyCSrNULGYCK2L6HpH3RjKSlNWmm2p2W6Fj65tpY79m7vcGzf+KEV5E1sSSwCBkH4K6/Tp6SmHh0fMZnMmkylFLr4cWST54CJf02VX30VaFkcUScy0yJhPCpbzGfdPj/npk0f88hc/45e//Dm//tUv+c1n/8Bvf/srfvvbX+/ab37Fb37zKz77zS/57LNf8utf/5LPfvMPfPabf+A3v/kVv/ntr/nt7z7jt7/7jN/969/s2u8+47e/+zW/+e2v+NWvf8mnn/6cn//8Ez756U+4/+CMo8NDlov5rSqoEhgVkacxkyxhlqdMs4RJFpOnMbkHnTSS4IFdZJqfezzIuHFO3vMA+M/GSWVY0WwMbT9Qtz1V21G3HU3X0/WSMtL3d+iwjN5b0LybfAvA2Z/y3yD+qlxonkBwpNwI+/lZeVzRyIevlfDb8aYZS2+kFkSvtbRBSCC7fqDpeuq2pekkmgxniHGjYy1RjkQ5YizWDPS6p+076q5l27Wsu5ZV17DuWta9tE3fsR0Gaq1pjaGzht4K79d4Z8KIf/PI/2cTay2D1p7eRlrXdbSeY23Qu3IF76axvKt8w4Nl93CdX0T0g6FqNJt6YFNpqtbQ9EK93muFdkJ5I9YB79uJfK5KlhDnKUmRkk4y8klGMcmYTFImk5Q8S2SSihOiOEOlBarwJrbJAjVZooolUS6vKl8Q5QuizDf/WYVWLIkmS+LJkmi6JJ4tiWZL4umcqJgSp5nQvMcxWZaQTxKKSUoxTcknOWmRkxSFAGeaoiJhllbK+4uskqTB3lFVmu22Z73pKMuBphnoeiM+HOOZs197dnc//3hkX4O+/dZbNQIRqPfphIqi8/mcma9mm2UZUeR9IGKZ9eCz4yoLfGZpFJGESkYOYueIfEtQZGnCdDphNp8xX8xYLBcsDpcsjg5YHi1ZHB74tmRxsGS+XDBbzpkt5szmM2azKbPplOlkwrTIhf4qTSS6TCkxhYW6RlpjtcYMBucLAIbzlex/MaflaUKWxCTRrubXzuMjsj8ry7reJxS/1sRHumu+aOBItxOUA0/+6oOvgslSuCnlL73Wzb5GvgXgvFmCvZWAOR5grLNCgOgd+LuJbIxn9O3tZz9GxPmJ0ILk1hhLN4RCRQNNt2tVCH+uG5quxVhNnsTMi4yDSc48l/oUWWyI0WjdUTYlq3rDVbXm1XbNs+0Nf9/4Vq54Vm14Xm15WZdcdg2rvmPd91KawFPGBw6wH5vjljFoYKBtO9qmoWkamjq0mq6TJMYRcL6TS3gHsAnixPlljTjCt7VmXQ6syoF1pdnUhrIx1J3QgYQExz2KT1AWYkecK5JpRDqNKOYxi2XC4UHK4TJlPomZxJD5SSZJMqLJHDU7QM2PUItjouUp0fIe0fKUeHmPeHFKvPRtcUq0kO3J8h7JwSnJwT2SQ3kfHxwTLw+J5kvivJCVtrVkyjHNFMt5ysFBxnKZM53nZNOcOM+JUw+CPvRWOjo47TCdo200q1XL5VXD5VXDatNSNQP9YHy2eignvX9Dv5OH+L3KuOBkDy2CSdenWqRpKqS6PpLt4OBQCrodLMnzgmhkLd6fhn0BsRBSHMfCEm0tkZYojqFuaNdbqps19WbD0LY4Y/3fTYizVMqbTwrS6YR0OpG6WdMJSZET5xlRmggDufd9OueEoX7Q6KbFVDW6LGk2G8rrG9ZXV2yurilXa8rNlmq7pa0bzNATO0uqpIRCnkqxtkmWkKVSPkD5KNyweJcm2kwYBb7bCEvFHcCRmKddBO9okdpTDmT8hzv4hj5067t3k2/hw/nHPR+OOO3Enhu6jO8ohH4TnMFyYYGdWHnVN42llIFCoiO0N8HtbqZclBxPjhUpRRopZllE5kMB0zhh7lcU2hg2dcP1tuRmW9J0HdYaiiRinkvezmGRscxiJpFCuYG6bbiuttyUJS+3a56ub/jzzRVPN2uelmv+tlnzrNryot7yqqm4bBuu+55SD1R6oDWGwXl6nPd6FD+cKB/u6awMqODDWS6XUh/H+3nyLPe+OO/EDc/UTwKv+3D2Sky/Ju8AOKGzhB7kf6Kd5DQ4FAcHBYtFTlGkaOdIUsgKhRADpJIQGae7iKUkIc4T4iwiwZA7zSSyLGYJxSQnSXNiFZPlBdl8QXHvjOTgmGhxSDw7JJofE89PiMPr7IR4HsxkR74dEs0OZfviyL8eEM2XqPkclRfC9VZX2LYmNS2TaOAg1xwsYg6OJxw+PmR2b0l+OCPOYpI0Io792DEWpy30hrYauLlq+fOfVzx9uuHZsy1/e7rm7883XFzXdD6/7fai7tuL+pZcat9GZBHrQScS53rX9dRVTVWWRD5KraoqqrqiaTsfQrwLiU6jmMwzOGdxRBY0HOtIHEyTRIosWoPpeqlcOp+SFwVpkZMWBfl8KmAzKUgnBclEos7iPJNFQiJRhc55a472YNN2DJstQ1nSrDdcvzzn4sUrzl+85ObiihcvXvHq1Tmr1ZqmqTB9D9aQxooijVlOM+aTjGmWkCik5LTROCNug+CmkLWh51Ub2QkCsadsN27Hrj3qRn6bsWJWE8bznR/6TeP55OSYTz75Kb///e+5d+8eU+/7/Sb5DjSc/Q7np6TQCYM2Yr2ms6ee3QXMN3Xb3de334UW0FkbKUzUak3rNZ3Wazp111O3HXXb0vaSTZ8lEdM8YV6kTNOIfKxNYTG2p+1bqq5m01bctBWXTcl5veWiLrlsKy6bisu25qZvWQ8dle5HsNGhbPOdc/0xiRvDoqVUQdd1tO2OPbr3JajDhPXttbQ3Pd23yHjTZGHSa0vdGspGs6k1ZaMpa03ZWupW6rYbz0UWqPsdXsOJHFGqiHJFPInIphHTecxykbCYJ0yLiDyC1DkpFB0lqGwC+dSb1pao6QHR7BDlQWXXDnZtKuCUzOU1nofv56jJjGgylbIXChJjyLBMEsVsmrCYZ8znGfk0I8lT4kxKY6golvW+vx/OOIx26N7StYbttmO1arlZtWzLnrbTnhpnL7z91g39lyNv6i3BrDaGS2cZ0+mU5XLJcrlkMZ+TeSbpsCDdP5AKJrVY/CKJgsg6lDYwDOi2pStL6vWWdlsytC1WS5lWpTzlSyLPJs5S4jQlyVL/XgI6RgZl3I6U1Zez103DUNX0ZUWz2VKt1pQ3a8rVmmqzoakqmrqmbzus1sRKTP5ppMg8kWjmkz0jJeMjWCDCo94bOqLhvKbRBK3mrnlNtofj7SwG/mDfoXwLwAkr0dufwmokiNwAfyH7qpofBGHf/eHBW6w4+3gbMMv6qLdeC8tqAJyy7ajajqbtaPuebhCONGfNyDSdxjFJEhEnEXEinUrFMSqRvI67jUThIrCRwygnqupec7jXOJt+jBJWYIFbbRgGuraladsRcLQxu2fw3nPW7UXI7ff77W3in7N3aPba0vaWphPA2VYDm7KnrIeRxkWK+Tmf8Ct1Y1BOCq3Fko6T5BHpJCafJWTTmCxVJMoS24FYayJjUNoxElX5EgPEqWT2J5k479P8TpPt4/eJlL2wBGoU4epRw0A09CRWk8aOYhJTTBPyaUqax8RpLEAzJj7LXbLGoQdD1xmaRlNVw+i/WW06qnoQ340Vu/xtM8i/THlTT9mBTjSyECwC4CwXTCaTXfRlLAUHbx3TW1MCKeZYCdgYbD+gm05AoaoZqgZdN+i6ldemxbQdtvOt77H94F97TNdj2g7dtei2Zag9wFQ13bak3myp1pvRfLb1rSxLmqah6zu0HrBWYsjiSHnqGl/E0ufiKP9UxeeyMyfbfZDxCa77jNmyON8Hl6AP7AAmbB8n1++h+3wLk9ouLHroB+kMIfx57xX/oBmBYg+VvaktiiRUUfn8i8HsbNF3AXa08o7OQEUeK1GdnTiO0ygiwtF0PdtGQKcfBpSDJIqYpClJJOR8SZKSpFIDxaUpLk2JiwnFbEY+m5JPJhTTCcv5lOVMKDWKNBmdeIknu0v9JIEwYowj5Xt4Zt9axucCY5jpgwcPmM1mpFlGkqbiLJ3Pd9x2b3iebzephaOHqSJ8viv7U8rd/f0iVcmDVUAcK+YzsWODo9eGIlfMp7GvnplAJFniYeEjhdVk4nFa4xk6IY0lybPV0PbEFhIXEbuUqDVEzUBkHJG/HOV8PR2F9zPuW8otzhqwWgqxDQNDXdNvN/SrFf16TXfxEn31Ere9JnENeWaYLBX5PCFbZKSHU5JZQZwnngldo5Cia13TsV23rK4bLi4anr8o+cMfr3j6fMv5RcXVTctq01HXWkwlvn2Xon7AsOivk/D3+mFgGIQGKE1TlFKsN2vqpqHvB9JESpME53a0Vyol9A1n5EZFiEltEsXkThEbS6EiMutwdYOpakxZYaqKYb2Vttm1fr2RttrQrdY0l9fUl9dUV1eUl9eszi84f/6Sq/MLLs4vef7ynBeXl5zfrFhXFZu6ou46BmuIY0WaRuS5BLVkqQQMCC0YnmhYWN+NkcXWYIT+Rkxmwk4wcsaNJrUANj4kWu6mH1+ezdoHDYQ5+uvk5OSETz755L1Nah8MOF/84xf84XOphzMMvYBN5NkCfNuXAJhhQIQdBDh2pJ0478PxzLmMgBtuEbf8QxGidip/wxQCQjhL0/U0XUffD1hj/L4RkzQhi4U7KMlykkzKFSgPNtlsznQhkS+T6YSZB5z5tCDxmlGWRGSplMxGSR0X5c9VKlncvvYfozggjmMmk4nQhEwmY3XGYKqI43j047wf4OzLB05KYl4e+45SkgwaKTx9v2UxjTlcpFJOPI6J4oQ4keojCuWreYZAUSNgkThUEmE7gys7VNUSD47EKuIhQTUG1RkJcY8iVKyk4yqfuq68yS6AjbPgtK88KiaUodzS3dzQXl0zbNboq1fYm1dQ3pCqnmIG05OMfJmRznOS+ZRk4h3PWBQDOImorLcdN1c1lxc15xc1z16U/OOX1x5watbbjrLS9L1nGHjTI/iW8mMAnP3+J3WDhFI/y1JUpLi+uaEsS7quI44irDHoocc6N3Ivpr7MvdiZpCRm7KCIYwoiMquIBkNqHInW2NKDTVmJ03+zZVhvGLYCNnqzpV9v6VfrEXDqq2vKiyuqy2s2l5esXl3w8vlzLs4vuLi85MXlFS+vrrlYrymbhqrv6IzG4EjSiDxPmOQZWZaQJr6OmFKAQw+aruuFbFcLw7Q2nlXdOQy+tDSiqI8+nDD/jvVux5uK8hVjg+XD2m/uQB8KOB9uUtvrZ8ojZdBwonF1KSJAs8uVCSqc/Fj2CqsyG6wi/mu3Z34LxwpbwjF7bagHQ9VrNk3PdVlzsSm52JSsq0YoGPaoW8JkFEURUZygshw1KUhmUyYHSw5Pjjg5PeHe2SkPz075yYNTfnr/lCdnxzw8XvLgYM7ZYsbpbMLhJGeRp8yzlCJk/97S8G6bGH8M4pz3p/kqoH3fU9U12+2WzWZDVVV+9bgL2vhw+fCrd86bDkKOQKdZbzvOr2qevyp5dVFzs+6oa0PXWIbOYgYpz4wdhE/GGz4FaBRqEhMtUqJFQlI4kmggNQ1pXxGXJepmjbpcw9UatylxdYPrOlzfge79cXfN2UGKsukBO3RS5rpr0GUp2s3VNcPVNWazQtUb4rYkMQ1ppMlmMekiJV1kxIXQwY/jxjlwBms1XTew3XZcXTVcXtZcXNacXzZcXDVcXrdsthIS/cZI6O9UvteDv5PIihxSr4Wfnp5ydnbGvbN7HB8fc3B4yGK5ZDKdkaTZmNRonS9R4H/vQhSZk3FgugFddwzbmn5d0lzdUL64YPvsJdu/v2Dz9xds//5c2tPnlM9eUr14Je35S8oXryhfvqJ6+Yry+Us2z1+wfv6Cm2cvuXr2gldPn/Py2QtePH/Bq/NzLq6vuV6vWZVb6q7FOAMRRLESTrlMLChpmogC4hzW3C7eFsDG+KhY7V4vry1az66NGnCIaLvls/n2o/2b5MMBJzy70PxAEXU1/Ls93bxJVVPjfzsw+aaLdvgB6fc3IcLCE971Poig0xKibIPt1xMEJmlKlqVkeUZaZKSe9yjwHWV5Tlbkotbm3oSWSfLV1LdZFo/vpz4DuEhi0jjYiRmTQH+MEu5yWNXoYaD3AQS951YTYAr3+X1k7A3fsG1PXutIu+ZUWGDAYCxtb6hbTdVKAMG2klbVmq4zmEFC8EO+QFjbETnp8XGEShQqi4jyiGgSEeWKKPWahe1RuoOhg76FTprrWly71/w2uk72aVtoG1zboPoG1beooSHSHTGaOIGkiEgK/3eTiCj1PkNvjlWESVDq2uje0Laaqh7YbDs2256yGug6TT+EaE7vu3nPp/QvSvb6g/LlDBIfQJBlGUWeM5tJXZ3lwZLZfEaW50TeJyYL2zDJ+knXA49VDu0svdF0eqDRYhmpm4aqbijrmqqqqbYVZVlRlRW1b1VZUVe1RMxVNWVVU9bStnVN2dSUXUs99DRDT6c1g5FKtWFURZ76K4mlrH3kacCCH08W4kK8u1u0ewAJPuTgw/FTY7hG68I4f5fFyDfu8K3lg01qX375pZSYPj9HD8OY1RtuFNyeWwRB/WYlwCREfbe1IpCoM2Nl0H2TKCVMBc6HIYfjKqXQXpXO00Sq9RU589mU04Mli8WM+XzG9OCQ2eERk4PDnd9mOvEstLHUmsB4JlYHZiBRljyC3IeuxrFwuqEE+Ewoq+B5kcLk/qMSr1nGcUye5xwcHIj/JkmYzWacnp5wcnJC4vmdxubvMd/KpPYGVAm7qL1U6ci3WEalihVRojAIbbsDilzMDm1vMVYRRbI69KQfosGG+cZrOuKLkYqbOEuURUS50McoF4HTwjgVI7QhegAPMPQtrqlxbY1ramgaXF3hqhK7WePKLW67wW2ucOsrVLUi1hVJXJNOerIZZEcZ+cmE7N6UeJbJ386C7wmM1vRdS1c3NHXHyxdb/vrXNf/05xXPnpe8OK94+nwr2l0jFUYl2TPc++++x6kfgUltX0I/i5SYPa2z1HWDc5AmKWkS03UtVVVhrR3L3UfeT2y9li/arxzTOktvDZ0ZGIwE09RtK1GujQTVlGVFWdZUTUNVNVRVzbasWG9LNmXFZltytV5zuVpztd5wtd1yXZZclSXbrqMaBhqj6a3BKIjiiDSVCpshwbPIfPl6r/EaI8X5+kHT9Zqu7+kGjbaWwRd0G7UaxG8TKp6G1x287fw2YR6WZyh+9ZCY/03yoSa1DwKcsiz58osv+Mc//IHzi3O0Hnx8/M6cJCInLmDgIyN85x3LTXuCzwA4jj16mnewJYqevEN8PE0OStTLLE2YFRnzSc5sUrCYz7h3fMTBYsF8sWB2eMj06ITp4RFFAJuJsMImsUQxJU6TKUcaOSKryZSliCFPIuJYkSQRRRrjQCr3abEvO8RMHOj+f3TiwTlNU+aLha83ErNcLj19yD0ZpCPd0O3ggXcDnDdNSHfBZu9V7YFOvNf8M7XKMVhhljAO4eCLItpG8nSyNGZWpJLTpZTPjRDizxC1NqaeKzFhREVEnMWiZQwWpQeUG4icRRkD3bCn5TQCOHUNTQW1B5xyi1uvcJsNbruC7Q2UV0TNitg2pEVPfuDIDmKy44L0eEJ6PCWepqgskfOMhG1a64Guaqi3FXXV8ezplj/+acUXX97w7EXJq8uGVxc123Kg7TXWSASoyHcPNvwIAQdCSWTpsygh90yShCzPUUqx3W5ZrVZoY4jGCDWZY6xzWCxOOaySz4PRtMNAqwf6YaDrOqqmFXBpauqmGQGnrlsBnLJmU1asy5L1Vl4vV2suVisuNhuuy5KbumbV1pRDT6MD2DiUj0TLfGJnnvjXPCHzgONwwpoygo2mG6QZGyqAvrmNXkY/F41ja3/xiAAPeI3oewacb2VSw5+0aCgyjvfDOceLGi/o9sWErrrrssGWuBs2t6fq12+EmNR86Vbj6Iyl1ZZmsDTa0luHRaFiocZI04Q8z4RafFJQTCcUs4nXbKYU0wn5pCCb5ORFRp6lkumbRkzTiFkWs8gTFoW0ZZGKDydPmWQJeeLj/D19+D/jePxm8Xq2tVbox31YdNd1Y8lp9266+FvkTRe/BzRvBJug2fgO5QcIkYBNbyx1r9m2mm09sCp7btY91+uezWagrjVD781q2vN2OMm3VspChABQoojyiHiWkCwy4llMVICKBqAD28LQQFvjmkpAxWsyripxdYmtKlxTQl1BXUJV4uqtvG9Koq4i0hWxbUhiTVIoskVCOk9IpglRHqFSH3IfIhwRM6DWhq7TdD4MerPpuL5puF51rDcdTWvoQynpsczv9wM2Pwa5baj35LI+PDrLMiZFwXK55Pj4mJOTE898PvXU/zFEovGO0Vq4UEFCFjHO0BpNrXuqvmPbNmyaWqLIqpKNrwy82mxZb7ZsQtuG9yXrbclqW7IqS27KilVVsaprNk1D1ffUeqA1Gu1JiaNIFt5JHBih5VVCoXc1wawVq4/WQp6prX3NNzP6aDzAjECzb2H5EXSN9wacESRCgMBYo0E0nBAnH422SKG/vr0SctKFvL9nBy3hjrzpzrz+XbiR1olrWDsYrGSl14Oh7n3z76teU3Wauuupup6m7WiajrZu6Oqarq5pq5qmrGjKmrqsKcuazbZiXdasyoZ13bCqW9ZNy6bpKNueuh9oBu3ts2JTN3cf9o9Ugg8nAE6zl/wZ8nSMT2b9WrmDIwIYe2axoLEkDlIHmYPcQeFg6mDuYA4cKDiK4MS30wjuSXOnEfZQYRYwTBxNalmZgfOy4+W65dWq5fKm5fqmYbVq2W462mZA91qyvo33qispe6GSCJXHRJOEaJYQLRKio4T4OCE+SlBLhZpZ1MSgCg3ZgEt8iweIe1zc4+IOl/SQDahcoyaGeO5IDhTpUSLtMCU9yEgWOcksIy6kxk3wLzhPcqu1oW0HNmsJEDi/KLm4lNDnm3XHeuvzboZdEIwjLAq+4Rl9a3nTAuKfR2RlLnNQHEVkacp8NuPw4JCT42OOjo5YHhywWC6YzRfkxYQoTrwlRGYaKYWjiDynv1UWrSyDMrQYSjuwNQNr3XMzdFz1LVdtw2Vbc1FXnFcl5+VWWrXlotpyWZWsmppt31LpjtYMDE5jfSKyiiFOIhJvRkvTxJvUZDEc+/yhoG2YPbAZtNlFpX1NYIAJa8m9HjHO23tDM6zl4AfoOl7eG3CCBLARhueA1DFJIiqu5KdIyYE4ZODu9ddxbtrf7Mb/7tyBt98N59VGudESONBoS+UBZttp1q3mpum5qTtuqobrbc3NpuRmU7JardncrNheX7O9vmZzdc366prV5TXXlzdcXt3w6mrFi6s1L67XPLve8Hy15fmq5MWm4rxsuKparuuWTTt4ldmirfgZ3q880Q8vzpvG+q6jaRrqupZEtJHIU0sSqH2LP03hw4QdRHuO+bsmsUTCkUkdFFaAZuKB5gA4Ao6BewoeRPAohicx/CSGn/r2JMY9jLD3IswRdDPHymmeVx1/X7c8vWl4flXz8qLi/KLi+rqhKjv6RqN7KaI3+jkUUrgtS6BIUPOM6CgnuV+QPJoQP8qJzxLUSYQ6cnBgYWFhanCFwRVaWt7jigGmGhYWdeCIDyE+jUgeZGSPC7KHBemZmNGSg4J4nhMV2ZicqJywPxitGbqeuuq4vK54+nzNV39f8+zFlvPLmut1x6YcKBvN4AGHEWz+1ydB24mUIkkS5rMZR4eH3v94ysnJCUfHJxweHzGdzYnTVOYJ73QXDSMskMXM6mKHiaFTlgrDBsPKaq7NwMXQcd63vOoanjclz+stT8stz8otL8otL8str6otV23NVnfUVtNh0JFFJYokkRybNIvIs5giT8SElgk/XJqmI1NCsNpIno0nJzYCOIOVMOgANiPwBH/NfgDB/v3aGQvkdc+oMO6z9/77kPf34VjDdlvypz99yRdf/COXl+dYoz2xXqhps5+3EQkoeP40fFEhAaIQPrwHPE72C+HTb5fdrbkFUfu8QFaCBsSnI+q0c5AqhTGGYTAYz3dkup62rGnKknpb0pQVq9WKy6sbzq+kfs7lpuTlas2rTcnFtuaq7riqO1ZNz7YbWDU9m1bTDIYhgI6VYIYfq6hQkCrLwBMkHh0d8ejRI87u3/eRfbLyktXXHR/Odsvnf/icL//0JU+fP5XV9r5JLAZiJy0ATs5Ou5kBS+AQWCg4juGebycxnIb3ERwpmIObgssVNlNoq6hbx6aRqLokggyFGaQPFUUujBKePy7U+YlCp0siVBqj8gQ1SYnmGdGBNDVLYBpDAUzAZeBSh0stpBaXGVxqIDWQaVRhiCaWaOaIF47kUJEexSRHKclRRrLMiecZ8SSTIIEklRwhp9CDxWhD1w7c3FT87W9X/PnPFzx/ueFvX23461dbnr2oWZc9bStmQzvGQX/dOPluRP0IfTj4iROEHzCKYokwTTMGrVmvN2w3W+I4ETPlIFUrnTNECvLEZ/NH4isZI74UDMrROkfrLLUzVNZQGs3WDmz0wGboWXWttF4Y5Td9y6ZrqXVP7zSDMljlIIYkUV6zEZ9NniVkY8vIspQkTUaN13rKrkFr6qaT2jSDAE5vLb0RK0rItQmaTQCb0COUR5TQ3WOvJOys1TszJX6e/pH5cHbOpjG6zGs7YTK65WD227mt4HjtJoBNOOb7yO2B5gSr/MpAVgG9sbQ+R6fsNNtuYNv2bJqOTd2yrmo2VSXRJZutz0Px9trNlvWmZF1WrMqam6pmVYk5bVV3rNueTStAU/aaqte0vkPoQCMRzITv8AD/OcX5Gjl6GBj2mta+No7Z8aq9LkG7kYG102jG2g8I7S3ScgUTBVMF0wjmSoBmGYk57TCCo1jacQzHkW/+80EEiwg3V5gC2thSGsN2EE12VQ2sth0rH0LcVD1dO9B3Gj1o8esEX6LyJQ1iJb6UIhbT2jwlmiWoaSIh05MIVUSoXKEyhUr9NaUKUrkulQlnmyoiVKFQUzlWPPfHm6ZERUKUJwJw8a5AobMOow19P9B1PU3Ts9123KxabjyLQFUPNJ2UH7hNznlrufW/CrmNcTK/yKIppShyptMp0+mU+UzKCswXcybTCbGPJB3jK+64BaSBiiUWySiHjhxaOTSWHkvnLJ0zNFbTGk3jW2s0ndF0Vgt5L0Jz5XzZjDiOSBKpbJz4NiZ1+kV6iNp1+GhXuwt718ab1qyUfxY3wm2NZt+Mtt8zZK59Q9ufdd9v8v1g+QDAEVEhSCCATThjN/43gtN4MeHa9tF1zGKX79//um8PNBd8Ol676HRwMg9svFntsmw439acb2perUperTacrza8urndztcbLjYll2XNVdVwXTfctD3rrmfTD2z7garX1L0WH44RzSZoZz/Q4vNbifOJXyO3mgeafQAybwOc0JMjH/WVApmCPIIiktdJJMAyi2Du20EMhwkcS1OnCdG9hOgsRd1L4F4C91I49fscJQJAh7H89iCGRYybR5hCMSTQKUdtDJu252rTcrluuVq3rDYt221LVbY0dS/+nP16MUq0MamloyAWxt8oiaXKZpqg0lSqbmaZb0JHH2cZcZYTpX577skcM79/mkj56yxFJQlC/xwooJGSyM5gjKbrOuqqYbup2Gxq1puW1brjZt2xLQeaTsKfrfVEpfz4+9b3KbcnTw86Pi8nTVNJgVgsODw85OjoiPl8TpYXvr6Qj5MPzSeBB+d9uufElybWmzSNpHnnvmzzwOHfZ6nQ0WRJQp4k5Gkq27JEXhP/mqakidRGimMp4Kh8LR/rhG1l0AI4Yi0JC9lQTmAvKGDPXzzen/1p95Y7NQR47SxL8t8PI+9vUjOGqtzyT3/6I3/68guuLi+wWouJwk9gbh9xncS8G59bAwi6p6l3kol5Yz9JUsDiHRzVbxB/FrJK8A9mMJZm0JS9puwGynbgumq52DZcbhsuNxWv1iXPrtc8u17x3Lenvj1bbXi1rTivGy6qhuu2Y90PbAbDdjBUg6bRhtoTiIq6G2ri3I6z+7GJaKfChAsQJwnHx8c8fPiQ09PTMWw6z3PSNFRUlLtsjGFTbvn8z3/gy6/+xNPr57hcwTSBmW9zr7ks1Q5kHmZwP4OHGdHjlOSnOclPM+JHGepJDo8L3IMczlI4Sb05LYJlLMeexDAR3wtEOCMldCMFRlvaWiLY6k6TxpLXonuNMZKPkaWxdFC5A37widNJkaJIgJRI5ahoQhQX0pIJcTYlzia3WpIVQo+UCZNwlCXEaSz5PUmEikOAgAcbnzfmrMYYIU69vthwdb7i1fMVz57d8OWfrvjyzyteXtRcXrWsNz11rYUZGz/bvFfPClPQm9o3i/qRmtRuyZ65V2tNP/SgYDadYayhrkrK7RbrrAQahLlHCTlmFisKX8JAatDETHyC9ySLmeQp0zxhmqdMs4xpnjErQsuZ+9dFkTOf+O25bJvlGZMso8gz8iwjSzOyNCX2BQCJYpyK0cZJba+up+0l7L1ue7pBCkwGGhuhsrkd9jwu8/16RiHrwDgKzZfb3ksqDXs6P19/3ya1DwKcsiw94HzJ1eUFehjGbhsoE+ScfZKVdRgjWbIgyYZZkpAkyc7fE7q+A+18pNeo+76/jDfQSd5Gqy1tr2l827Q960bIPcW81nK9rbjclNK2Fefbkouy5rKquWk71m3Hqu/ZDppKGxrfWiNF4KR5v40T2HuHZ/fPK0oS54J/JklTTk5OePToEffu3RMq+DynKAryPH8dcKotn//TH/jy73/k6dVzXKag8MBQxF6zUd505jWbexmcpqjTlOgsJX6QED9MiU5TuJfhTjMBmoNYTG1zJcA1iSCLII2lJRFuULjOz7/WYTtLXw20nQDMLBciV2UtcaTIi5SiSKW/RZ4rTSlZ+6kYRQYqQZGgKFAqR8UFUZx50CmI04I4yYiTnDjJiBLPUJx49oAklrDrse6vUNffAhtnsW7AaE3Xtlydb7g833BxvuHlecmf/7biL19tuVq1rLcS7t33e+XZX+tYXzfxf913vMP3/wIAxy/XZeHrJKpr6HFAnufUVcXq+pqbmxVGa/FNBjOaEr9uHgkRcNBwpIyzT8ocCXvlfZ6mFGlKnqVMcknUnOQpk/3XLJF9fDJnnqZkXgOTxbb4RlExTol2M2hD12vqrhvzb/b9N8YxEnXeDQxw4Ul6wAmGh8iDThRykSIx56o9Ek/plwFw9m/sm+Xk5ISfffKz9wYc5d4Fzvak73vOX73i//Z/+U/8p//T/5Ev/vEPVFU1TvAyyXoyOI++2kip595Xkcyz1CN9Kh0kZP164rhOG7pB0+/VZHm/1ZxIADG5+bKKSSPFJBUnchpFTJJYVjVx5M1Lu+JDg7V01tAZT5GDY3AOLfnJt1RZ53ySp/OpH3dP5kcqAWzyPCfNMhaLBb/57DP+N//Vf8Xvf/97FosFJycnnJ6csFgsRrZdgH7oefbqOf/7/+v/gf/z//M/8T/+l/+MjcClCWSp9PIx/NlKsMAkhtMU5glqGhMvIDmOSJYRpAqdxwx5jE3FkSuUzoPc1MFBCZQOKgdbB88MPLdQW/LGMa0tk8axSCPuHxb8/hdHPDmdcu9owtnZAY8eH3N2/5Aki0kyMXtFSQwqAZUhEQKJNFcgJ516x1Tqv4vu9MdAldgAg3/fSz4PfYijZOR1cxrnBqyRkudV2fLVP13x8tmKVy9LXl42/JcvV3z+pw2bbU/bGvreMvSeakhmBjmH14bv/uf3BYO7x9pJFMWcnp7y3/w3/4H/+B//I//+3//7cQHyw8vt85RbIJYE57WbzXbDq/Nzzi8uqKqSP3z+Of/Tf/7PfPH557R1RYKjiECqjjgKJVbgLDCCR+PE4WdwNbKOy6vsoHyi+VhSwmvMcRSKv3kLQjDZhuN4s551MFjF4FPG6q6jrBu2VUU3DAzaULcdXS85OMYTcwatRq78toRTjvCaTYhIUzvqHIWSXmnB+PnaWIf2/sFvsi798tNf8m//7b/lv/3f/bd89tlnHB8f393ljfLegKOHgevra/7H/+G/57//f/+/+Nvf/krbNHuAIzKqeQ60MbvwWudIk8RTb8tKk+DE9f6EXgf1UQbV7gzf/VTDUFPIjQ59J4kUeSx1wRMlanUex6SRTCJys6UsgnYSETJYM5rntAt1cPx4B9HqHLgQLPCdhaV93YTx7vfi60QpRRTHZJ7WZjqb8bNPPuF3v/sd//CrXzGbTlkeHHCwXDKbTkdNCGDQAxfXl/zf/4f/B/+f//m/4/M/f4FVQBJDmsgNTxHQyaw42fMIDiT6SxUR0RSSZUQ0kwADm0boLMYmHnCc8aDj40BroHXQOKiASwuXFtVY0s6Rd46is0zjmON5xj88XnB2WHC0zDk6mnN674Cj4xlJEhOl3k8TR6LVqMRHNoRq9yHSIYBM2L7/XNweoHQebIwHHmnewCv7eb+NcxpnxV/WND2vnq24Oi+5vqq5Wnf8+auSvzytqOqBrrPowaF14La7u6p5l77wtr70Lr+VfnJ4eMh//V//b/l3/+7f8fvf/54sy/6ZNJzb5xzmB29sFLN/VXGzuuH6ZkXbNPz1L3/hj1/8I3/961/om4ZYibKc4OS9gixypH6yFowRVUFqXAXACdcbNOPgCxE+PAEgYazfjwTbRe6CG7mWvL9mb7Ha9QN1J1Q6vZaiem0vwKN9uRYbXBbjnbj9DCL/UXnAEZ+NbAjBEcr/bWmegssHKpivMasFx8fjJ4/5N//63/Af/sN/4JOffcJyuby76xvlvQHHGkNd1/z9q7/xt7/+lZvrawY9jJOv/L8zqznwlNc7H44kiUquzihObp9zSCZtKFw1dqj3Os1bjyAMishrOskef1sSieYj9N8CGs4nhtnRSWe9RiNAE2h6ggj/dPitN+98J/J1g/m7+SMyCBSxN29mWcbx0REPHjzg9N49IUYsCiZFMU4w4X4aY6iain/66p/467O/8er6QoA48kbjsBCM3W7OTv1SUsjpiDKICon+IgIXK2wcYWMl1+jcjj7ceoVh8PGgPVBaqBxKQzw4Yu1IjCNTEbM85vSgYD5JmOYJk2nGbF4wneYy6EKVxtGsNvLo7AFMtAcyYftdcR50tH8NLWg1YWoIGkkoaSChzcOg2axb6rKjrgaqVnN103G96oRNQAtj9s7csbea+4FEKcVkUvDJJ5/wi1/8gsePH99afPywcvu6b49Fv2jte5pa6GiGQXNzfcXF+TnX19eYYSDyFTWVn6Dj4O9Q/mAhkCkc1wOE/1Le7W0LwCLvPdiEPf138rVHIf+jEUB899Yjg7twpVm3K9ViAwvLa9rN7WcwftrLuVHhfPbOU461P1eHAn7fDDgHBwc8fPSQz379GUfHRxRFcXfXN8p7A47zEU1t09C0DcMw7JEG4i9jr95C2HrnzyivddwW2SfcgHHr+50ivPYI/J3228duMj6E3bk4dn9c3u/5l/fO8M7V3P72/U/3LfLaVezJd/ZHpAMGLdAHCWRZRpplPgpx5+PZn2CcE99c00lf6L3NfOzd7F1CmKeVH+F+RI7Wich/6fd3kafJlU+7F7dnuHZBoXBSE82BcvI+QuzVaeITk31ychzH4lvxK9PdxDL2irec9P7rmyScUJDQa0Jf2buGcT95tVZ8DiP9vHUMg0QpCdYK0Lz2xF/b8P1KHEey+JgIue0/D9jwxgu/O+bGRa4xktMySNGyYRj8zp5twu+///T3uuEtEdARkXdv2iv8/k3z297vfJ0n7oCHQ7RYiXL1PWdvEfx2edNf28nXf3v7jn7TfKtQxImY4Wez2RhM9C7y3oDD3g3Y5QKM3+y9313i2/7E7Q672+ctu39ncuvmq9e23L6Ot5zLWzb/y5U90A3Asg8wb5tcnPd7ySAJk6zf980/ub19/KN7275J7na5Ow9j/5ABTMbJxU8Gt3a8JW/c6OXrvvu6HvF134X+7rUXv9J0QRnyv/2+x8S7SOgPIWfkxyz7k3V4De1N8nVP9juRd/0D/vRunWW4hv1tHyBvO4UPOW7oC++r5X4Q4HyUj/JRPspH+SjvKz/uZcpH+Sgf5aN8lP/FyEfA+Sgf5aN8lI/yg8hHwPkoH+WjfJSP8oPIR8D5KB/lo3yUj/KDyEfA+Sgf5aN8lI/yg8hHwPkoH+WjfJSP8oPIR8D5KB/lo3yUj/KDyEfA+Sgf5aN8lI/yg8hHwPkoH+WjfJSP8oPIR8D5KB/lo3yUj/KDyEfA+Sgf5aN8lI/yg8j/H05KibsxkEM1AAAAAElFTkSuQmCC)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}